%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Ejercicios de ecuaciones diferenciales en variables separadas.
%
% Autor: Andrés Herrera Poyatos (https://github.com/andreshp)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{article}

\usepackage{spanish}
\usepackage{template}
\usepackage{title1}
\usepackage{mathematics}

\newcommand{\doctitle}{Apuntes}
\newcommand{\docsubtitle}{}
\newcommand{\docdate}{\date}
\newcommand{\subject}{Modelos matemáticos 2}
\newcommand{\docauthor}{Andrés Herrera Poyatos}
\newcommand{\docaddress}{Universidad de Granada}
\newcommand{\docemail}{andreshp9@gmail.com}
\newcommand{\docabstract}{}
\newcommand{\docrhead}{}

\begin{document}

\maketitle

\section{Introducción}

En esta asignatura se resuelven problemas varacionales que aparecen tanto en la física como en la
biología. El objetivo principal será desarrollar las herramientas que nos permitan abordar estos
problemas. En este proceso aparecerán múltiples ecuaciones diferenciales ordinarias y problemas de
contorno.

En primer lugar vamos a ver un ejemplo de este tipo de problemas que motive el desarrollo de la
teoría.

\begin{ex}[Problema de la cuerda mínima] \label{ex:intro} Sean $(x_0, y_0)$ y $(x_1, y_1)$ dos
  puntos del plano. Consideramos todas las cuerdas que van desde $(x_0, y_0)$ a $(x_1, y_1)$ y nos
  preguntamos cuál es la cuerda de longitud mínima. La respuesta a este problema debería ser el
  segmento que une ambos puntos. No obstante, la demostración de este hecho no es tan evidente. Una
  cuerda es una curva continua que tiene su origen en $(x_0, y_0)$ y termina en $(x_1, y_1)$. En
  este momento nos centramos en aquellas curvas que son la gráfica de una función con el objetivo de
  simplificar el problema. Parece evidente que el resto de curvas no van a tener longitud mínima
  aunque no disponemos una prueba de este hecho todavía. Además, exigimos que las curvas sean de
  clase uno. En resumen, consideramos solamente el siguiente conjunto de curvas
  \[\mathcal{D} = \{y \in \mathcal{C}^1(x_0, x_1)\mid (y, y')([x_0, x_1]) \subset \Omega, y(x_0) =
    y_0, y(x_1) = y_1\}.\] Recordemos que la longitud de una curva $y \in \mathcal{C}^1(x_0, x_1)$
  viene dada por $\int_{x_0}^{x_1} |y'(x)| \diff x$. Por tanto, buscamos aquel elemento
  $\overline{y} \in \mathcal{D}$ que minimice el funcional $\mathcal{F}\colon \mathcal{D} \to \mathbb{R}$
  dado por
  \[\mathcal{F}[y] = \int_{x_0}^{x_1} \sqrt{1 + y'(x)^2} \diff x.\]
  Esta cuestión se denomina \emph{formulación variacional del problema}. Supongamos que existe
  $\overline{y} \in \mathcal{D}$ mínimo de $\mathcal{F}$ y busquemos alguna condición necesaria que
  debe verificar tal mínimo. Nótese que para cualquier
  $\phi \in \mathcal{C}^1_0([x_0, x_1]) = \{\varphi \in \mathcal{C}^1(x_0, x_1)\mid \varphi(x_0) = 0
  = \varphi(x_1)\}$ y $s \in \mathbb{R}$ se tiene que $\overline{y} + s \phi \in \mathcal{D}$ y, por
  tanto, $\mathcal{F}[\overline{y}] \le \mathcal{F}[\overline{y} + s \phi]$. Esto es, $0$ es el
  mínimo global de la función $f\colon \mathbb{R} \to \mathbb{R}$ dada por
  $f(s) = \mathcal{F}[\overline{y} + s \phi]$. Esta función es derivable gracias a la regla de
  Leibniz y su derivada viene dada por
  \[f'(s) = \int_{x_0}^{x_1} \frac{\phi'(x)(\overline{y}'(x) + s \phi'(x))}{\sqrt{1 +
        (\overline{y}'(x) + s \phi'(x))^2}} \diff x.\] Puesto que $f'(0) = 0$, hemos obtenido que
  $\overline{y}$ verifica
  \begin{equation} \label{eq:ex:fdp} 0 = \int_{x_0}^{x_1} \frac{\phi'(x) \overline{y}'(x)}{\sqrt{1 +
        \overline{y}'(x)^2}} \diff x.
  \end{equation}
  Supongamos que $\overline{y} \in \mathcal{C}^2(x_0, x_1)$. En tal caso podemos integrar
  \eqref{eq:ex:fdp} por partes con $u = \overline{y}'/\sqrt{1 + \overline{y}'(x)^2}$ y
  $\diff v = \phi'(x)$ para obtener
  \begin{equation} \label{eq:ex:fd} 0 = -\int_{x_0}^{x_1} \phi(x) \frac{\partial}{\partial
      x}\frac{\overline{y}'(x)}{\sqrt{1 + \overline{y}'(x)^2}} \diff x.
  \end{equation}
  A la búsqueda de aquellas funciones $\overline{y} \in \mathcal{D}$ que verifican \eqref{eq:ex:fd}
  para cualquier $\phi \in \mathcal{C}^1_0([x_0, x_1])$ se le llama \emph{formulación débil del
    problema}. En la Sección \ref{sec:pv} veremos una versión básica del Lema fundamental del
  Cálculo de Variaciones, que aplicamos a \eqref{eq:ex:fd} para obtener que $\overline{y}$ verifica
  la siguiente ecuación diferencial ordinaria
  \begin{equation} \label{eq:ex:edo} \frac{\partial}{\partial x}\frac{\overline{y}'(x)}{\sqrt{1 +
        \overline{y}'(x)^2}} = 0.
  \end{equation}
  A esta ecuación diferencial se le denomina \emph{ecuación de Euler-Lagrange}. Recordemos que
  además tenemos que $\overline{y}(x_0) = 0 = \overline{y}(x_1)$ y, por tanto, la función
  $\overline{y}$ es solución de un problema de contorno, que se denomina \emph{formulación clásica
    del problema}. En este caso el problema de contorno tiene fácil solución. En efecto,
  desarrollando \eqref{eq:ex:edo} obtenemos que
  \[ \frac{\overline{y}''(x)}{\sqrt{1 + \overline{y}'(x)^2}} = 0,\]
  esto es, $\overline{y}'' = 0$ y, por tanto, $\overline{y}(x) = ax+b$ para ciertos
  $a, b \in \mathbb{R}$. Las condiciones de contorno implican que $\overline{y}$ debe ser el
  segmento que une $(x_0, y_0)$ con $(x_1, y_1)$. En resumen, si la solución fuese de clase 2,
  entonces es el segmento que une ambos puntos.
\end{ex}

En el ejemplo anterior hemos seguido el siguiente proceso:
\begin{enumerate}
\item Suponemos que $\overline{y}$ es un mínimo del funcional $\mathcal{F}$ con la regularidad
  requerida.
\item Fijado $\phi \in \mathcal{C}_0^1(\Omega)$ definimos la función
  $f(s) = \mathcal{F}[\overline{y} + s \phi]$. De $f'(0) = 0$ obtenemos una ecuación integral.
\item Integramos por partes la ecuación obtenida, utilizando las condiciones de contorno de $\phi$.
\item Por el Lema Fundamental del Cálculo de Variaciones obtenemos una ecuación diferencial que
  verifica $\overline{y}$. Esta ecuación se denomina ecuación de Euler-Lagrange.
\item\label{item:candidatos} Resolvemos la ecuación de Euler-Lagrange imponiendo las condiciones de
  contorno, obteniendo los candidatos a mínimo de $\mathcal{F}$.
\end{enumerate}

Queda demostrar que una de las soluciones obtenidas en \ref{item:candidatos} es el mínimo de
$\mathcal{F}$. Esta cuestión es compleja y en este curso solo podremos resolverla bajo condiciones
bastante restrictivas.

En lo que sigue desarrollaremos formalmente la ecuación de Euler-Lagrange y
demostraremos que bajo determinadas condiciones las soluciones de la ecuación de Euler-Lagrange
siempre son soluciones de nuestro problema variacional. Además, intentaremos rebajar cada una de las
hipótesis que se han asumido a lo largo del ejemplo.
  
\section{Problemas varacionales} \label{sec:pv}

Introducimos a continuación una primera definición de problema variacional que incluye al Ejemplo
\ref{ex:intro}. Esta definición se irá ampliando a lo largo del curso a medida que nuestras
herramientas sean más potentes.

\begin{definition} \label{def:pv} Sea $I = [x_0, x_1] \subset \mathbb{R}$ y sea
  $\Omega \subset \mathbb{R}^2$ un dominio. Consideramos $F\colon I \times \Omega \to \mathbb{R}$
  derivable y un conjunto no vacío
  \[\mathcal{D} \subset \{y \in \mathcal{C}^1(x_0, x_1)\mid (y, y')([x_0, x_1]) \subset \Omega\}\]
  que puede ser de una de las siguientes formas:
  \begin{enumerate}
  \item $\mathcal{D} = \{y \in \mathcal{C}^1(x_0, x_1)\mid (y, y')([x_0, x_1]) \subset \Omega\};$
  \item
    $\mathcal{D} = \{y \in \mathcal{C}^1(x_0, x_1)\mid (y, y')([x_0, x_1]) \subset \Omega, y(x_0) =
    y_0\}$ para cierto valor $y_0$;
  \item
    $\mathcal{D} = \{y \in \mathcal{C}^1(x_0, x_1)\mid (y, y')([x_0, x_1]) \subset \Omega, y(x_1) =
    y_1\}$ para cierto valor $y_1$;
  \item
    $\mathcal{D} = \{y \in \mathcal{C}^1(x_0, x_1)\mid (y, y')([x_0, x_1]) \subset \Omega, y(x_0) =
    y_0, y(x_1) = y_1\}$ para ciertos valores $y_0$ e $y_1$.
  \end{enumerate}

  Definimos el funcional $\mathcal{F}\colon \mathcal{D} \to \mathbb{R}$ como
  \[\mathcal{F}[y] = \int_{x_0}^{x_1} F(x, y(x), y'(x)) \diff x.\]
  Un problema variacional consiste en encontrar el mínimo o máximo de $\mathcal{F}$ en caso de que
  exista.
\end{definition}

En lo que sigue denotaremos $x,y$ y $p$ a las tres variables de $F$. También denotaremos $F_x$,
$F_y$ y $F_p$ a sus primeras derivadas parciales respectivamente.

\subsection{Ecuación de Euler-Lagrange}

Vamos a reproducir en este contexto general el argumento que se desarrolló en el Ejemplo
\ref{ex:intro}. Como se avisó en este ejemplo necesitaremos utilizar el Lema fundamental del Cálculo
de Variaciones.

\begin{thm}[Versión básica del Lema fundamental del Cálculo de Variaciones]
  Sea $f \in \mathcal{C}([x_0, x_1])$. Entonces, $f = 0$ si, y solo si, para cualquier
  $\phi \in \mathcal{C}^1_0([x_0, x_1])$ se tiene
  \[\int_{x_0}^{x_1} f(x) \phi(x) \diff x = 0.\]
\end{thm}
\begin{proof}
  Es claro que si $f = 0$ entonces se verifica la segunda afirmación. Veamos que el recíproco
  también es cierto. Razonamos por el contrarrecíproco. Supongamos que existe $x_2 \in [x_0, x_1]$
  tal que $|f(x_2)| > 0$. Como $f$ es continua, existe un intervalo abierto
  $J = ]a,b[ \subset ]x_0, x_1[$ tal que $f(x)f(x_2) > 0$ para todo $x \in J$. Definimos la función
  $\phi \in \mathcal{C}^1_0([x_0, x_1])$
  \[ \phi(x) = \begin{cases} \cos\left(\pi\frac{x-(a+b)/2}{b-a}\right) + 1 & \text{ si } x \in J; \\
      0 & \text{ en caso contrario}.\end{cases}\] Nótese que $\phi(x) > 0$ para todo $x \in J$. Por
  tanto, obtenemos que
  \[\int_{x_0}^{x_1} f(x) \phi(x) \diff x \ne 0,\]
  como se quería.
\end{proof}

Aunque de momento podemos desarrollar la teoría usando la versión básica del Lema fundamental del
Cálculo de Variaciones, en un futuro vamos a necesitar aplicar una versión más general del
mismo. Esta versión se enuncia en el siguiente resultado pero no podemos demostrarla con las
herramientas de este curso.

\begin{theorem}[Lema fundamental del cálculo de variaciones]
  \label{thm:fundamental-variaciones}
  Sea $\Omega \subset \R^d$ un dominio y $f \in \mathrm{L}^2(\Omega)$. La función $f$ es igual a la
  función constantemente cero c.p.d si, y solo si, para cualquier
  $\phi \in \mathcal{C}^1_0(\Omega) = \{ \phi \in \mathcal{C}^1(\Omega) \mid \phi = 0 \text{ fuera
    de un compacto de }\Omega\}$ se tiene
  \[\int_{x_0}^{x_1} f(x) \phi(x) \diff x = 0.\]
\end{theorem}

Ya podemos deducir en un ámbito general la denominada ecuación de Euler-Lagrange.

\begin{thm}[Condición necesaria - Ecuación de Euler-Lagrange] \label{thm:el} Consideremos un
  problema variacional tal que $F$ es dos veces derivable respecto de $y$ y $p$. Si
  $\overline{y} \in \mathcal{D} \cap \mathcal{C}^2(x_0, x_1)$ es un mínimo de $\mathcal{F}$,
  entonces $\overline{y}$ cumple la ecuación diferencial
  \[F_y(x, y(x), y'(x)) - \frac{\partial}{\partial x} F_p(x, y(x), y'(x)) = 0.\] A esta ecuación se
  le denomina ecuación de Euler-Lagrange asociada al problema variacional. Por comodidad la
  escribiremos como
  \[F_y - \frac{\partial}{\partial x} F_p = 0.\]
\end{thm}
\begin{proof}
  Supongamos que $\overline{y} \in \mathcal{D} \cap \mathcal{C}^2(x_0, x_1)$ es un mínimo de
  $\mathcal{F}$. Consideremos $\phi \in \mathcal{C}^1_0([x_0, x_1])$. Utilizando la compacidad de la
  imagen de $\overline{y}$ y que $\Omega$ es abierto es sencillo ver que existe $\varepsilon > 0$
  tal que $\overline{y} + s \phi \in \mathcal{D}$ para todo $s \in ]-\varepsilon,
  \varepsilon[$. Puesto que $\overline{y}$ es mínimo global de $\mathcal{F}$, obtenemos que
  $\mathcal{F}[\overline{y}] \le \mathcal{F}[\overline{y} + s \phi]$ para todo
  $s \in ]-\varepsilon, \varepsilon[$. Esto es, $0$ es el mínimo global de la función
  $f\colon ]-\varepsilon, \varepsilon[ \to \mathbb{R}$ dada por
  $f(s) = \mathcal{F}[\overline{y} + s \phi]$. Escribimos por comodidad
  $\#(x, s) = (x, \overline{y}(x) + s \phi(x), \overline{y}'(x) + s \phi'(x))$. La función $f$ es
  derivable gracias a la regla de Leibniz y su derivada se corresponde con
  \[f'(s) = \int_{x_0}^{x_1} \frac{\partial}{\partial s} F(\#(x, s)) \diff x = \int_{x_0}^{x_1}
    F_y(\#(x, s)) \phi(x) + F_p(\#(x, s)) \phi'(x) \diff x.\] Puesto que $f'(0) = 0$, hemos obtenido
  que $\overline{y}$ verifica
  \begin{equation} \label{eq:el:fdp} 0 = f'(0) = \int_{x_0}^{x_1} F_y(\#(x, 0)) \phi(x) +
    \int_{x_0}^{x_1} F_p(\#(x, 0)) \phi'(x) \diff x.
  \end{equation}
  Por hipótesis $\overline{y} \in \mathcal{C}^2(x_0, x_1)$ y, por tanto, podemos integrar el segundo
  sumando de \eqref{eq:el:fdp} por partes con $u = F_p(\#(x, 0))$ y $\diff v = \phi'(x)$ para
  obtener
  \begin{equation} \label{eq:el:fdp:2} 0 = \left[F_p(\#(x, 0)) \phi(x)\right]_{x_0}^{x_1} -
    \int_{x_0}^{x_1} \phi(x) \frac{\partial}{\partial x} F_p(\#(x, 0)) \diff x = - \int_{x_0}^{x_1}
    \phi(x) \frac{\partial}{\partial x} F_p(\#(x, 0)) \diff x.
  \end{equation}
  En vista de \eqref{eq:el:fdp:2} y que $\phi$ se anula en $x_0$ y $x_1$ podemos escribir
  \eqref{eq:el:fdp} como sigue
  \begin{equation} \label{eq:el:fd} 0 = \int_{x_0}^{x_1} \left(F_y(\#(x, 0)) -
      \frac{\partial}{\partial x} F_p(\#(x, 0))\right) \phi(x) \diff x.
  \end{equation}
  
  Aplicamos el Lema fundamental del Cálculo de Variaciones a \eqref{eq:el:fd} para obtener que
  $\overline{y}$ verifica la siguiente ecuación diferencial ordinaria
  \begin{equation} \label{eq:ex:edo} 0 = F_y(x, \overline{y}(x), \overline{y}'(x)) -
    \frac{\partial}{\partial x} F_p(x, \overline{y}(x), \overline{y}'(x))
  \end{equation}
  como se quería.
\end{proof}

En este punto estudiamos cada una de las tres posibles definiciones del conjunto $\mathcal{D}$ por
separado con el fin de comprobar que los mínimos de $\mathcal{F}$ también verifican dos condiciones
de contorno. En efecto, tenemos los siguientes casos:

\begin{enumerate}
\item El conjunto $\mathcal{D}$ es de la forma
  $\{y \in \mathcal{C}^1(x_0, x_1): (y, y')([x_0, x_1]) \subset \Omega, y(x_0) = y_0, y(x_1) =
  y_1\}$ para ciertos valores $y_0$ e $y_1$. En tal caso las condiciones de contorno son
  $y(x_0) = y_0$ e $y(x_1) = y_1$.
\item $\mathcal{D}$ es de la forma
  $\{y \in \mathcal{C}^1(x_0, x_1): (y, y')([x_0, x_1]) \subset \Omega\}$. En tal caso podemos
  repetir el razonamiento realizado en la demostración del Teorema \ref{thm:el} para
  $\phi \in \mathcal{C}^1(x_0, x_1)$ obteniendo
  \begin{equation} \label{eq:contorno:fdp} 0 = \int_{x_0}^{x_1} \left(F_y(\#(x, 0)) -
      \frac{\partial}{\partial x} F_p(\#(x, 0))\right) \phi(x) \diff x + \left[F_p(\#(x, 0))
      \phi(x)\right]_{x_0}^{x_1}.
  \end{equation}
  No obstante, ya sabemos que $\overline{y}$ verifica la ecuación de Euler-Lagrange y, por tanto,
  \eqref{eq:contorno:fdp} se puede simplificar para obtener
  \begin{equation} \label{eq:contorno:fdp:2} 0 = F_p(x_1, \overline{y}(x_1), \overline{y}'(x_1))
    \phi(x_1) - F_p(x_0, \overline{y}(x_0), \overline{y}'(x_0)) \phi(x_0).
  \end{equation}
  Puesto que \eqref{eq:contorno:fdp:2} es válida para cualquier $\phi$ podemos escoger $\phi$
  verificando $\phi(x_0) = 0$ y $\phi(x_1) = 1$, obteniendo que
  $F_p(x_1, \overline{y}(x_1), \overline{y}'(x_1)) = 0$. Análogamente deducimos que
  $F_p(x_0, \overline{y}(x_0), \overline{y}'(x_0)) = 0$.
\item $\mathcal{D}$ es de la forma
  $\{y \in \mathcal{C}^1(x_0, x_1): (y, y')([x_0, x_1]) \subset \Omega, y(x_0) = y_0\}$ para cierto
  valor $y_0$. Razonamos de forma análoga a b) para obtener las condiciones de contorno
  $y(x_0) = y_0$ y $F_p(x_1, \overline{y}(x_1), \overline{y}'(x_1)) = 0$. Nótese que no podemos
  obtener la condición $F_p(x_0, \overline{y}(x_0), \overline{y}'(x_0)) = 0$ ya que para que
  $\phi \in \mathcal{C}^1(x_0,x_1)$ verifique \eqref{eq:contorno:fdp} debe cumplir $\phi(x_0) = 0$
  (en caso contrario $\overline{y}+s\phi \not \in \mathcal{D}$ para cualquier $s \in \R$).
\item $\mathcal{D}$ es de la forma
  $\{y \in \mathcal{C}^1(x_0, x_1): (y, y')([x_0, x_1]) \subset \Omega, y(x_1p) = y_1\}$ para cierto
  valor $y_1$. Razonamos de forma análoga a c) para obtener las condiciones de contorno
  $y(x_1) = y_1$ y $F_p(x_0, \overline{y}(x_0), \overline{y}'(x_0)) = 0$.
\end{enumerate}

\begin{definition}
  En el contexto actual, el problema de contorno que hemos obtenido se denomina \emph{problema de
    contorno del problema variacional}. A las soluciones del problema de contorno se les llaman
  \emph{extremales}.
\end{definition}

\begin{ex}[Curva de longitud mínima]
  Retomamos el Ejemplo \ref{ex:intro} eliminando la condición de contorno $y(x_1) = y_1$. En tal
  caso por los razonamientos anteriores las extremales verifican la ecuación de Euler-Lagrange,
  $y'' = 0$, y las condiciones $y(x_0) = x_0$ y $0 = F_p(x_1, y(x_1), y'(x_1))$. Recuérdese que
  $F_p = p / \sqrt{1+p^2}$ y, por tanto, la segunda condición de contorno es $y'(x_1) =
  0$. Obtenemos que solo hay una única extremal, la función $y = x_0$ como cabría esperar.
\end{ex}

Cuando pretendamos resolver un problema variacional el primer paso será calcular las extremales
asociadas. La ecuación de Euler-Lagrange no siempre es sencilla de resolver. No obstante, en la
práctica la función $F$ puede no depender de alguna de las variables $x$, $y$ o $p$. En tal caso la
resolución de la ecuación de Euler-Lagrange se simplifica enormemente como mostramos a continuación.

\begin{enumerate}
\item La función $F$ no depende de de $x$. En tal caso tenemos que
  \[\frac{\partial}{\partial x} \left(F(\overline{y}(x), \overline{y}'(x)) - \overline{y}'(x)
      F_p(\overline{y}(x), \overline{y}'(x))\right) = \overline{y}'(x) \left(F_y(\overline{y}(x),
      \overline{y}'(x)) - \frac{\partial}{\partial x} F_p(\overline{y}(x), \overline{y}'(x))\right)
    = 0.\] Consecuentemente, los extremales son aquellas soluciones de las ecuaciones
  \begin{equation}
    \label{eq:el:x}
    F(\overline{y}(x), \overline{y}'(x)) = \overline{y}(x) F_p(\overline{y}(x), \overline{y}'(x)) + k
  \end{equation}
  para $k \in \mathbb{R}$ arbitrario que verifican las condiciones de contorno. Estas ecuaciones
  suelen ser más sencillas de resolver ya que solo intervienen $F$ y $F_p$.
\item La función $F$ no depende de de $y$. En tal caso las extremales son aquellas soluciones de las
  ecuaciones
  \begin{equation}
    \label{eq:el:y}
    F_p(x, \overline{y}'(x)) = k
  \end{equation}
  para $k \in \mathbb{R}$ arbitrario que verifican las condiciones de contorno. Este es el caso del
  Ejemplo \ref{ex:intro}.
\end{enumerate}

\subsection{Convexidad: Condición suficiente de existencia}

En este apartado damos una primera condición suficiente de existencia de solución para un problema
variacional. Recordemos en este punto que cuando uno minimiza una función real de variable real
derivable la convexidad local de la función nos permite discernir si un punto crítico es mínimo,
máximo o punto de inflexión. Vamos a aplicar el concepto de convexidad en el ámbito actual.

\begin{definition}
  Sea $\Omega \subset \R^d$ un conjunto convexo y $f \colon \Omega \to \R$. La función $f$ es
  \emph{convexa} si para cualquier $x,y \in \Omega$ se tiene que
  \[ f(tx + (1-t)y) \le tf(x) + (1-t)f(y) \] para todo $t \in [0,1]$. Si la desigualdad anterior
  siempre es estricta entonces $f$ es \emph{estrictamente convexa}.
\end{definition}

Desarrollamos a continuación el principal teorema de esta sección.

\begin{theorem}
  \label{thm:convex:minimo}
  Consideremos un problema variacional con las condiciones de regularidad el Teorema
  \ref{thm:el}. Sea $\overline{y} \in \mathcal{D} \cap \mathcal{C}^2(x_0,x_1)$ un extremal. Si el
  conjunto $\mathcal{D}$ y el funcional $\mathcal{F}$ son convexos, entonces $\overline{y}$ es un
  mínimo global de $\mathcal{F}$ en $\mathcal{D}$.
\end{theorem}
\begin{proof}
  En primer lugar, observamos que invirtiendo la demostración del Teorema \ref{thm:el} obtenemos que
  \[ \left.\frac{\partial}{\partial t}\left( \mathcal{F}[ \overline{y} + t \phi ] \right)\right|_{t
      = 0} = 0 \] para cualquier $\phi \in \mathcal{C}_0^1(x_0,x_1)$. Sea $z \in
  \mathcal{D}$. Veamos que $\mathcal{F}[ \overline{y} ] \le \mathcal{F}[z]$. Definimos la función
  $\phi = z - \overline{y} \in \mathcal{C}^1(x_0,x_1)$. Por la convexidad de $\mathcal{F}$
  deducimos que para $t$ lo suficientemente pequeño se verifica $y+t\phi \in \mathcal{F}$ y
  $\mathcal{F}[\overline{y}+t\phi] = \mathcal{F}[(1-t)\overline{y}+ tz] \le
  (1-t)\mathcal{F}[\overline{y}] + t \mathcal{F}[z]$. Consecuentemente obtenemos que
  \[ \frac{\mathcal{F}[\overline{y}+t\phi] - \mathcal{F}[\overline{y}]}{t} \le \mathcal{F}[z] -
    \mathcal{F}[\overline{y}]. \] Haciendo tender $t$ a $0$ deducimos el resultado.
\end{proof}

En ocasiones podemos encontrar mínimos locales de $\mathcal{F}$. En tal caso la convexidad también
nos permite asegurar que son mínimos globales.

\begin{prop}
  Consideremos un problema variacional tal que el conjunto $\mathcal{D}$ y el funcional
  $\mathcal{F}$ son convexos. Si $\overline{y} \in \mathcal{D}$ es mínimo local (resp. estricto) de
  $\mathcal{F}$ bajo la norma $||\cdot||_{\infty}$, entonces $\mathcal{F}$ alcanza un mínimo global
  en $\overline{y}$.
\end{prop}
\begin{proof}
  Sea $U \subset D$ entorno convexo en el que $\overline{y}$ es mínimo global. Sea
  $z \in \mathcal{D}$. Existe $t \in \R$ tal que $tz+(1-t)y \in U$. Tenemos que
  $\mathcal{F}[ \overline{y} ] \le \mathcal{F}[tz+(1-t)y] \le (1-t)\mathcal{F}[\overline{y}] + t
  \mathcal{F}[z]$. Consecuentemente $\mathcal{F}[ \overline{y} ] \le \mathcal{F}[z]$ como se quería.
\end{proof}

En este punto nos preguntamos cómo podemos comprobar que $\mathcal{D}$ y $\mathcal{F}$ son
convexos. El siguiente resultado nos proporciona una condición suficiente fácil de verificar.

\begin{prop}[Condición de convexidad] \label{prop:convex:cond} Consideremos un problema
  variacional. Si el conjunto $\Omega$ es convexo y la función $F$ es convexa sobre $\Omega$, esto
  es, para cualquier $x \in I$ fijo la función $F(x, y, p)$ es convexa, entonces $\mathcal{D}$ es
  convexo y $\mathcal{F}$ es convexo.
\end{prop}
\begin{proof}
  Es una consecuencia de la linealidad y la monotonía de la integral.
\end{proof}

\begin{remark}
  Recordemos en este punto que dado $\Omega \subset \R^d$ abierto y $f \in \mathcal{C}^2(\Omega)$,
  la función $f$ es convexa si, y solo si, su matriz hessiana es semidefida positiva. Este resultado
  nos permitirá comprobar las hipótesis de la Proposición \ref{prop:convex:cond}.
\end{remark}

\begin{remark}
  La condición anterior no es necesaria. Por ejemplo, el funcional
  \[ \mathcal{F}[y] = \int_0^1 y^2(x)(1 - y'(x)) \diff x \] es convexo sobre
  $\mathcal{D} = \mathcal{C}_0^1(0,1)$ pero $F$ no es una función convexa.  En efecto, tenemos que
  \[ \mathcal{F}[y] = \int_0^1 y^2(x) \diff x - \int_0^1 y^2(x)y'(x) \diff x = \int_0^1 y^2(x) \diff
    x - \left[ \frac{y^3(x)}{3}\right]^1_0 = \int_0^1 y^2(x) \diff x, \] de donde deducimos por la
  proposición previa que $\mathcal{F}$ es convexo. No obstante, la función $F$ verifica
  \[ \mathrm{Hess}(F)(y,p) = \left(
      \begin{matrix}
        2(1-p) & -2y \\
        -2y & 0
      \end{matrix}
    \right), \] que es semidefinida negativa para $p > 1$.
\end{remark}

\section{Cálculo de extremales: Problemas de contorno}

En la sección anterior deducimos la ecuación de Euler-Lagrange así como las condiciones de contorno
que debe verificar un mínimo del funcional que sea de clase $2$. Esto es un problema de contorno.

\begin{definition}
  Un \emph{problema de contorno} o \emph{PC} consiste en encontrar una solución de una ecuación
  diferencial ordinaria en un intervalo $I = [x_0, x_1]$ obligando a que la solución verififique
  ciertas condiciones en los extremos del intervalo.
\end{definition}

Las condiciones de contorno pueden ser muy variadas. A continuación introducimos los tipos de
condiciones de contorno más habituales.

\begin{enumerate}
\item \textbf{Condiciones de tipo Dirichlet:} Se fija el valor de la función en los extremos del
  intervalo.
\item \textbf{Condiciones de tipo Newmann:} Se fija el valor de la derivada en los extremos del
  intervalo.
\item \textbf{Condiciones separadas:} En cada extremo del intervalo se fija el valor de una
  combinación lineal de la función y su derivada. Generalizan a las condiciones de tipo Dirichlet y
  Newmann.
\item \textbf{Condiciones periódicas:} Los valores de la función o su derivada en el extremo deben
  ser los mismos.
\end{enumerate}

Además, si los valores impuestos son nulos las condiciones se denominan \emph{homogéneas} mientras
que se denominan \emph{no homogéneas} en caso contrario.

Los problemas de contorno pueden tener solucion única, tener múltiples soluciones o no tener
solución.  En lo que sigue vemos un ejemplo de cad auno de estos casos.

\begin{ex} \label{ex:contorno} Consideramos la EDO $x'' + x = 0$. Sabemos que las soluciones de esta
  EDO son de la forma $A \cos(x) + B \sin(x)$ con $A,B \in \R$.
  
  \begin{enumerate}
  \item Si fijamos condiciones de tipo Dirichlet en $I = [0,\pi]$ ($y(0) = y_0$, $y(\pi) = y_1$),
    entonces el problema de contorno tiene solución si, y solo si, $y_0 = y_1$, en cuyo caso hay
    tantas soluciones como posibles valores de $B$.
  \item Si fijamos condiciones de tipo Dirichlet en $I = [0, \pi / 2]$, entonces existe una única
    solución.
  \end{enumerate}
\end{ex}

\begin{ex} \label{ex:no-sol} Consideramos el problema de contorno con condiciones de tipo Newmann
  \[
    \begin{cases}
      y'' = 2; \\
      y'(0) = 0; \\
      y'(1) = 0.
    \end{cases}
  \]

  El problema no tiene solución ya que esta debe ser de la forma $y(t) = t^2 + A t + B$ pero
  $y'(0) = A \ne y'(1) = 1+A$.
\end{ex}

Nos preguntamos en este punto si todo problema de contorno puede verse como la ecuación de
Euler-Lagrange de algún funcional. La respuesta es en general negativa aunque esto sea posible a
veces como mostramos en el siguiente ejemplo.

\begin{ex} \label{ex:no-sol:2} En el Ejemplo \ref{ex:no-sol} vimos un problema de contorno que no
  tiene solución. Nos preguntamos si proviene de un problema variacional. En tal caso, debe tenerse
  $F_y - \frac{\partial}{\partial x} F_p = y''-2$. Supongamos que $F_y = -2$. Entonces,
  $\frac{\partial}{\partial x} F_p = -y''$ y, por tanto, $F_p = -y'$. Deducimos que debe tenerse
  $F(x,y(x),y'(x)) = -2y(x) - y'(x)^2/2$. Por tanto, $F(x,y,p) = -2y -p^2/2$. Consideramos
  $\Omega = \R^2$, $I = [0,1]$ y $\mathcal{D} = \mathcal{C}^1(0, 1)$. El problema variacional
  asociado tiene a $y'' -2 = 0$ como ecuación de Euler-Lagrange. Además, las condiciones de contorno
  son $y'(0) = 0 = y'(1)$ pues $\mathcal{F}_p(x,y(x),y'(x)) = -y'(x)$ . Por tanto, el funcional no
  tiene ningún mínimo de clase $2$. De hecho, el funcional no va a tener ningún mínimo pues no está
  acotado, basta considerar las funciones $Cx^2(x-1)^2$ para comprobarlo.
\end{ex}


\subsection{El problema de la viga}

\begin{ex}[Problema de la viga]
  
\end{ex}

\begin{ex}[Formulación variacional del problema de la viga]
  
\end{ex}

\subsection{Forma autoadjunta}

Aunque el problema de la viga admita una formulación variacional, no todo problema de contorno puede
verse como la ecuación de Euler-Lagrange de un PV. En esta sección nos centramos en EDOs de segundo
orden, que sí provienen de un PV. Consideramos tres funciones continuas
$a, b, c : [x_0, x_1] \to \R$ y la EDO
\begin{equation} \label{eq:edo:2}

  y''(x) + a(x) y'(x) + b(x)y(x) = c(x).  \tag{E2}
\end{equation}

Las EDOs de segundo orden permiten una formulación más simple como mostramos a continuación. Fijamos
$x_0 \in [x_0, x_1]$. Definimos $P(X) = \exp\left(\int^x_{x_0} a(s) \diff s\right)$ para todo
$x \in [x_0, x_1]$. Nótese que $P > 0$. Por tanto, multiplicando \eqref{eq:edo:2} por $P(x)$
obtenemos una ecuación equivalente que responde a
\[c(x) P(x) = P(x)y''(x) + P'(x)y'(x) + P(x) b(x) y(x) = \left(P(x)y'(x)\right)' + P(x) b(x) y(x).\]
Denotando $R(x) = c(x) P(x)$ y $Q(x) = P(x) b(x)$, hemos obtenido que \eqref{eq:edo:2} es
equivalente a la ecuación
\begin{equation}
  \label{eq:edo:sturm}
  \left(P(x)y'(x)\right)' + Q(x) y(x) = R(x),
  \tag{S}
\end{equation}
que se denomina \emph{forma autoadjunta} o \emph{forma de Sturm} de la EDO de segundo orden. La
forma autoadjunta nos permite trabajar de forma más cómoda con la ecuación diferencial, por lo que
será habitualmente utilizada de aquí en adelante.

En este punto podemos intentar utilizar la estrategia del Ejemplo \ref{ex:no-sol:2} sobre
\eqref{eq:edo:sturm}. Obligamos a que $\frac{\partial}{\partial x} F_p = - \left(P(x)y'(x)\right)'$,
obteniendo que $F_p = -P(x)y'(x)$ y $F_y = Q(x)y-R(x)$. Deducimos que la única posibilidad es
$F(x,y,p) = Q(x)y^2/2 - R(x)y - P(x) p^2/2$. Este hecho da lugar al siguiente teorema.

\begin{thm} \label{thm:pv:sturm} Consideramos una EDO de segundo orden \eqref{eq:edo:sturm} y
  definimos $F(x,y,p) = P(x) p^2/2 - Q(x) y^2/2 + R(x)y$. Entonces \eqref{eq:edo:sturm} es la
  ecuación de Euler-Lagrange del problema variacional asociado a $F$ para cualquier
  $I = [x_0, x_1] \subset \R$.
\end{thm}
\begin{proof}
  La demostración de este hecho es una simple comprobación.
\end{proof}

Cabe resaltar que a priori el funcional $\mathcal{F}$ del Teorema \ref{thm:pv:sturm} puede tener un
mínimo que no sea extremal. En este punto entra en juego el Teorema \ref{thm:sturm:pv}. Para poder
demostrarlo necesitamos desarrollar antes varias herramientas.


En primer lugar, vamos a poner en equivalencia roblemas de contorno de tipo Dirichlet o Newmann no
homogéneos con un problema del mismo tipo homogéneo. El siguiente lema consigue este hecho para
problema de tipo Dirichlet y es fácilmente generalizable a problemas de tipo Newmann. En vista de
este resultado de aquí en adelante consideraremos condiciones homogéneas.


\begin{lemma} \label{lem:pc:hom} Consideramos una EDO \eqref{eq:edo:sturm} con condiciones de
  contorno tipo Dirichlet. Sea $y(x)$ una solución de este problema de contorno. Entonces la función
  \[ z(x) = y(x) - \frac{y_1(x-x_0) - y_0(x-x_1)}{x_1- x_0} = y(x) - y_0 - \frac{y_1 - y_0}{x_1-
      x_0}(x-x_0) \] es solución del problema de contorno
  \[
    \begin{cases}
      (P(x)z'(x))' + Q(x)z(x) = R(x) + P'(x) \frac{y_1 - y_0}{x_1- x_0} + Q(x)  \frac{y_1(x-x_0) - y_0(x-x_1)}{x_1- x_0}; \\
      z(x_0) = 0; z(x_1) = 0.
    \end{cases}
  \]
\end{lemma}
\begin{proof}
  Es una comprobación directa.
\end{proof}

Consideramos una EDO de segundo orden homogénea. Esta puede escribirse como sigue
\begin{equation}
  \label{eq:sturm:eh}
  (P(x)y'(x))' + Q(x)y(x) = 0.
  \tag{SH}
\end{equation}

Sabemos que las soluciones de esta ecuación forman un espacio vectorial de dimensión $2$ y, por
tanto, son de la forma $A \phi_1(x) + B \phi_2(x)$, donde $\{\phi_1, \phi_2\}$ es un sistema
fundamental de soluciones. Nótese que las condiciones de contorno del tipo
$a_i y(x_i) + b_i y'(x_i) = 0$ y las condiciones periódicas dan lugar a ecuaciones lineales sobre
$A$ y $B$. Juntando las dos ecuaciones que obtenemos de $x_0$ y $x_1$ tenemos un sistema de
ecuaciones lineales con dos incógnitas, cuyas soluciones forman un espacio vectorial de dimensión
$0$, $1$ o $2$. En el Ejemplo \ref{ex:contorno} hemos visto todos estos casos.

\begin{ex}
  Justificar por qué es imposible que todas las soluciones de una EDO lineal de orden 2 resuelvan el
  mismo PC con condiciones de contorno separadas.

  Realizamos el ejercicio para condiciones Dirichlet del tipo $y(x_0) = 0$ y $y(x_1) = 0$. Tras
  resolver la EDO y aplicar las condiciones de contorno a la solución $A \phi_1(x)+B\phi_2(x)$
  obtenemos el sistema
  \[
    \left(
      \begin{matrix}
        \phi_1(x_0) & \phi_2(x_0) \\
        \phi_1(x_1) & \phi_2(x_1)
      \end{matrix}
    \right) \left(
      \begin{matrix}
        A \\
        B
      \end{matrix}
    \right) = 0.
  \]
  Todas las soluciones de la EDO verifican el problema de contorno si, y solo si, cualquier par
  $(A,B)$ es solución el sistema, esto es, la matriz de coeficientes es idénticamente $0$. Pero esto
  implica que el wronsquiano de $\phi_1$ y $\phi_2$ en $x_0$ y $x_1$ es $0$, lo que contradice que
  sean un sistema fundamental de soluciones.
\end{ex}

Ya sabemos resolver los problemas homogéneos. A partir de las soluciones de los problemas homogéneos
nos planteamos resolver los problemas completos. En primer lugar, nótese que dadas $y_1, y_2$
soluciones de \eqref{eq:edo:sturm} se tiene que $y_1-y_2$ es solución de \eqref{eq:sturm:eh}.  Por
tanto, para calcular todas las soluciones de \eqref{eq:edo:sturm} basta conocer una solución
particular y resolver la ecuación homogénea. Para obtener una solución particular podemos utilizar
el método de variación de las constantes.

El siguiente resultado discute la existencia de solución del los problemas completos.

\begin{thm}[Alternativa de Fredholm]
  Consideramos un problema de contorno cuya EDO es \eqref{eq:edo:sturm} con condiciones de contorno
  separadas homogéneas o periódicas. Se cumple una de estas alternativas:
  \begin{enumerate}
  \item El problema homogéneo tiene como única solución a $y = 0$, en cuyo caso el problema completo
    tiene una única solución.
  \item El problema homogéneo tiene más de una solución (un espacio vectorial de dimensión $1$ o
    $2$), en cuyo caso el problema completo tiene solución si, y solo si, para cualquier solución
    $y$ del problema homogéneo se cumple
    \[\int_{x_0}^{x_1}R(s) y(s) \diff s = 0,\]
    en cuyo caso cada solución del problema homogéneo determina una única solución del problema
    completo.
  \end{enumerate}
\end{thm}
\begin{proof}
  Vamos a escribir las soluciones de \eqref{eq:edo:sturm}. Sea $\{\phi_1, \phi_2\}$ un SFS de
  \eqref{eq:sturm:eh}. Entonces, una solución $y$ de \eqref{eq:edo:sturm} es de la forma
  \[y(x) = y_p(x) + y_h(x) = y_p(x) + A \phi_1 + B\phi_2\] para ciertos $A, B \in \mathbb{R}$ e
  $y_p$ es una solución particular de (EC), que se puede calcular mediante la fórmula de variación
  de las constantes, obteniendo
  \[y_p(x) = \int_{x_0}^{x} \frac{R(s)}{W(x_0) P(x_0)} ((\phi_2(x) \phi_1(s) - \phi_2(s) \phi_1(x))
    \diff s),\]

  donde $W(x)$ es el wronskiano de $\phi_1$ y $\phi_2$. En este punto estudiamos el resultado para
  distintos problemas de contorno. Nosotros vamos a ver la demostración para condiciones tipo
  Dirichlet, esto es, las condiciones son $y(x_0) = 0 = y(x_1)$. Podemos suponer que
  $\phi_1(x_0) = 1$, $\phi_1'(x_0) = 0$, $\phi_2(x_0) = 0$ y $\phi_2'(x_0) = 1$. Evaluando $y$ en
  las condiciones de contorno obtenemos el sistema
  \[\left(
      \begin{array}{cc}
        1 & 0 \\ 
        \phi_1(x_1) & \phi_2(x_1) \\
      \end{array}
    \right) \left(
      \begin{array}{c}
        A \\ B
      \end{array}
    \right) = \left(
      \begin{array}{c}
        0 \\ \beta
      \end{array}
    \right),
  \]
  donde $\beta = -y_p(x_1)$. Estudiando las soluciones del sistema anterior obtenemos fácilmente el
  resultado. En efecto, el sistema homogéneo tiene única solución si, y solo si $\phi_2(x_1) \ne
  0$. En tal caso, el sistema completo tiene solución única. Si $\phi_2(x_1) = 0$, entonces el
  sistema previo tendrá solución si, y solo si, $\beta = 0$.  Como $\phi_2(x_1) = 0$ tenemos que
  $\phi_1(x_1) \ne 0$ gracias a $W(x_1) \ne 0$. Por tanto, la existencia de solución equivale
  \[\int_{x_0}^{x_1} R(s) \phi_2(s) \diff s = 0.\]
  Nótese que las soluciones de la ecuación homogénea son de la forma $B \phi_2$ y cada valor de $B$
  determina una única solución de la ecuación completa.
\end{proof}


Como consecuencia obtenemos el principal resultado de esta sección.


\begin{thm} \label{thm:sturm:pv} Sean $P, Q$ y $R$ son funciones continuas en $[x_0, x_1]$ con
  $P \in \mathcal{C}^1(x_0, x_1)$ y $P > 0$. Si $Q < 0$, entonces la función
  $F(x,y,p) = P(x) p^2/2 - Q(x) y^2/2 + R(x)y$ es convexa. Además, bajo estas hipótesis, consideramos el problema
  de contorno dado por \eqref{eq:edo:sturm} y las condiciones
  \begin{equation}
    \begin{cases}
      a_0 y(x) + b_0 y'(x) = c_0; \\
      a_1 y(x) + b_1 y'(x) = c_1;
    \end{cases}
  \end{equation}
  cumpliendo $|a_0| + |a_1| > 0$, $a_0 b_0 \ge 0$ y $a_1b_1 \ge 0$. Entonces existe una única
  solución del problema de contorno que es mínimo de $\mathcal{F}$.
\end{thm}
\begin{proof}
  Es fácil ver que la función $F$ es convexa. En efecto, fijado $x$ obtenemos que
  \[ \mathrm{Hess}(F)(x,y,p) = \left(
      \begin{matrix}
        -Q & 0 \\
        0 & P
      \end{matrix}
    \right), \] que es definida positiva. Por tanto, $F$ es convexa y el funcional $\mathcal{F}$
  también lo es. El Teorema \ref{thm:convex:minimo} garantiza que las soluciones de la ecuación de
  Euler-Lagrange son mínimos de $\mathcal{F}$. Veamos que hay una única solución de este problema de
  contorno. Utilizamos una variante del Lemma \ref{lem:pc:hom} para reducir el problema de contorno
  a uno Dirichlet homogéneo. En este contexto, por la alternativa de Fredholm basta corroborar que
  el sistema homogéneo tiene solamente como solución a la trivial. Por reducción al absurdo,
  supongamos que el problema tiene una solución $y$ distinta de la trivial. Nótese que
  $y'(x_0) \ne 0$ por unicidad de solución del PVI $y(x_0) = 0$, $y'(x_0) = 0$. Suponemos sin
  pérdida de generalidad que $y'(x_0) > 0$. La función tendrá un máximo en un punto $x_2$, con
  $y(x_2) > 0$. Este punto debe ser interior y, por tanto, $y'(x_2) = 0$ e $y''(x_2) < 0$. No
  obstante, en la ecuación obtenemos que $P(x_2)y''(x_2) + P'(x_2)y'(x_2) + Q(x_2) y(x_2) =
  0$. Consecuentemente, $y''(x_2) = - Q(x_2) y(x_2) / P(x_2) > 0$, contradicción.
\end{proof}

\section{Problemas variacionales generalizados}

\subsubsection{Motivación: Existencia de geodésicas}

El problema de las geodésicas consiste en, dada una superficie y dos puntos suyos, buscar una curva
que conecte los dos puntos y que tenga la mínima longitud posible. Nosotros hemos resuelto
parcialmente este problema en el plano, obteniendo que la solución era el segmento que une los dos
puntos. Las geodésicas se plantean mediante un PV que dependen de varias funciones con
restricciones. Por ejemplo, podemos considerar la esfera, en cuyo caso la solución es un segmento de
círculo. La superficie se escribirá de la forma $S = \{x \in \R: \phi(x_1, x_2, x_3) = 0\}$ y el
funcional a minimizar se corresponde con
\[L[y] = \int_{x_0}^{x_1} \sqrt{y_1'(x)^2 + y_2'(x)^2 +y_3'(x)^2} \diff x\] para cualquier
$y \in \mathcal{C}^1([x_0, x_1], \R^3)$ tal que $\phi(y) = 0$.

Como vemos el funcional a minimizar depende de varias funciones. Esto lo formalizamos considerando
$n \in \N$ y $F : [x_0, x_1] \times \Omega \to \R$ de manera que el funcional a minimizar viene dado
por
\[\mathcal{F}[y] = \int_{x_0}^{x_1} F(x, y_1(x), \ldots, y_n(x), y_1'(x), \ldots, y_n'(x)) \diff
  x.\]

\subsection{Ecuaciones de Euler-Lagrange}

En este punto extendemos las ecuaciones de Euler-Lagrange al problema de Lagrange.

\begin{thm}
  En el contexto actual, si $\overline{y} \in \mathcal{C}^2(x_0, x_1)$ es un mínimo de
  $\mathcal{F}$, entonces verifica el siguiente sistema de ecuaciones en derivadas parciales
  \[
    \begin{cases}
      F_{y_1} - \frac{\partial}{\partial x} F_{p_1} & = 0;\\
      & \vdots \\
      F_{y_n} - \frac{\partial}{\partial x} F_{p_n} & =  0;
    \end{cases}
  \]
  que se denomina ecuación de Euler-Lagrange.
\end{thm}

\subsection{Restricciones de tipo algebraico}

En este punto añadiremos ligaduras de tipo algebraico $\varphi_j(y_1, \ldots, y_n) = 0$, donde
$j \in \{1, \ldots, m\}$ y $m < n$. Definimos
\[\mathcal{D}_\varphi = \{y_i \in \mathcal{C}^1(x_0, x_1): y_i(x_0) = y_{i0}, y_i(x_1) = y_{i1},
  \mathrm{Im}(y, y') \subset \Omega, \varphi_j(y_1, \ldots, y_n) = 0\}.\]

El problema variacional a resolver consiste en hallar el mínimo de $\mathcal{F}(y)$ en
$\mathcal{D}_\varphi$. Amén de una posible sustitución (despejar alguna $y_i(x)$ en función de las
otras), vamos a generalizar el método de los multiplicadores de Lagrange.

 Definimos la función
\[F^* = F + \sum_{j = 1}^m \lambda_j(x) \varphi_j(y_1, \ldots, y_n)\] y el funcional
$\mathcal{F}^* = \int F$.

El siguiente resultado nos proporciona una propiedad e los mínimos de $\mathcal{F}$.

\begin{thm}
  Si $\overline{y}$ es un mínimo de $\mathcal{F}$ en $\mathcal{D}_\varphi$, entonces existen $m$
  funciones $\lambda_1(x), \ldots, \lambda_m(x)$, denominadas multiplicadores de Lagrange, tales que
  en $\overline{y}$ se cumplen
  \[
    \begin{cases}
      \mathcal{F}_{y_1}^* - \frac{\partial}{\partial x} \mathcal{F}_{p_1}^* = 0; \\
      \vdots \\
      \mathcal{F}_{y_n}^* - \frac{\partial}{\partial x} \mathcal{F}_{p_n}^* = 0; \\
      \varphi_1(y_1, \dots, y_n) = 0; \\
      \vdots \\
      \varphi_1(y_1, \dots, y_n) = 0.
    \end{cases}
  \]
  A las soluciones de estas ecuaciones se les llaman extremales de $\mathcal{F}^*$.
\end{thm}
\begin{proof}
  Véase [Elsgoltz].
\end{proof}

\subsection{Restricciones de tipo algebraico-diferencial}

Abordamos el problema generalizado incluyendo restricciones sobre las derivadas
$\varphi_j(y_1, \ldots, y_n) = 0$, para $j \in \{1, \ldots, m\}$ y $m < n$. Esto es, consideramos
\[\mathcal{D}_\varphi' = \{y \in \mathcal{C}^1(x_0, x_1): y_i(x_0) = y_{i0}, y_i(x_1) = y_{i1},
  \mathrm{Im}(y, y') \subset \Omega, \varphi_j(y_1, \ldots, y_n, y_1', \ldots, y_n') = 0 \}.\]

\begin{prop} \label{prop:ml:ad}
  Sea $\overline{y} \in \mathcal{C}^2 \cap \mathcal{D}_\varphi'$ mínimo de $\mathcal{F}$ en
  $\mathcal{D}_\varphi'$. Existen $m$ funciones $\lambda_1(x), \ldots, \lambda_m(x)$, denominadas
  multiplicadores de Lagrange, tales que en $\overline{y}$ se cumplen
  \[
    \begin{cases}
      \mathcal{F}_{y_1}^* - \frac{\partial}{\partial x} \mathcal{F}_{p_1}^* = 0; \\
      \vdots \\
      \mathcal{F}_{y_n}^* - \frac{\partial}{\partial x} \mathcal{F}_{p_n}^* = 0; \\
      \varphi_1(y_1, \dots, y_n, y_1', \ldots, y_n') = 0; \\
      \vdots \\
      \varphi_1(y_1, \dots, y_n, y_1', \ldots, y_n') = 0.
    \end{cases}
  \]
  A las soluciones de estas ecuaciones se les llaman extremales de $\mathcal{F}^*$.
\end{prop}

\subsection{Restricciones de tipo integral}

En este apartado consideramos restricciones de tipo integral.
\[\mathcal{D}_G = \{y \in \mathcal{C}^1(x_0, x_1): y_i(x_0) = y_{i0}, y_i(x_1) = y_{i1},
  \mathrm{Im}(y, y') \subset \Omega, \int_{x_0}^{x_1}G_j(y_1, \ldots, y_n, y_1', \ldots, y_n') = L_j
  \ \forall j \in \{1, \ldots, m\},\] donde $m \in \N$.

\begin{thm}[Ligaduras integrales] \label{thm:el:ri} Sea
  $\overline{y} \in \mathcal{C}^2 \cap \mathcal{D}_G$ mínimo de $\mathcal{F}$ en
  $\mathcal{D}_G$. Existen $m$ constantes $\lambda_1, \ldots, \lambda_m$, denominadas
  multiplicadores de Lagrange, tales que, para
  $F^* = F + \sum_{j = 1}^m \lambda_j G_j(x, y_1, \ldots, y_n, y_1', \ldots, y_n')$, en
  $\overline{y}$ se cumplen las ecuaciones
  \[
    \begin{cases}
      \mathcal{F}_{y_1}^* - \frac{\partial}{\partial x} \mathcal{F}_{p_1}^* = 0; \\
      \vdots \\
      \mathcal{F}_{y_n}^* - \frac{\partial}{\partial x} \mathcal{F}_{p_n}^* = 0; \\
      \int_{x_0}^{x_1} G_1(y_1, \dots, y_n, y_1', \ldots, y_n') = L_1; \\
      \vdots \\
      \int_{x_0}^{x_1} G_1(y_1, \dots, y_n, y_1', \ldots, y_n') = L_m.
    \end{cases}
  \]
  A las soluciones de estas ecuaciones se les llaman extremales de $\mathcal{F}^*$.
\end{thm}
\begin{proof}
  Defino el funcional $\widetilde{F}[y, z_1, \ldots, z_m] = \mathcal{F}[y]$, que depende de $n+m$
  funciones, y lo considero sobre el conjunto
  \[\mathcal{D}_\varphi' = \{y \in \mathcal{D}, z_j \in \mathcal{C}^1([x_0,x_1]), z_j(x_0) = 0,
    z_j(x_1) = L_j, \varphi_j = G_j(x, y_1, \ldots, y_n, y_1', \ldots, y_n') - z_j'= 0\}.\] Nótese
  que estas restricciones sobre $z_j$ equivalen a
  \[L_j = z_j(x_1) = \int_{x_0}^{x_1} G_1(y_1, \dots, y_n, y_1', \ldots, y_n').\] Aplicamos la
  Proposición \ref{prop:ml:ad}, obteniendo para
  $\widetilde{\mathcal{F}}^* = F + \sum_{j = 1}^m \lambda_j(x)(G_j - z_j')$ las ecuaciones
  \[\widetilde{\mathcal{F}}_{y_1}^* - \frac{\partial}{\partial x} \widetilde{\mathcal{F}}_{p_1}^*\]
  para $i = 1, \ldots, n$ y las ecuaciones
  \[0 - \frac{\partial}{\partial x} \widetilde{\mathcal{F}}_{z_j}^* = 0\] para $j = 1, \ldots,
  m$. Estas últimas ecuaciones equivalen a $\lambda_j'(x) = 0$, esto es, las funciones $\lambda_j$
  son constantes. La demostración finaliza al comprobar que las ecuaciones obtenidas son las mismas
  que las del enunciado.
\end{proof}

\begin{ex}[Problemas isoperimétricos]
  Se trata de maximizar el área que pueda encerrar una cuerda de longitud prefijada. Modelizamos la
  cuerda como una curva $\alpha: [t_0, t_1] \to \R^2$ de clase $1$, que escribimos
  $\alpha(t) = (x(t), y(t))$, verificando $\alpha(t_0) = \alpha(t_1)$. La longitud de la curva viene
  dada por $\ell(\alpha) = \int_{t_0}^{t_0} \sqrt{x'(t)^2 + y'(t)^2} \diff t$. Por el teorema de
  Stokes obtenemos que
  \[\mathrm{Area}(\alpha) = \int_\Omega 1 \diff x = \frac{1}{2} \int_{t_0}^{t_1}(x(t) y'(t) -
    y(t)x'(t))\diff t.\] Buscamos maximizar el funcional
  \[\mathcal{F}[x, y] = \int_{t_0}^{t_1} \frac{x(t) y'(t) - y(t)x'(t)}{2} \diff t\]
  sobre
  \[\mathcal{D}_G = \{x, y \in \mathcal{C}^1([0,1]): x(0) = x(1), y(0) = y(1), \int_0^1
    \sqrt{x'(t)^2 + y'(t) ^2 = L}\}.\] Definimos $F(x,y,p,q) = (xq-yp)/2$ y
  $G(x,y,p,q) = \sqrt{p^2 + q^2}$. Aplicamos el Teorema \ref{thm:el:ri}, obteniendo las ecuaciones
  \begin{equation*}
    \label{eq:1}
    \begin{cases}
      -\frac{x'}{2} - \frac{\partial}{\partial t} \left(\frac{x}{2} + \lambda \frac{y'}{\sqrt{x'^2 + y'^2}}\right) = 0; \\
      -\frac{y'}{2} - \frac{\partial}{\partial t} \left(\frac{y}{2} + \lambda \frac{x'}{\sqrt{x'^2 +
            y'^2}}\right) = 0;
    \end{cases}
  \end{equation*}
  que se simplifican en
  \begin{equation*}
    \label{eq:1}
    \begin{cases}
      x - \lambda \frac{y'}{\sqrt{x'^2 + y'^2}} = x_0; \\
      y - \lambda \frac{x'}{\sqrt{x'^2 + y'^2}} = y_0. \\
    \end{cases}
  \end{equation*}
  Veamos que la solución es una circunferencia de centro $(x_0, y_0)$. En efecto,
  \[(y-y_0)^2 + (x-x_0)^2 = \left(\lambda \frac{y'}{\sqrt{x'^2 + y'^2}}\right)^2 + \left(\lambda
      \frac{x'}{\sqrt{x'^2 + y'^2}}\right)^2 = \lambda^2\] y el radio es el multiplicador de
  Lagrange $\lambda$. Por tanto, de tener solución el problema y ser ésta de clase 2, entonces es la
  circunferencia. En el futuro probaremos que efectivamente se verifican estos hechos con el Teorema
  de Lax-Milgram.
\end{ex}

\begin{ex}[Problema de la Catenaria]
  Fijada una longitud $L > 1$ de ante mano, buscamos la curva $y$ de longitud $L$ que encontramos al
  fijar los extremos de una cuerda en los puntos $(0,h)$ y $(1, h)$ y someterla a la acción de la
  gravedad.  Tras plantear el problema mediante razonamientos físicos obtenemos que hay que
  minimizar el funcional
  \[\mathcal{F}[y] = \int_0^1 y(x) \sqrt{1 + y'(x)^2},\]
  que mide la energía potencial de la cuerda, y está definido sobre el conjunto
  \[\mathcal{D}_G = \{y \in \mathcal{C}^1([0,1]): y(0) = y(1) = h, \int_0^1 \sqrt{1 + y'(t)^2}
    = L > 1\}.\]

  Aplicamos los multiplicadores de Lagrange para restricciones de tipo integral. Tenemos
  $F^{*} = y \sqrt{1+p^2} + \lambda \sqrt{1+p^2}$. La ecuación de Euler-Lagrange equivale a las
  ecuaciones
  \[C = F^{*} - y' F_p^{*} = (y+\lambda)\sqrt{1+p^2} - p(y+\lambda) \frac{p}{\sqrt{1+p^2}}\] para
  $C > 0$. Esta ecuación se simplifica en
  \[y = C \sqrt{1+(y')^2} - \lambda.\] Para resolver esta ecuación, en primer lugar, buscamos las
  posibles soluciones constantes. Nótese que la única solución constante es $y = C-\lambda$. No
  obstante, estas soluciones están en $\mathcal{D}_G$. Para encontrar las soluciones no constantes
  realizamos el cambio de variable $y' = \sinh(t)$. Obtenemos la ecuación
  \[y = C \cosh(t) - \lambda.\] Sea $x = x(y)$ una función que depende de $y$. Tenemos que $x$
  verifica la ecuación
  \[x = \int\limits^{y} \frac{1}{y'(x(y))} \diff y = \int \frac{C\sinh(t)}{\sinh(t)} \diff t =
    Ct+K.\] Tenemos que $t = (x-k) / t$ y, por tanto, $y = C \cosh((x-k)/C) - \lambda$.  NO ENTIENDO
  NADA DE ESTOS CAMBIOS...

  Ahora, fijada $y = C \cosh((x-k)/C) - \lambda$, imponemos las condiciones de Dirichlet y la
  restricción integral. De las primeras condiciones obtenemos que $\cosh(-k/C) =
  \cosh((1-k)/C)$. Esto se produce si, y solo si, $|k/C| = |(1-k)/C|$, de donde deducimos que
  $k = 1/2$. Además,
  \[L = \int\limits_0^1 \sqrt{1+\sinh(\frac{2x-1}{2C})^2} \diff x = \int\limits_0^1
    \cosh(\frac{2x-1}{2C}) \diff x = 2C\sinh(\frac{1}{2C}).\] Esta ecuación en función de $C$ tiene
  una única solución. Por tanto, solo hay una extremal válida para el problema que viene dada por
  $y = C \cosh((x-0.5)/C) - \lambda$. De la condición $y(0) = h$ obtenemos el valor de $\lambda$.
\end{ex}

\section{Problemas de Sturm-Liouville}

En esta sección relacionamos los problemas de Sturm-Liouville con los PV con restricciones
integrales. En primer lugar vemos un ejemplo que motiva el estudio de los problemas de
Sturm-Lioville.

\begin{ex}
  Sea $L > 0$. Busca los valores de $\lambda \in \R$ para los cuales el problema de contorno
  
  \begin{equation}
    \label{eq:ex:sl}
    \begin{cases}
      y'' + \lambda y = 0; \\
      y(0) = 0; \\
      y(L) = 0;
    \end{cases}
  \end{equation}
  tiene soluciones no nulas y di cuáles son esas soluciones.

  Procedemos como es habitual. El polinomio de la EDO es $P(\mu) = \mu^2 + \lambda$.  Distinguimos
  tres casos.
  \begin{enumerate}
  \item El número $\lambda$ es negativo. Entonces las raíces de $P$ son $\mu_+ = \sqrt{-\lambda}$ y
    $\mu_- = -\sqrt{-\lambda}$, que son reales. Por tanto, las soluciones de la EDO vienen dadas por
    \[y(x) = A e^{\mu_+ x} + B e^{\mu_- x},\] donde $A,B \in \R$. Imponemos las condiciones de
    contorno a la solución general. Obtenemos el sistema
    \begin{equation}
      \begin{cases}
        A + B  = 0; \\
        A e^{\mu_+ L} + B e^{\mu_- L} = 0;
      \end{cases}
    \end{equation}
    que tiene solución única.
  \item El número $\lambda$ es $0$. En tal caso, las soluciones son las rectas. Al imponer las
    condiciones iniciales obtenemos que la única solución es $y = 0$.
  \item El número $\lambda$ es positivo. En tal caso las raíces de $P$ son $\mu_+ = i\sqrt{\lambda}$
    y $\mu_- = -i\sqrt{\lambda}$. Por tanto, la solución general de la ecuación es
    \[y(x) = A \cos(\sqrt{\lambda}x) + B \sin(\sqrt{\lambda} x),\] donde $A,B \in \R$. Imponemos las
    condiciones de contorno a la solución general. Obtenemos el sistema
    \begin{equation}
      \begin{cases}
        A  = 0; \\
        A \cos(\sqrt{\lambda}L) + B \sin(\sqrt{\lambda}L) = 0;
      \end{cases}
    \end{equation}
    que tiene solución única si, y solo si, $\sin(\sqrt{\lambda}L) \ne 0$, lo que sucede si, y solo
    si, $\lambda \ne (n \pi / L)^2$ para cualquier $n \in \N$. En tal caso, la solución es $A = 0$ y
    $B = 0$. Si por el contrario, $\lambda = (n \pi / L)^2$ para cierto $n \in \N$, entonces
    obtenemos una recta de soluciones, que son los múltiplos de
    \[y_n(x) = \sin(\frac{n \pi x}{L}). \qedhere\]
  \end{enumerate}
\end{ex}


\begin{definition}
  Un problema de Sturm-Liouville consiste en encontrar los valores $\lambda \in \R$ para los cuales
  el problema de contorno
  \begin{equation}
    \label{eq:sl:pc}
    \begin{cases}
      (Py')' + (Q + \lambda S) y = 0; \\
      a_0 y(x_0) + b_0 y'(x_0) = 0; \\
      a_1 y(x_1) + b_1 y'(x_1) = 0;
    \end{cases}
    \tag{SL}
  \end{equation}
  donde $P, Q, S$ son continuas, $P$ es de clase $1$ y $P, S > 0$.  A los valores $\lambda$ los
  llamamos valores propios asociados al problema de Sturm-Liouville y a las soluciones no nulas de
  \eqref{eq:sl:pc} funciones propias.
\end{definition}

Vamos a utilizar el Teorema de Sturm-Lioville, que no demostraremos por la dificultad de la
demostración.

Las soluciones del problema de Sturm-Liouville son elementos del espacio de Hilbert
\[L^{2}_S(x_0, x_1) = \left\{y \in L(x_0, x_1): \int\limits_{x_0}^{x_1} y^2(x) S(x) \diff x <
    +\infty\right\},\]
cuyo producto escalar es
\[\left\langle y, z \right\rangle = \int\limits_{x_0}^{x_1} y(x) z(x) S(x) \diff x.\]

\begin{theorem}[Sturm-Liouville]
  \label{thm:sl}
  Los valores propios del problema de Sturm-Liouville forman una sucesión $\{\lambda_n\}$ creciente
  que diverge positivamente. Las funciones propias normalizadas quedan determinadas de forma única
  salvo el signo y verifican:
  \begin{enumerate}
  \item\label{item:sl:a} Tienen exactamente $n-1$ ceros en $[x_0, x_1]$.
  \item\label{item:sl:b} Son ortogonales dos a dos.
  \item\label{item:sl:c} Cualquier otra función en $L^{2}_S(x_0, x_1)$ admite un desarrollo en
    funciones propias, eso es,
    \[y(x) = \sum\limits_{n \ge 0|} \left\langle y, y_n \right\rangle y_n(x).\]
  \end{enumerate}
\end{theorem}

Sea $\mathcal{D} = \{y \in L^2: y \in \mathcal{C}^{2}\}$ y $L: \mathcal{D} \to L_S^2$ dado por $L[y] = ((Py')' + Q y) / S$. Tenemos que
\[ \left\langle y, L(z) \right\rangle  = \int_{x_0}^{x_1} y((P z')' + Q z) \diff x = -\int_{x_0}^{x_1} Py'z' + \int_{x_0}^{x_1} y Q z \diff x = \left\langle L y, z \right\rangle.\]
Consecuentemente, $L$ es un funcional autoadjunto. No sabemos de momento si es continuo.


\subsection{Relación con PVs}

Consideramos el funcional
\[\mathcal{F}[y] = \int\limits_{x_0}^{x_1} (P(x) y'(x)^2 + Q(x) y(x)^2) \diff x.\]
Buscamos su mínimo en $y \in \mathcal{C}^{2}$ con $y(x_0) = 0 = y(x_1)$ con restricción de tipo
$\int\limits_{x_0}^{x_1}y(x)^2 S(x) \diff x = 1$. Tenemos que $F(x,y,p) = P p^2 - Q y^2$. Utilizando
el Teorema \ref{thm:el:ri} encontramos $\lambda \in \R$ y
$F^{*}(x,y,p) = P p^2 - Q y^2 + \lambda y^2 S$ tal que las soluciones del problema verifican las
ecuaciones

\[
  0 =\mathcal{F}_{y}^* - \frac{\partial}{\partial x} \mathcal{F}_{p}^* = -2 \left[ (P y')' + (Q+\lambda S) y \right], \\
\]
y, por tanto, las extremales del problema son soluciones de un problema de Sturm-Liouville. El
objetivo es buscar los valores propios y las funciones propias del problema.

  \begin{theorem}
    En el contexto actual, sean $(\lambda_n, y_n)$ los valores y funciones propios del problema de
    Sturm-Liouville asociado al funcional
    \[\mathcal{F}[y] = \int\limits_{x_0}^{x_1} P(x)(y'(x))^{2} - Q(x)y(x)^{2} \diff x.\]
    Fijado $n \in \N$, el mínimo del funcional $\mathcal{F}$ en el conjunto
    \[\mathcal{D}_{n-1} = \{y \in \mathcal{C}^{2}(x_0, x_1) \text{ con c.c. separadas y
        restricciones de tipo integral }\]
    \[\int\limits_{x_0}^{x_1}y(x)^2 S(x) \diff x = 1, \int\limits_{x_0}^{x_1}y_1(x) y(x) S(x) \diff
      x = 0, \ldots, \int\limits_{x_0}^{x_1}y_{n-1}(x) y(x) S(x) \diff x = 0 \}\]

    es $y_n$ y verifica $\mathcal{F}[y_n] = \lambda_n$.
  \end{theorem}

  \begin{ex}
    Calcula el mínimo de
    \[\mathcal{F}[y] = \int\limits_{1}^{e} x(y'(x))^2 \diff x\]
    en
    \[\mathcal{D} = \left\{y \in \mathcal{C}^{1}(1, e): y(1) = 0 = y(e), \int\limits_{x_0}^{x_1}y(x)^2
    / x \diff x = 1, \int\limits_{x_0}^{x_1} \sin(\pi \log(x)) y(x) S(x) \diff x = 0 \right\}.\]
  \end{ex}

  \section{Funcionales de funciones que dependen de varias variables}

  Sea $\Omega \subset \R$ abierto conexto y $\gamma : \overline{\Omega} \to \R$ continua. Sea además
  $F : D \to \R$ con $D = \Omega \times W \subset \R^5$, $F(x,u,p,q)$. Consideramos el funcional
  \[\mathcal{F}[u] = \int_{\Omega} F(x, u(x), u_{x_1}(x), u_{x_2}(x)) \diff x\]

  definido en
  $\mathcal{D} = \{u \in \mathcal{C}^{2}(\Omega): u(x) = \gamma(x) \ \forall x\in\partial\Omega
  [restriciones del conjundo D]\}$. Podemos adaptar el Teorema \ref{thm:el} en este contexto para
  obtener una nueva ecuación de Euler-Lagrange
  \begin{equation}
    \label{eq:el:general}
    F_u - \frac{\partial}{\partial x_1} F_p - \frac{\partial}{\partial x_2} F_q = 0.
  \end{equation}

\begin{ex}[La membrana vibrante] \label{ex:membrana}
  Se trata de modelar la posición de una membrana (película elástica homogénea) sometida a fuerzas
  verticales. EN equilibrio, suponemos que $(x,\varphi(x))$ describe su posición, donde
  $\varphi: \overline{\Omega} \subset \R^2 \to \R$ con $\varphi \in \mathcal{C}^2$. Supongamos que
  solo hay desplazamientos verticales y llamo $(x, u(t,x))$ a la posición en tiempo $t$, con
  $u(t,x) = \varphi(x)$. Por el \emph{principio de Halminton} los físicos obtienen que la solución
  al problema minimiza la energía el sistema, esto es, minimiza el siguiente funcional
  \[ \mathcal{F}[u] = \int_{0}^{+\infty}\left(\int\limits_{\Omega} (E_k[u] - E_p[u]) \diff x
    \right)\diff t, \] donde $E_k[u] = \frac{\partial}{\partial t} u(t,x)^2/ 2$ es la energía
  cinética mientras que $E_p[u]$ es la energía potencial en el punto $x$. Tras desarrollar las
  expresiones físicas que aparecen en el funcional obtenemos un modelo muy complejo que no merece la
  pena estudiar a mi criterio. Tras varias simplificaciones de este funcional obtenemos
  \[ \mathcal{F}[u] = \frac{1}{2} \int\limits_{\Omega} \left(\sigma (\nabla u)^2 + \alpha u^2 -
    2f(x) u \right) \diff x \]

  en $\mathcal{D} = \{u \in \mathcal{C}^1(\overline{\Omega}) \mid u = 0 \text{ en } \Omega\} =
  \mathcal{C}_0^1(\Omega)$, donde $\sigma$ y $\alpha$ son constantesy $f$ es una función en
  $x$. Escribiendo la ecuación de Euler - Lagrange asociada a este PV obtenemos la denominada ecuación
  de la membrana
  \[ -\mathrm{div}(\sigma(x)\nabla u) = - \alpha(x)u + f, \]

  donde $\mathrm{div}(G) = \frac{\partial}{\partial x_{1}} G_1 + \cdots + \frac{\partial}{\partial x_{n}} G_n$.

  [AÑADIR DEL PAPEL DEL AMIGO JUANJO].
\end{ex}
l
\subsection{Resolución de la ecuación de ondas}

En el Ejemplo \ref{ex:membrana} hemos obtenido la ecuación de Ondas como ecuación de Euler-Lagrange de un PV. En esta sección vamos a resolver la ecuación de ondas en casos particulares.

\subsubsection{Caso 1}

\begin{equation}
\label{eq:ondas:1}
  \begin{cases}
    u_{tt} = c^2 u_{xx}, \quad t \ge 0, x \in \R; \\
    u(0,x) = u_0(x); \\
    u_t(0,x) = v_0(x).
  \end{cases}
\end{equation}

Hacemos el cambio de variable $\xi = x + ct$, $\eta = x -ct$. Consideramos la función $U(\xi, \eta) = u(t,x) = u( (\xi-\eta)/(2c), (\xi+\eta)/2)$. Por la regla de la cadena obtenemos que
\[ u_{tt} = c^{2} U_{\xi \xi} + c^2 U_{\eta \eta} - 2c^2 U_{\xi \eta}; \]
\[ u_{xx} = U_{\xi \xi} +  U_{\eta \eta} +2 U_{\xi \eta}; \]
Por tanto, de \eqref{eq:ondas:1} deducimos que $U_{\xi \eta} = 0$. Esto equivale a que $U(\xi, \eta) = g(\xi) + h(\eta)$ para ciertas funciones $g$ y $h$ de clase $2$. Por tanto, obtenemos que $u(t,x) = g(x+ct) + h(x-ct)$. Imponiendo las condiciones iniciales obtenmemos $g(x)+h(x) = u_0(x)$ y $cg'(x)-ch'(x) = v_0(x)$. En particular, $g'(x) + h'(x) = u_0'(x)$, de donde deducimos que
\[
  \begin{cases}
    g'(x) = (v_0(x) + c u_0'(x)) / (2c); \\
    h'(x) = (c u_0'(x) - v_0(x)) / (2c).    
  \end{cases}
\]
Intengrando obtenemos una expresión para $g$ y $h$
\[
  \begin{cases}
    g(x) = u_0(x) / 2 + \int\limits_{0}^{x} v_0(x) / (2c) \diff x + K_1; \\
    h(x) = u_0(x) / 2 - \int\limits_{0}^{x} v_0(x) / (2c) \diff x + K_2;
  \end{cases}
\]

Sumando y comprobando que las constantes se anulan obtenemos la fórmula de D'Alembert
\begin{equation}
\label{eq:onda:dalembert}
u(t,x) = \frac{u_0(x+ct) + u_0(x-ct)}{2} + \frac{1}{2c} \int_{x-ct}^{x+ct} v_0(y) \diff y.
\end{equation}

\subsubsection{Caso 2}

Sea $c > 0$ la velocidad de la onda.
\begin{equation}
  \label{eq:ondas:2}
  \begin{cases}
    u_{tt} = c^2 u_{xx}, \quad t \ge 0, x \in [0,L]; \\
    u(0,x) = u_0(x); \\
    u_t(0,x) = v_0(x); \\
    u(t,L) = u(t,0) = 0 \quad \forall t \ge 0.
  \end{cases}
\end{equation}

Añadimos además las siguientes condiciones de combatibilidad
\[
  \begin{cases}
    u_0(0) = u_0(L) = 0; \\
    u_0''(0) = u_0''(L) = 0; \\
    v_0(0) = v_0(L) = 0. \\
  \end{cases}
\]

Buscamos soluciones no nulas de la forma $u(t,x) = T(t) W(x)$. De existir una solución de esta forma
se verificará
\[ u_{tt} = T''(t) W(x) \text{ y } u_{xx} = T(t) W''(x). \] Puesto que $u_{tt} = c^2 u_{xx}$,
suponiendo que $T$ y $W$ no se anulan ontenemos que
\[ \frac{T''(t)}{T(t)} = c^2 \frac{W''(x)}{W(x)}. \] Por tanto, las funciones $T''/T$ y $W''/W$ son
iguales a una constante $\lambda$. Esto es, se verifican las ecuaciones diferenciales
\[
  \begin{cases}
    T''(t) + \lambda T(t) = 0; \\
    W''(x) + \frac{\lambda}{c^2} W(t) = 0.
  \end{cases}
\]

Empezamos resolviendo la ecuación de $W$. De las condiciones de contorno del problema deducimos que
$T(t)W(0) = 0$ para todo $t \ge 0$. Puesto que hemos supuesto que $T$ no se anula tenemos que
$W(0) = 0$. Análogamente deducimos que $W(L) = 0$. Distinguimos tres casos.
\begin{enumerate}
\item Se tiene $\lambda < 0$. En tal caso
  $W(x) = A \exp(\sqrt{-\lambda} x / c) + B \exp(\sqrt{\lambda} x / c)$. No obstante, las
  condiciones de contorno obligan a que $A = B = 0$, luego la única solucióne es la constantemente
  cero, que hemos descartado previamente.
\item Se tiene $\lambda = 0$. Análogamente la única solución del problema de contorno es la
  constantemente $0$.
\item Se tiene $\lambda > 0$. Las soluciones son de la forma
  $W(x) = A \sin(\sqrt{\lambda} x / c) + B \cos(\sqrt{\lambda} x / c)$. De $W(0) = 0$ deducimos que
  $A = 0$. De $W(L) = 0$ deducimos que o bien $B = 0$, solución que hemos descartado, o bien
  $\sin(\sqrt{\lambda} L / c) = 0$, esto es, $\lambda = (n \pi c / L)^{2}$ para algún $n \in \N$, en
  cuyo caso las soluciones son múltiplos de $\sin(n \pi x / L)$.
\end{enumerate}

Hemos deducido que la ecuación tiene solución no nula solamente para los valores
$\lambda_n = (n \pi c / L)^{2}$. Resolvemos ahora la ecuación asociada a $T$ para estos valores de
$\lambda$. Obtenemos que $T(t) = A \cos(n c \pi x / L) + B \sin(n c \pi x / L)$. Obtenemos pues que
la solución de la ecuación diferencial debe ser de la forma
\begin{equation}
  \label{eq:2}
  u(t,x) = \sin(n \pi x / L) \left(A \cos(n c \pi x / L) + B \sin(n c \pi x / L)\right).
\end{equation}

Es fácil comprobar que estas funciones son soluciones de la ecuación. Veamos si verifican las
condiciones iniciales en el tiempo. Tenemos que $u(0, x) = A \sin(n \pi x / L)$ y
$u_t(0,x) = B n c \pi \sin(n \pi x / L) / L$. Estas funciones pueden no ser iguales a las funciones
$u_0$ y $v_0$. Lo solucionamos mediante el desarrollo wn serie de Fourier. Por las condiciones de
compatibilidad obtenemos que $u_0(x) = \sum_{n \ge 1} A_n \sin(n \pi x / L)$. Análogamente
$v_0(x) = \sum_{n \ge 1} C_n \sin(n \pi x / L)$.

\begin{remark}[Principio de superposición]
  Una suma, finita o infinita con convergencia uniforme, de soluciones de la ecuación
  \eqref{eq:ondas:2} es solución de la ecuación \eqref{eq:ondas:2}.
\end{remark}

Si conseguimos esta convergencia uniforme de la serie de Fourier obtenemos que
$u(t,x) = \sum_{n \ge 1} u_n(t,x)$ es solución de \eqref{eq:ondas:2} y verifica todas las
condiciones del problema.

\begin{ex}
  Consideramos el problema de contorno
  \begin{equation}
    \label{eq:ondas:3}
    \begin{cases}
      u_{tt} - u_{xx} = x, \quad t \ge 0, x \in [0,1]; \\
      u(t, 0) = 0 \text{ y }
      u(t, 1) = 1; \\
      u(0,x) = x; \\
      u_t(0, x) = 0.
    \end{cases}
  \end{equation}
  Utilizamos las soluciones del problema homogéneo, que es un caso particular de la ecuación de
  Ondas \eqref{eq:ondas:2}. Sea $\omega$ una solución del problema homogéneo y
  $u(t,x) = \omega(t,x) + v(x)$. Tenemos que $u$ es solución de \eqref{eq:ondas:3} si, y solo si,
  $- v''(x) = x$, $v(0) = 0$, $v(1) = 1$ y se verifican las condiciones de contorno en
  $x$. Deducimos que debe tenerse $v(x) = (7 x - x^3) / 6$, $\omega(0,x) = (x^3-x) / 6$,
  $\omega_t(0,x) = 0$. Podemos encontrar tal $\omega$ mediante una serie de Fourier como se hizo
  anteriormente.
\end{ex}

En los siguientes párrafos introducimos los conceptos de análisis funcional que necesitamos para
completar el desarrollo
anterior. %En primer lugar, recordemos que el siguiente conjunto de funciones es un sistema ortonormal de $\mathrm{L}^2(0,T)$,

\begin{theorem}[Riesz-Fischer, 1907]
  \label{thm:riesz}
  El conjunto
  \[ B = \left\{\frac{1}{\sqrt{T}}, \sqrt{\frac{2}{T}} \sin(\frac{nT}{2\pi}x), \sqrt{\frac{2}{T}}
      \cos(\frac{nT}{2\pi}x): n \in \N\right\} \] es una base de Hilbert de $\mathrm{L}^2(0,T)$.
\end{theorem}


\begin{ex}
  Consideramos el problema de contorno
  
  \begin{equation}
    \label{eq:3}
    \begin{cases}
      y'' + \lambda y = 0 \quad \text{en }[0,T]; \\
      y(0) = y(T); \\
      y'(0) = y'(T).
    \end{cases}
  \end{equation}

  Buscamos los valores propios del problema de Sturm-Liouville, esto es, los valores de $\lambda$
  para los que el problema tiene solución no trivial. Es fácil comprobar que si $\lambda < 0$,
  entonces la única solución es $y = 0$. En cambio, si $\lambda = 0$, las soluciones son las
  funciones constantes, luego $0$ es un valor propio. Por último, si $\lambda > 0$, el problema
  tiene solución si, y solo si, $\cos(T \sqrt{\lambda}) = 1$ o, equivalentemente,
  $\lambda = (2 n \pi / T)^2$ para algún $n \in \N$. En tal caso, las funciones propias son $2$ para
  cada $n \in \N$, $y_{2n} = \cos(2 n \pi x / T )$ y $y_{2n-1} = \sin(2 n \pi x / T )$.
\end{ex}

En $\mathrm{L}_2([0,T])$ la convergencia en norma no implica necesariamente la convergencia puntual
y mucho menos la convergencia uniforme. Necesitaremos criterios de convergencia que nos aseguren que
la serie de Fourier converge uniformemente. Uno de los criterios más sencillos es el criterio de
Weierstrass. En lo que sigue enunciamos los teoremas de convergencia que utilizaremos en la
asignatura.

\begin{theorem}[Teoremas de convergencia]
  \label{thm:fourier:convergencia}
  Sea $y \in \mathrm{L}_2([0,T])$ con $y(0) = y(T)$. Se verifican las siguientes afirmaciones.
  \begin{enumerate}
  \item Por el Teorema de Riesz-Fisher, la serie de Fourier de $y$ admite una parcial que converge
    c.p.d. a $y$.
  \item Si $y$ es continua, entonces la serie de Fourier de $y$ converge puntualmente a $y$.
  \item Si $y$ es continua a trozos en $[0,T]$, entonces la serie de Fourier de $y$ converge
    puntualmente a $y$ fuera de los puntos de discontinuidad. En los puntos de discontinuidad la
    serie de Fourier converge a la media de los límites laterales de $y$.
  \item Si $y$ es continua y además $y'$ es continua a trozos, entonces la serie de Fourier de $y$
    converge absoluta y uniformemente.
  \item Si $y \in \mathcal{C}^{k}([0,T])$ y $y^{m)}(0) = y^{m)}(T)$ para todo $0 \le m \le k$ e
    $y^{k+1}$ es continua a trozos, entonces la serie de las derivadas hasta orden $k$ converge
    absoluta y uniformemente a la correspondiente derivada de $y$.
  \end{enumerate}
\end{theorem}

En ocasiones necesitaremos desarrollos de Fourier en $\mathrm{L}_2([-L,L])$. Para ello podemos
transladar la función a $[0,2L]$, calcular el desarrollo de Fourier en este intervalo y volverlo a
transladar. Realizando los cálculos obtenemos que
\[ y(x) = \frac{a_0}{2} + \sum\limits_{n = 1}^{\infty} \left(a_n \cos(\frac{n \pi}{L} x) + b_n
    \sin(\frac{n \pi}{L} x)\right), \]

donde
\[ a_0 = \frac{1}{L} \int_{-L}^L y(x) \diff x; \]
\[ a_n = \frac{1}{L} \int_{-L}^L y(x) \cos(\frac{n \pi}{L}x) \diff x; \]
\[ b_n = \frac{1}{L} \int_{-L}^L y(x) \sin(\frac{n \pi}{L}x) \diff x. \]

Nótese que si la función $y$ es par, entonces $b_n = 0$ para todo $n$. En cambio, si la función $y$
es impar, entonces $a_n = 0$ para todo $n$.

Consideremos $y \in \mathrm{L}_2([0,L])$. Podemos extender $y$ a $[-L, L]$ para que sea par o impar
y aplicar los desarrollos obtenidos a la nueva función. Obtenemos pues dos nuevos desarrollos que
solamente involucran cosenos y senos respectivamente:
\begin{itemize}
\item \textbf{Serie de cosenos.} Tenemos que
  $y(x) = a_0 / 2 + \sum_{n = 1}^{\infty} a_n \cos(\frac{n \pi}{L} x)$, donde para cada $n$
  \[ a_n = \frac{1}{L} \int_{-L}^L y_{par}(x) \cos(\frac{n \pi}{L}x) \diff x = \frac{2}{L}
    \int_{0}^L y(x) \cos(\frac{n \pi}{L}x) \diff x.\]
\item \textbf{Serie de senos.} Tenemos que
  $y(x) = \sum_{n = 1}^{\infty} b_n \sin(\frac{n \pi}{L} x)$, donde para cada $n$
  \[ b_n = \frac{1}{L} \int_{-L}^L y_{par}(x) \sin(\frac{n \pi}{L}x) \diff x = \frac{2}{L}
    \int_{0}^L y(x) \sin(\frac{n \pi}{L}x) \diff x.\]
\end{itemize}

Ahora podemos aplicar los teoremas de convergencia a estas nuevas series, obteniendo el siguiente
resultado.

\begin{theorem}
  \label{thm:fourier:convergencia:2}
  Sea $y \in \mathcal{C}([0, T])$ con $y'$ continua a trozos. Entonces,
  
  \begin{enumerate}
  \item su serie de cosenos converge uniformemente;
  \item si $y(0) = y(T) = 0$, entoces la serie de senos converge.
  \end{enumerate}
\end{theorem}

Ya podemos resolver la ecuación de ondas de partida. Recogemos todos los argumentos dados en el
siguiente teorema.

\begin{theorem}
  \label{thm:ondas:2}
  Dados $u_0 \in \mathcal{C}^2(]0,1[)$ con $u_0'''$ continua a trozos y
  $v_0 \in \mathcal{C}^1(]0,L[)$ con $v_0''$ continua a trozos tales que
  \[ u_0(0) = u_0(L) = u_0''(0) = u_0''(L) = v_0(0) = v_0(L). \] El sistema
  \[
    \begin{cases}
      u_{tt} = c^2 u_{xx}, \quad t \ge 0, x \in [0,L]; \\
      u(0,x) = u_0(x), \quad x \in [0,L]; \\
      u_t(0,x) = v_0(x), \quad x \in [0,L]; \\
      u(t,0) = u(t, L) = 0, \quad t \ge 0.
    \end{cases}
  \]
  tiene una única solución dada por
  \[ u(t,x) = \sum\limits_{n = 1}^{\infty} \left( a_n \cos(\frac{n c \pi t}{L}) + \frac{b_nL}{n c
        \pi} \sin(\frac{n c \pi t}{L}) \right) \sin(\frac{n \pi x}{L}),\] donde $a_n$ y $b_n$
  provienen de las series de Hilbert de $u_0$ y $v_0$, esto es,
  \[u_0(x) = \sum\limits_{n = 1}^{\infty} a_n \sin(\frac{n \pi x}{L}) \text{ y } v_0 =
    \sum\limits_{n = 1}^{\infty} b_n \sin(\frac{n \pi x}{L}).\]
\end{theorem}
\begin{proof}
  La existencia viene dada por el procedimiento desarrollado durante la sección. Veamos qe se da la
  unicidad. Utilizamos el denominado \emph{método de la energía}. Definimos el funcional $E$ que a
  cada función $u \in \mathcal{C}^2([0,L])$ le asgina la función $E[u]$ dada por
  \[ E[u](t) = \frac{1}{2} \int_0^L \left( u_t^2 + c^2 u_x^2 \right) \diff x, \quad t \ge 0. \]
  Veamos que si $u$ es solución de la ecuación de ondas, entonces $E[u]$ es constante. En efecto,
  tenemos que
  \[ \frac{1}{2}\int_0^L \frac{\partial}{\partial t}(u_t)^2 \diff x = \int_0^L u_t u_{tt} \diff x =
    c^2\int_0^L u_t u_{xx} \diff x = \left[ u_t u_{x} \right]_0^L - c^2\int_0^L u_{tx} u_{x} \diff
    x. \]

  Deducimos pues que
  \[ \frac{\partial}{\partial t} \frac{1}{2} \int_0^L \left( u_t^2 + c^2 u_x^2 \right) \diff x =
    \frac{1}{2}\int_0^L \frac{\partial}{\partial t}(u_t)^2 \diff x + c^2\int_0^L u_{tx} u_{x} \diff
    x = \left[ u_t u_{x} \right]_0^L. \]
  
  
  Sean $u_1$ y $u_2$ dos soluciones de la ecuación de ondas. Entonces, $u = u_1 - u_2$ es solución
  del problema con todas las condiciones a cero. Utilizando la igualdad anterior tenemos que $E[u]$
  tiene derivada nula, luego $E[u](t) = E[u](0) = 0$.  $u_1 = u_2$. Deducimos pues que $u = 0$ y,
  por tanto, $u_1 = u_2$.
\end{proof}


\subsection{Solución de la ecuación de Dirichlet}

NO EXAMEN.

Vamos a resolver la ecuación de Dirichlet utilizando la técnica de separación de variables, que
hemos utilizado para la ecuación de ondas. Recordemos que la ecuación de Dirichlet viene dada por

\begin{equation}
  \label{eq:dirichlet}
  \begin{cases}
    \Delta u = 0 \quad \text{en } \Omega; \\
    u = \gamma \quad \text{en } \partial \Omega.
  \end{cases}
\end{equation}

\subsubsection{Laplaciano en polares}

Realizamos un cambio a polares, $u(x_1,x_2) = U(\rho, \theta)$. Obtenemos la expresión denominada
\emph{Laplaciano en polares}

\begin{equation}
  \label{eq:laplaciano:polares}
  U_{pp} + \frac{U_{\theta\theta}}{\rho^2} + \frac{U_{\rho}}{\rho} = \Delta_x u(\rho \cos(\theta), \rho \cos(\theta)).
\end{equation}

Si la función $u$ es racial, esto es, $u(x) = U(\rho)$ para todo $x \in \Omega$, entonces la
expresión del Laplaciano en polares se simplifica, obteniendo

\begin{equation}
  \label{eq:laplaciano:radial}
  \Delta_x u(x) = U_{pp} + \frac{U_{\rho}}{\rho} = \frac{1}{\rho^{N-1}} \frac{\partial}{\partial \rho}(\rho^{N-1} U_{\rho}),
\end{equation}

donde $N$ es el número de variables de $u$.

\subsubsection{La ecuación de Dirichlet para funciones radiales}

Aplicando lo anterior para $u$ radial obtenemos que la ecuación de Dichlet equivale a

\begin{equation}
  \label{eq:4}
  \rho^{N-1} U_{\rho} = \mathrm{cte}.
\end{equation}

Obtenemos pues que todas las soluciones de la ecuación son de la forma

\[ u(x) =
  \begin{cases}
    C_1 |x| & \text{si} N = 1; \\
    C_2 \log |x| & \text{si} N = 2; \\
    C_3 / |x|^{N-1} & \text{si} N \ge 3,
  \end{cases}
\]

que es la llamada \emph{solución fundamental del laplaciano en $\R^N$}

\subsubsection{La ecuación de Dirichlet en el disco}

Nos proponemos resolver \eqref{eq:dirichlet} en el disco unidad.  Utilizando el Laplaciano en polares obtenemos el problema equivalente

\begin{equation}
\label{eq:dirichlet:disco}
\begin{cases}
  U_{pp} + \frac{U_{\theta\theta}}{\rho^2} + \frac{U_{\rho}}{\rho} = 0, & (\rho, \theta) \in ]0,1]\times[0,2\pi]; \\
  U(1, \theta) = \overline{\gamma}(\theta), & \theta \in [0, 2\pi]; \\
  U(\rho, 0) = U(\rho, 2\pi), & \rho \in ]0, 1].
\end{cases}
\end{equation}

Separamos variables. Buscamos $U(\rho, \theta) = v(\rho) w(\theta)$.  En tal caso se verifica la ecuación

\begin{equation}
\label{eq:dirichlet:disco:sep}
v''(\rho) w(\theta) + \frac{v(\rho)}{\rho^2} w''(\theta) + \frac{v'(\rho)}{\rho}w(\theta) = 0,
\end{equation}

de donde deducimos que

\begin{equation}
  \label{eq:dirichlet:disco:sep:2}
  \frac{w''(\theta)}{w(\theta)} = -\frac{\rho^2 v''(\rho) + \rho v'(\rho)}{v(\rho)} = -\lambda \cong \mathrm{cte}.
\end{equation}


\section{Derivadas generalizadas}

\begin{theorem}[Fórmula de Green]
  \label{thm:green}
  Sea $\Omega \subset \R^n$ dominio y sean $u, v \in \mathcal{C}^1(\overline{\Omega})$. Entonces
  \[ \int_{\Omega} u(x) \frac{\partial}{\partial x_i} v(x) \diff x = - \int_{\Omega}
    \frac{\partial}{\partial x_i} u(x) v(x) \diff x + \int_{\Omega} u(x)v(x) \diff s. \]
\end{theorem}

Sea $f \in \mathcal{C}^1(\overline{\Omega})$. Para cada
$\phi \in \mathcal{C}_0^\infty(\Omega) = \{\gamma \in \mathcal{C}^{\infty}(\overline{\Omega}) \mid
\mathrm{Sop}(\gamma) \subset \subset \Omega\}$, donde $A \subset \subset B$ significa que
$A \subset \text{abierto} \subset \text{compacto} \subset B$ se verifica
\begin{equation}
  \label{eq:green:soporte}
  \int_{\Omega} \phi(x) \frac{\partial}{\partial x_i} f(x) \diff x = - \int_{\Omega}
  \frac{\partial}{\partial x_i} \phi(x) f(x) \diff x.
\end{equation}

A la función $\phi$ se le denomina \emph{función test}. Sea
$f \in \mathcal{L}_{loc}^1 = \{g\colon \Omega \to \R \mid g \in \mathcal{L}(K) \ \forall K \subset
\subset \Omega \}$. El funcional $L_f\colon \mathcal{C}_0^\infty(\Omega) \to \R$, dado por
\[ L_f[\phi] = - \int_{\Omega} \frac{\partial}{\partial x_i} \phi(x) f(x) \diff x, \]

es un operador lineal. Lo denotamos
$L_f[\phi] = \left\langle \frac{\partial}{\partial x_i} f, \phi\right\rangle$. Nótese que si $f$
fuese de clase $1$, entonces $\left\langle \frac{\partial}{\partial x_i} f, \phi\right\rangle$ es
efectivamente el producto en $\mathrm{L}^2$ por \eqref{eq:green:soporte}.

\begin{proposition}
  Si $f$ es $\mathcal{C}^1$, entonces su derivada queda caracterizada por $L_f$, es decir, si
  $g \in \mathcal{C}^1(\Omega)$ es otra función tal que para cada
  $\phi \in \mathcal{C}_0^\infty(\Omega)$ se tiene
  \[ \int_{\Omega} g(x)\phi(x) \diff x = - \int_{\Omega} f(x) \frac{\partial}{\partial x_i} \phi(x)
    \diff x, \] entonces $g = \frac{\partial}{\partial x_i} f$.
\end{proposition}
\begin{proof}
  Es una consecuencia del Lema fundamental del Cálculo de Variaciones.
\end{proof}

\begin{definition}
  Dada $f \in \mathcal{L}_{loc}(\omega)$ definimos su \emph{derivada generalizada} o \emph{derivada
    distribucional} respecto de la variable $x_i$ como el operador lineal sobre
  $\mathcal{C}_0^{\infty}(\Omega)$ dado por
  \[ \left\langle \frac{\partial}{\partial x_i} f, \phi\right\rangle = - \int_{\Omega}
    \frac{\partial}{\partial x_i} \phi(x) f(x) \diff x. \]
\end{definition}

\begin{remark}
  Se puede definir la \emph{derivada generalizada de orden $k$} como
  \[ \left\langle \frac{\partial^{|k|}}{\partial x^k} f, \phi\right\rangle = - \int_{\Omega}
    \frac{\partial^k}{\partial x^{|k|}} \phi(x) f(x) \diff x, \] donde $x = (x_1, \ldots, x_n)$ y
  $k = (k_1, \ldots, k_n)$
\end{remark}

\begin{remark}
  La derivada generalizada es un operador lineal continuo sobre el espacio
  $\mathcal{D}(\Omega) = \mathcal{C}_0^{\infty}(\Omega)$ con una topología $\tau$ que no podemos
  definir en este momento. Cabe decir que la convergencia de una sucesión $\{\phi_n\}$ a $\phi$ en
  esta topología equivale a que $\{\frac{\partial^{|k|}}{\partial x^k} \phi_n\}$ converge
  uniformemente a $\frac{\partial^{|k|}}{\partial x^k} \phi$ para todo $k$.
\end{remark}

\begin{definition}
  Una función $f \in \mathcal{L}_{loc}(\Omega)$ tiene \emph{derivada débil} cuando su derivada
  generalizada viene representada por una función, es decir, existe
  $g \in \mathcal{L}_{loc}(\Omega)$ tal que para cada $\phi \in \mathcal{C}_0^{\infty}(\Omega)$
  \[ \left\langle \frac{\partial}{\partial x_i} f, \phi\right\rangle = \left\langle g,
      \phi\right\rangle = \int_{\Omega} g(x)\phi(x) \diff x.\]

  A la clase funciones iguales a $g$ c.p.d. se le llama \emph{derivada débil de $f$ respecto de
    $x_i$}.
\end{definition}

\begin{remark}
  En caso de existir la derivada débil es única por el Lema fundamental del Cálculo de Variaciones
  (versión generalizada a $\mathcal{L}_{loc}(\Omega)$).
\end{remark}

\begin{ex} \label{ex:der-debil:abs} Calculamos la derivada débil de $f(x) = |x|$ en $\Omega =
  \R$. Tenemos que
  \[ - \int_\R |x|\phi'(x) \diff x = \int_{-\infty}^{0} x\phi'(x) \diff x - \int_0^{\infty}
    x\phi'(x) \diff x = \int_{-\infty}^{0} \phi(x) \diff x - \int_0^{\infty} \phi(x) \diff x =
    \int_\R s_a(x) \phi(x) \diff x,\]

  donde $s$ es la función signo, definida en $0$ como $s(0)=1$.
\end{ex}

\begin{ex}
  La función $H \colon \R \to \R$ dada por
  \[ H(x) =
    \begin{cases}
      1 & \text{si } x \ge 0; \\
      0 & \text{si } x < 0;
    \end{cases}
  \]
  no tiene derivada débil. En efecto, tenemos que
  \[ - \int_{\R} H(x)\phi'(x) \diff x = - \int_0^{\infty} \phi'(x) \diff x = \phi(0),\] que es el
  operador ``evaluar en $0$''. Los ingenieros utilizan la delta de Dirac (que no es una función)
  para decir que este operador es igual a $\left\langle \delta_0, \phi \right\rangle$. De ello
  deducen que $\delta_0$ es la derivada débil de $H$. Esto es formalmente erróneo, no existe la
  derivada débil de esta función. En efecto, el operador ``evaluar en $0$'' no coincide con
  $\left\langle g, \phi \right\rangle$ para ninguna $g$. En tal para cualquier
  $\phi \in \mathcal{C}_0^{\infty}([0, +\infty[)$ tendríamos $\left\langle g, \phi
  \right\rangle$. Por el Lema fundamental del Cálculo de Variaciones obtenemos que $g$ es $0$ en
  $[0,+\infty[$. Razonamos de forma análoga en $]-\infty, 0]$, obteniendo que $g$ es constantemente
  $0$, contradicción.
\end{ex}

\begin{proposition}
  \begin{enumerate}
  \item Si $u \in \mathcal{C}^1(\overline{\Omega})$, entonces $u'$ es la derivada débil de $u$.
  \item Si $u \in \mathcal{C}^1(\Omega)$ y $u$ tiene derivada débil, entonces $u'$ es la derivada
    débil de $u$.
  \end{enumerate}
\end{proposition}

Puede ser que $u \in \mathcal{C}^1(\Omega)$ pero $u$ no tenga derivada débil. En tal caso, la
derivada generalizada suele ser de la forma $u' + \delta$, donde $\delta$ es una delta de dirac en
un subconjunto de la frontera de $\Omega$.

\begin{definition}
  Sean $m \in \N$ y $p \in [1,+\infty]$. Sea $\Omega$ dominio de $\R^N$. El \emph{espacio de
    Sobolev} es
  \[ W^{m,p} = \{\text{funciones de } L_p(\Omega) \text{ tales que sus derivadas hasta orden } m
    \text{ son débiles y están en } L_p(\Omega) \}. \] Es un espacio de Banach con la norma
  \[ ||u|| = \left( ||u||^p_{L_p(\Omega)} + \sum_{1 \le |\alpha| \le m}
      ||\frac{\partial^{|\alpha|}}{\partial x^{\alpha}} u ||^p_{L_p(\Omega)} \right)^{1/p} \]

  si $p \in [1, +\infty[$ y
  \[ ||u|| = \max_{0 \le |\alpha| \le m} ||\frac{\partial^{|\alpha|}}{\partial x^{\alpha}} u
    ||^p_{\mathrm{L}_p(\Omega)} \]

  si $p = +\infty$. Para $p = 2$ el espacio de Sobolev es un espacio de Hilbert, y se denota
  $\mathrm{H}^m(\Omega)$, para el producto escalar
  \[ \left\langle u, v \right\rangle = \int_{\Omega} uv \diff x + \sum_{1 \le |\alpha| \le m}
    \int_{\Omega} \frac{\partial^{|\alpha|}}{\partial x^{\alpha}} u \cdot
    \frac{\partial^{|\alpha|}}{\partial x^{\alpha}} v \diff x.\]
\end{definition}

\begin{ex} [Derivada débil de $|x|^{\alpha}$]
  Nótese que el gradiente de $|x|^{\alpha}$ es $\alpha x |x|^{\alpha-2}$ para $x \ne 0$. Buscamos la
  derivada débil de $|x|^{\alpha}$ en $B(0,1)$. Para ello procedemos com en el Ejemplo
  \ref{ex:der-debil:abs}, obteniendo que efectivamente ésta es la derivada débil.
\end{ex}

\begin{ex}
  Sea $B \subset \R^N$. Prueba que
  \begin{itemize}
  \item $1/|x|^{\alpha} \in L_p(B)$ si, y solo si, $\alpha p < N$;
  \item $1/|x|^{\alpha} \in L_p(\R^N \setminus B)$ si, y solo si, $\alpha p > N$.
  \end{itemize}
  Ayuda: Cambio a radiales en $\R^N$.
\end{ex}

En $H^1(\Omega)$ hay un subespacio destacado,
$H_0^1(\Omega) = \{u \in H^1(\Omega) \mid u = 0 \text{ en } \partial \Omega\}$. Aunque a priori no
tiene sentido exigir que una función sea $0$ en la frontera de $\Omega$ (la medida de su frontera es
$0$), esto sí se puede hacer mediante \emph{densidad}. Esto se estudia en otras asignaturas de la
carrera. De hecho, $W_0^{1,p} (\Omega) = \overline{\mathcal{C}_0^\infty(\Omega)}$, donde el cierre
es en $W^{1,p}$. Es más, se puede demostrar que
$W^{1,p} (\Omega) = \overline{\mathcal{C}^\infty(\Omega)}$.

\begin{theorem}[Teorema fundamental del cálculo integral]
  \label{thm:fundamental-calculo}
  Dado $I = ]a,b[$ y $f \in \mathrm{L}_{loc}^1(I)$ y $c \in I$, definimos
  \[ F(x) = \int_c^x f(s) \diff s \]

  para todo $x \in I$. Entonces, $F$ tiene derivada débil y ésta es $f$. A $F$ se le llama primitiva
  de $f$. Además, $F$ es continua.
\end{theorem}
\begin{proof}
  Tenemos que
  \begin{align*}
    - \int_a^b F(x) \phi'(x) \diff x & = - \int_a^b \int_{c}^{s} f(s) \phi'(x) \diff s \diff x \\
                                     & =  \int_a^c \int_{s}^{c} f(s) \phi'(x) \diff s \diff x - \int_c^b \int_{c}^{s} f(s) \phi'(x) \diff s \diff x \\
                                     & =  \int_a^c \int_{x}^{c} f(s) \phi'(x) \diff s \diff x - \int_c^b \int_{c}^{x} f(s) \phi'(x) \diff s \diff x \\
                                     & =  \int_a^c f(s) (\phi(c)-\phi(s)) \diff s - \int_c^b  f(s) (\phi(s) - \phi(c)) \diff s  
  \end{align*}
\end{proof}

\begin{theorem}[Poincaré]
  \label{thm:cota-h1}
  Sea $\Omega \subset \R^N$ acotado en al menos una dirección, esto es, existe $v \in \R^N$ ,
  $a,b \in \R$ con $a < b$ tales que $a \le <x,v> \le b$ para todo $x \in \Omega$. Entonces, para
  cada $u \in \mathrm{H}_0^1(\Omega)$ existe $c > 0$ con
  \[ \int_{\Omega} u^2(s) \diff s \le C \int_{\Omega} |\nabla u(s)|^2 \diff s.\]
\end{theorem}
\begin{proof}
  Demostramos el resultado para el caso el caso uno dimensional.  Defino el funcional
  $\mathcal{F}\colon \mathcal{D}_1 \to \R$ dado por
  \[ \mathcal{F}[u] = \int_{x_0}^{x_1} (u')^2 \diff x, \] donde
  $\mathcal{D}_1 = \{u \in \mathcal{C}_0^1(x_0,x_1) \mid \int_{x_0}^{x_1} u^2 \diff x =
  1\}$. Podemos aplicar el Teorema \eqref{thm:sl}, obteniendo que el funcional $\mathcal{F}$ tiene
  mínimo y vale $\lambda_1 = (\pi / (x_1-x_0))^2$. Por tanto, dado $u \in C_0^1(x_0, x_1)$ tenemos
  que
  \[\mathcal{F}[u / \int_{x_0}^{x_1} u^2 \diff x] \ge \lambda_1.\]
  Hemos probado parcialmente el resultado para $C = 1 / \lambda_1$. Para pasar a
  $\mathrm{H}_0^1(x_0, x_1)$ usamos que
  $\mathrm{H}_0^1(x_0, x_1) = \overline{\mathcal{C}_0^1(x_0, x_1)}^{\mathrm{H}^1}$.
\end{proof}

\begin{theorem}
  \label{thm:h1-norma}
  Sea $\Omega$ acotado en al menos una dirección. Entonces en el espacio $\mathrm{H}_0^1(\Omega)$ la
  norma
  \[ ||| u ||| = \left( \int_{\Omega} |\nabla u (s)|^2 \diff s \right)^{1/2}\]

  es equivalente a la norma heredada de $\mathrm{H}^1(\Omega)$.
\end{theorem}

\begin{theorem}[Teoremas de representación de Riesz para Hilbert]
  \label{thm:rep-riesz}
  Dado $H$ espacio de Hilbert, entonces toda aplicación lineal y continua de $H$ en $\R$ es de la
  forma $\left\langle v, \cdot \right\rangle$ para cierto $v \in H$.
\end{theorem}

\begin{theorem}
  \label{thm:riesz-lp}
  Sea $p \in [1, +\infty[$ y $p' > 0$ con $1 = 1/p + 1/p'$. Toda aplicación
  $G \colon \mathrm{L}^p(\Omega) \to \R$ lineal y continua es de la forma
  \[ G(f) = \int_{\Omega} g(x)f(x) \diff x, \]

  donde $g \in \mathrm{L}^{p'}(\Omega)$.
\end{theorem}

\begin{lemma}
  Sea $H$ espacio de Hilbert y $A \subset H$. Se verifican las siguientes afirmaciones:
  \begin{enumerate}
  \item $(A^T)^T = \overline{\left\langle A \right\rangle}$;
  \item Si $A$ es denso, entonces $A^T = \{0\}$.
  \end{enumerate}
\end{lemma}

Recordamos en este punto el problema de la membrana. Podemos definir el operador asociado a este
problema en $\mathrm{H}_0^1$. Este operador viene dado por
\[ E[U] = \int_{\Omega} \frac{\sigma}{2} |\nabla u|^2 + \frac{\alpha}{2} |u|^2 \diff x -
  \int_{\Omega} f(x)u(x) \diff x.\]

Recordemos que su ecuación de Euler - Lagrange era de la forma $-\sigma \Delta u = f - \alpha u$.
Definimos las funciones
\[ a(u,v) = \int_{\Omega} \sigma \nabla u \nabla v + \alpha uv \diff x, \]

\[ \overline{f}(u) = \int_{\Omega} f(x)u(x) \diff x, \]

y
\[ J[u] = \frac{1}{2} a(u,u) - \overline{f}(u) \]


\begin{theorem}[Teorema de Lax - Milgram]
  \label{thm:lax-milgram}
  Sea $H$ un espacio de Hilbert y $a \colon H \times H \to \R$ una forma bilineal, continua y
  coerciva (existe $\alpha$ tal que $a(u,u) \ge \alpha ||u||$ para todo $u \in H$). Entonces, para
  cada función $\overline{f} \in H^{*}$, existe un único elemento $\overline{u} \in
  H$ que sea solución de
  \begin{equation}
    \label{eq:lax-milgram}
    a(\overline{u}, v) = \overline{f}(v) \quad \forall \,v \in H.
    \tag{PD}
  \end{equation}
  Además, la aplicación $F$\colon H^* \to H$ que a cada $\overline{f}$ le hace corresponder la única
  solución de \eqref{eq:lax-milgram} verifica $||F(\overline{f})|| \le ||\overline{f}|| / \alpha$
  para todo $\overline{f} \in H^*$ y, por tanto, $F$ es continua.

  Además, si $a$ es simétrica, entonces $F(\overline{f})$ es también la única solución del problema
  \begin{equation}
    \label{eq:lax-milgram:pv}
    J(u) = \min_{u \in H} J(u),
    \tag{PV}
  \end{equation}
  siendo $J(u) = a(u,u)/2 - \overline{f}(u)$.
\end{theorem}
\begin{proof}
  Definimos mediante el Teorema de Riesz-Fréchet la aplicación $A \colon H \to H$ tal que $A(u)$ es
  el único vector que verifica $a_u(v) = a(u,v) = \langle A(u), v \rangle$ para todo $v \in H$. La
  aplicación $A$ es claramente lineal. Además, por la continuidad de $a$ existe $C \ge 0$ tal que
  $|a(u,v)| \le C ||u|| ||v ||$. Obtenemos que $||A(u)|| = ||a_u|| \le C ||u||$ por lo que $A$ es
  continua.

  Sea $\overline{f} \in H^*$. De nuevo por el Teorema de Riesz-Fréchet existe una única $f \in H$
  tal que $\overline{f}(v) = \langle f, v\rangle$ para todo $v \in H$. Tenemos que el problema
  \eqref{eq:lax-mmilgram} equivale a encontrar $u\in H$ tal que $A(u) = f$. La existencia de
  solución equivale a la sobreyectividad de $A$ y la unicidad de solución equivale a la inyectividad
  de $A$. Nótese que por la coercividad se cumple
  $\alpha ||v||^2 \le |a(v, v)| = |\left\langle A(v), v \right\rangle| \le ||A(v)||||v||$. Esto es,

  \begin{equation}
    \label{eq:lax-milgram:cota}
    ||v|| \le \frac{1}{\alpha}||A(v)|| \quad \forall\, v \in H,
  \end{equation}
  
  de donde deducimos que $A$ es inyectiva. Veamos ahora que $A(H)$ es denso y cerrado. En efecto,
  $A(H)^\perp = \{0\}$ ya que si $a(u,v) = 0$ para todo $u \in H$, entonces $a(v,v) = 0$, pero
  $|a(v,v)| \ge \alpha ||v||^2$, luego $v = 0$. Por último, $A^{-1}$ es continua por tenerse
  $||v|| \le ||A(v)|| / \alpha$ para todo $v \in H$. Luego $A$ es un isomorfismo y $A(H)$ es
  completo. Consecuentemente, $A(H)$ es cerrado como se quería.

  Supongamos ahora que $a$ es simétrica. Tenemos que
  \[J(u+v) = a(u+v, u+v)/2 - \overline{f}(u+v) = J(u) + a(u,v) - \overline{f}(v) +
    \frac{1}{2}a(v,v)\] para todo $u, v \in H$. Nótese que si $u$ es solución de
  \eqref{eq:lax-milgram}, entonces $J(u+v) = J(u) + a(v,v)/2$ para todo $v \in H$. Esto prueba que
  $u$ es el único mínimo de $J$.
\end{proof}

\begin{ex}
  Aplicamos a continuación este resultado al problema de la membrana. Recordemos que deducimos la
  ecuación de Euler-Lagrange

  
  \begin{equation}
    \label{eq:el:lax-milgram}
    \begin{cases}
      - \sigma \Delta u = f - \alpha u; \\
      u \in \Omega; \\
      u = 0 \text{ en } \partial \Omega.
    \end{cases}
  \end{equation}

  Buscábamos el mínimo del funcional
  \begin{equation}
    \label{eq:pv:lax-milgram}
    E[u] = \int_{\Omega} \frac{\sigma}{2}|\nabla v|^2 + \frac{\alpha}{2}v^2 \diff x + \int_{\Omega}
    f(x) v(x) \diff x.
  \end{equation}

  Denotamos $a(v,v)/2$ a la primera integral y $\overline{f}(v)$ a la segunda. Generalizamos $a$
  como sigue
  \[ a(u,v) = \int_{\Omega} \sigma\nabla u \cdot \nabla v + \alpha u \cdot v \diff x.\] La función
  $a$ es bilineal, continua y coerciva. Además, la función $\overline{f}$ es lineal y continua ya
  que
  \[ | \overline{f}(v) | \le ||f ||_{L^2} ||v||_{L^2} \le ||f ||_{L^2} ||v||. \]

  Recordemos de la demostración de la ecuación de Euler - Lagrange que se verifica
  
  \begin{equation}
    \label{eq:el:2:lax-milgram}
    a(u,v) - f(v) = 0.
  \end{equation}

  Integrando por partes esta ecuación obtuvimos que

  \begin{equation} \label{eq:el:3:lax-milgram} \int_{\Omega} u(-\sigma \Delta v + \alpha v) =
    \int_{\Omega} v \cdot v \diff s
  \end{equation}
\end{ex}

\begin{definition}
  La ecuación \eqref{eq:el:lax-milgram} tiene solución
  
  \begin{enumerate}
  \item \emph{clásica} si $u \in \mathcal{C}^2(\Omega)$ cumple \eqref{eq:el:lax-milgram}.
  \item \emph{distribucional} si $u \in \mathrm{L}_{loc}^1(\Omega)$ es el mínimo de
    \eqref{eq:el:3:lax-milgram}.
  \item \emph{variacional} si $u \in \mathrm{H}_{0}^1(\Omega)$ cumple \eqref{eq:pv:lax-milgram} para
    todo $v \in \mathrm{H}_0^1(\Omega)$.
  \item \emph{débil} si $u \in \mathrm{H}_{0}^1(\Omega)$ cumple \eqref{eq:el:2:lax-milgram} para
    todo $v \in \mathrm{H}_0^1(\Omega)$.
  \end{enumerate}
\end{definition}

Como consecuencia del Teorema de Lax-Milgram obtenemos que la ecuación de la membrana tiene una
única solución débil $u \in \mathrm{H}_0^1(\Omega)$. Además, es mínimo del funcional en cuanto
$f \in \mathrm{L}^2$.

\begin{ex}
  Sea $\Omega$ un dominio acotado de $\R^n$. Prueba que la ecuación
  \begin{equation}
    \label{eq:ex:lax-milgram}
    \begin{cases}
      -\Delta u = f \text{ en } \Omega; \\
      u = 0 \text{ en } \partial \Omega;
    \end{cases}
  \end{equation}
  tiene una única solución débil y variacional en $\mathrm{H}_0^1(\Omega)$ para todo
  $f \in \mathrm{L}^2(\Omega)$. Describe el PV asociado.

  Multiplicamos la ecuación \eqref{eq:ex:lax-milgram} por $v \in \mathrm{H}_0^1(\Omega)$ e
  integramos por partes el lado izquierdo mediante el Teorema de Green, obteniendo la formulación
  débil del problema

  \begin{equation}
    \label{eq:ex:debil}
    \int_{\Omega} \nabla u \nabla v \diff x = \int_{\Omega} f v \diff x \quad \forall \, v \in \mathrm{H}_0^1(\Omega).
  \end{equation}

  Definimos $a(u,v) = \int_{\Omega} \nabla u \nabla v \diff x$, que es claramente bilineal. Además,
  verifica $|a(u,v)| \le ||\nabla u||_{L^2} ||\nabla v||_{L^2} \le ||\nabla u|| ||\nabla
  v||$. Análogamente deducimos que $\overline{f}(v) = \int_{\Omega} f v \diff x$ es lineal y
  continua. Además, a partir de la desigualdad de Poincaré deducimos que $a$ es coerciva. En efecto,
  existe $C \ge 0$ tal que
  $||u||^2_{H^1} \le (1+C) \int_{\Omega} ||\nabla u||^2 \diff s = (1+C) a(u,u)$. Por tanto, podmeos
  aplicar el Teorema de Lax-Milgram, obteniendo que \eqref{eq:ex:debil} tiene una única solución en
  $\mathrm{H}_0^1(\Omega)$. Además, la función bilineal $a$ es claramente simétrica. Por tanto,
  resolver la ecuación \eqref{eq:ex:debil} equivale a encontrar el mínimo del funcional
  
  \begin{equation*}
    E[u] = \int_{\Omega} \frac{1}{2}|\nabla v|^2 \diff x -\int_{\Omega}
    f(x) v(x) \diff x,
  \end{equation*}

  que era el que aparecía en el problema de la membrana.
  
\end{ex}

\begin{ex}
  Consideramos la forma bilineal simétrica
  $a \colon \mathrm{H}_0^2(-1,1) \times \mathrm{H}_0^2(-1,1) \to \R$ dada por
  \[ a(u,v) = \int_{-1}^{1} u''(x) v''(x) \diff x. \]

  Demostrar que $a$ es coerciva.

  El ejercicio es una consecuencia de la desigualdad de Poincaré. En efecto, existe $C \ge 0$ tal
  que
  \[ \int_{-1}^1 u(x)^2 \diff x \le C \int_{-1}^1 u'(x)^2 \diff x\] para todo
  $u \in \mathrm{H}_0^1(\Omega)$.  Por tanto, para cada $u \in \mathrm{H}_0^2(-1,1)$
  \[ \int_{-1}^1 u(x)^2 \diff x \le C \int_{-1}^1 u'(x)^2 \diff x \le C^2 a(u,u).\]

  Consecuentemente, tenemos que

  \[ ||u||_{\mathrm{H}^2_0}^2 \le a(u,u) + C a(u,u) + C^2 a(u,u) = (1+C+C^2) a(u,u) \]

  para todo $u \in \mathrm{H}_0^2(-1,1)$ como se quería.
\end{ex}


\newpage

\section{Biología}

En este apartado estudiamos problemas de la biología que se reducen en resolver problemas de contorno. Concretamente el temario se divide en

\begin{enumerate}
\item Química, leyes de acción de masas (LAM).
\item Poblaciones, leyes de crecimiento.
\item Poblaciones + movimiento difusivo. Difusión.
\item Morfogénesis, varias poblaciones.
\end{enumerate}

\subsection{Leyes de acción de masas}

Consideramos una reacción química, esto es, un proceso por el cuál una determinada cantidad de
sustancias se convierte en otras. La denotamos $A+B \rightarrow C$ en caso de que a partir de los
productos $A$ y $B$ se obtenga $C$. Buscamos la velocidad con la que reaccionan $A$ y $B$. Denotamos
por $\left[ A \right]$ a la concentración de $A$ (cantidad por unidad de volumen). Es una función
del tiempo, por lo que también la denotaremos $a(t)$. La ley de acción de masas dice que la
velocidad de la reacción, $\frac{\partial}{\partial t}\left[ C \right]$ es proporcional a
$\left[ A \right]\left[ B \right]$.Si $k$ es la constante de proporcionalidad, se escribe
$A+B \rightarrow^k C$. Obviamente tenemos que
$\frac{\partial}{\partial t}[A] = \frac{\partial}{\partial t}[B] = - \frac{\partial}{\partial
  t}[C]$.

Puede suceder que la reacción sea reversible, de manera que al mismo tiempo también se produce
$C \rightarrow_{k_{-1}} A+B$. En conjunto lo denotamos $A+B \leftrightarrow_{k_{-1}}^{k_1}
C$. Tenemos que
\[ \frac{\partial}{\partial t}[C] = k_1 [A][B] - k_{-1}[C]. \] El equilibrio tiene lugar cuando las
concentraciones son constantes.

\begin{ex}
  Estudiamos el modelo para el crecimiento de una bacteria basado en las tesis biológicas de
  Michaelis y Mneten. Una bacteria tiene receptores enzimáticos que intentan obtener el substrato o
  alimento del exterior, pasando a través de la membrana celular Los receptores enzimáticos pueden o
  bien liberar el substrato que han "agarrado" o bien lo introduce en la bacteria en forma de
  producto proceso mecánico de volteo. En ambos casos la encima queda libre de nuevo. El complejo
  enzimático que se produce cuando el substrato se acopla a la encima lo llamamos $SE$. Por $E$ nos
  referimos a las encimas y por $S$ al substrato. Por último, denotamos por $P$ a los productos que
  se producen cuando la encima absorbe definitivamente el substrato. Tenemos las relaciones
  \begin{equation}
    \label{eq:5}
    \begin{cases}
      S + E \to ^{k_{1}} SE; \\
      SE \to ^{k_{-1}} S+E; \\
      SE \to^{k_2} E+P.
    \end{cases}
  \end{equation}
  Llamamos $e(t) = [E]$, $s(t) = [S]$, $c(t) = [SE]$, $p(t) = [P]$. Añadimos las condiciones
  iniciales $e(0) = e_0 > 0$, $c(0) = 0$, $s(0) = s_0 > 0$, $p(0) = 0$. Utilizando las leyes de
  acción de masas deducimos que estas funciones verifican el sistema
  \begin{equation}
    \label{eq:bacteria}
    \begin{cases}
      p'(t) = k_2 c(t); \\
      s'(t) = k_{-1}c(t) - k_1 s(t) e(t); \\
      c'(t) = k_1 s(t) e(t) - k_2 c(t) - k_{-1}c(t); \\
      e'(t) = -k_1 s(t) e(t) + k_1 c(t) + k_2 c(t).
    \end{cases}
  \end{equation}

  Podemos simplificar esta ecuación como sigue.

  \begin{itemize}
  \item En primer lugar, de la ecuación $p' = k_2 c$, podemos despejar la función $p$ mediante el
    Teorema Fundamental del Cálculo, esto es, $p(t) = \int_0^{t} k_2c(s) \diff s$.
  \item Tenemos que $c'(t) + e'(t) = 0$ ya que $e(t)+c(t)$ es constante, esto es,
    $e(t) = e_0 - c(t)$.
  \end{itemize}
  Tras estas simplificaciones el PVI resultante es
  \begin{equation}
    \label{eq:bacteria:simplificada}
    \begin{cases}
      s'(t) = k_{-1}c(t) - k_1 s(t) (e_0 - c(t)); \\
      c'(t) = k_1 s(t) (e_0 - c(t)) - (k_2 + k_{-1})c(t). \\
    \end{cases}
  \end{equation}
  Es claro que el sitema tiene solución única por el Teorema de Picard-Lindelöf. En lo que sigue
  vamos a estudiar el PVI asociado a las condiciones iniciales $s(0) = s_0$ y $c(0) =
  0$. Comprobaremos las iguientes características de éste:
  \begin{enumerate}
  \item Positividad.
  \item Acotación.
  \item Intervalo de definición (será $[0, +\infty[$).
  \item Comportamiento cuando $t \to +\infty$.
  \end{enumerate}
  No podemos calcular una solución explíctamente, razón por la cual tendremos que utilizar los
  resultados clásicos de acotación para ecuaciones diferenciales ordinarias. Previamente realizamos
  un cambio de varaible con el fin de normalizar las soluciones y eliminar las unidades físicas. El
  cambio de variable es $u(\tau) = s(\tau / (k_1 e_0)) / s_0$ y
  $v(\tau) = c(\tau / (k_1 e_0)) / e_0$. Obtenemos el nuevo sistema
  \begin{equation}
    \label{eq:bacteria:norm}
    \begin{cases}
      u' = \left(\frac{k_{-1}}{k_1 s_0} + u \right) v -u; \\
      v' = \frac{s_0}{e_0} u - \left( \frac{s_0}{e_0} u + \frac{k_{-1} + k_2}{e_0k_1} \right)v.
    \end{cases}
  \end{equation}
  Definimos $\varepsilon = e_0 / s_0$, $\lambda = k_2 / (k_1 s_0)$ y
  $k = (k_2 + k_{-1}) / (k_1 s_0)$. Nótese que estas constantes no tienen dimensiones. Escribimos
  \eqref{eq:bacteria:norm} utilizando solamente estas constantes, obteniendo
  \begin{equation}
    \label{eq:bacteria:adi}
    \begin{cases}
      u' = \left(k-\lambda +u \right) v - u; \\
      v' =  (u - (u+k)v) / \varepsilon; \\
      u(0) = 1; \\
      v(0) = 0.
    \end{cases}
  \end{equation}

  Nótese que $k - \lambda > 0$. Veamos que las soluciones $u$ y $v$ son no negativas en
  $[0, \omega[$. Razonamos por reducción al absurdo. Nótese que $u(0) = 1 > 0$ y
  $v'(0) = 1/\varepsilon >0$, luego existe $T> 0$ tal que $v$ y $u$ son positivas en $]0, T[$ y una
  de las dos comienza a ser negativa en $T$. Hay tres casos posibles:
  \begin{enumerate}
  \item Se cumple $u(T) = 0$ y $v(T) = 0$. En tal caso $u = 0$ y $v = 0$ por unicidad global de
    solución, lo que contradice las condiciones iniciales.
  \item Se cumple $u(T) = 0$ y $v(T) > 0$. Entonces, $u'(T) < 0$. No obstante,
    $u'(T) = (k-\lambda)v(T) > 0$, contradicción.
  \item Se cumple $u(T) > 0$ y $v(T) = 0$. Entonces, $v'(T) < 0$. No obstante,
    $v'(T) = u(T) / \varepsilon > 0$, contradicción.
  \end{enumerate}

  A continuación demostramos que las soluciones están acotadas. Definimos
  $h(\tau) = u(\tau) + \varepsilon v(\tau)$. Tenemos que $h'(\tau) = -\lambda v(\tau) \le
  0$. Recordemos que $h(0) = 1$ y $h \ge 0$, luego $h$ es decreciente y $0 \le h(\tau) \le 1$ para
  todo $\tau \in [0,\omega[$. Consecuentemente, $0 \le u \le 1$ y $0 \le v \le 1/\varepsilon$. Como
  consecuencia, por el teorema de comportamiento en el extremo superior deducimos que
  $\omega = +\infty$.

  Veamos que $u(\tau)$ y $v(\tau)$ tienden a $0$ cuando $\tau \to +\infty$. Como $h$ decrece y está
  acotada, deducimos que $h$ tiene límite en $+\infty$. Sea $c \in [0,1[$ ese límite. Existe
  $\{\tau_n\} \to +\infty$ con $\{-\lambda v(\tau_n)\} = \{h'(\tau_n)\} \to 0$. Por tanto,
  $\{u(\tau_n)\} \to c$. Podemos suponer que $\{v(\tau_n)\}$ es estrictamente decreciente. De la
  ecuación \eqref{eq:bacteria:adi} deducimos que $\{v'(\tau_n)\} \to c / \varepsilon$. Supongamos
  que $c > 0$ para llegar a una contradicción. En tal caso, una parcial de $\{v'(\tau_n)\}$ es
  positiva, por lo que podemos asumir que es la propia sucesión. Para cada $n \in \N$ encontramos
  $\omega_n \in ]\tau_n, \tau_{n+1}[$ tal que $v'(\omega_n) = 0$ con $v(\omega_n) <
  v(\tau_{n+1})$. Obtenemos $\{v(\omega_n)\} \to 0$ y $\{v'(\omega_n)\} \to 0$. De las ecuaciones
  deducimos $\{u(\omega_n)\} \to 0$, lo que contradice que $\{h(\omega_n)\} \to
  c$. Consecuentemente, $c = 0$ y $u(\tau)$ y $v(\tau)$ tienden a $0$ cuando $\tau \to +\infty$.

  Podemos ahora recuperar el valor de $p$. En efecto, tenemos que
  \[ p(t) = \int_0^t k_2 c(s) \diff s = \frac{k_2}{k_1} \int_0^{k_1 e_0 t} v(\tau) \diff \tau =
    -\frac{k_2}{k_1 \lambda} \int_0^{k_1 e_0 t} h'(\tau) \diff \tau = \frac{k_2}{k_1 \lambda} (1 -
    h(k_1 e_0 t)). \] Por tanto, $p$ es creciente y verifica $p(0) = 0$ y
  $\lim_{t \to +\infty} p(t) = k_2 (k_1 \lambda)$.
\end{ex}


\subsection{Modelos de crecimiento de poblaciones biológicas}

Sea $P(t)$ el número o densidad de individuos de una cierta población en el instante de tiempo
$t$. Se define la \emph{tasa instantánea de crecimiento} como 
\[\alpha(t) = \frac{P'(t)}{P(t)} = \lim_{h \to 0} \frac{P(t+h) - P(t)}{h P(t)}.\] 
En este contexto, modelar es proporcionar $\alpha$. 

\subsubsection{Modelo de Malthus (1798)}

Este modelo supone que $\alpha$ es una constante real. La función $P$ es solución del PVI
\begin{equation}
\label{eq:malthus}
\begin{cases}
  P' = \alpha P; \\
  P(0) = P_0.
\end{cases}
\end{equation}
Tenemos que $P(t) = P_0 e^{\alpha t}$. Este modelo solo es válido normalmente en las primeras fases de una población. Tras cierto periodo de tiempo las variables ambientales influirán de alguna manera a la tasa instanánea de crecimiento.

\subsubsection{Modelo de P. Verhulst o modelo logístico (1838) }

La tasa $\alpha$ cambia en el tiempo debido a que los nutrientes de los cuales se alimenta la
población se consumen si ésta es demasiado grande. Esto es, se pretende que $\alpha$ sea
proporcional a los nutrientes del entorno. Además, se supone que el crecimiento de la población es
inversamente proporcional a la variación del número de nutrientes. Deducimos que
$\alpha(t) = \alpha_0 (1 - P(t) / P_{\infty})$. Obtenemos el PVI
\begin{equation}
\label{eq:logistico}
\begin{cases}
  P' = \alpha_0 P (1 - \frac{P}{P_{\infty}}); \\
  P(0) = P_0.
\end{cases}
\end{equation}
A la constante $P_{\infty}$ se le llama carga máxima. El PVI \eqref{eq:logistico} se puede resolver, obteniendo
\[ P(t) = P_{\infty} \frac{e^{\alpha_0 t}}{e^{\alpha_0 t} - 1 + P_0 / P_{\infty}}. \]
Nótese que la solución verifica $\lim_{t \to +\infty} P(t) = +\infty$.

\subsubsection{Reproducción sexual (S. XX)}

Debido a la reproducción sexual de múltiples poblaciones se propone utilizar una tasa que requiera
un mínimo de población para reproducirse. De esta forma se modifica el modelo logístico, obteniendo
\[ \alpha(t) = \alpha_0 \left(1- \frac{P(t)}{P_{\infty}}\right)\left(\frac{P(t)}{P_{min}}
    -1\right). \] El comportamiento de la solución es similar al logístico cuando $P_0 >
P_{min}$. Si $P_0 \le P_{min}$, entonces la población se extingue, lo que se llama efecto Allée
fuerte.

Este modelo se puede extender al dado por la siguiente tasa
\[ \alpha(t) = \alpha_0 (1- \frac{P}{P_{\infty8}}) (\frac{P}{P_{min}})^{k+1}. \]

\subsection{Movimiento}

Modelamos una población que no crece pero se dispersa. En este contexto surgen la Ley de Fick y la
ecuación del calor o de difusión. Denotamos por $u(x,t)$ a la densidad de población en el instante
$t$ en el lugar $x \in \Omega \subset \R^N$. Por tanto, dado $B \subset \Omega$, el tamaño de la
población contenido en $B$ en el instante de tiempo $t$ viene dado por
\[ \int_B u(x,t) \diff x. \] La población se mueve por el efecto de \emph{difusión}. El tamaño de la
población permanece constante. Por tanto, la cantidad de ésta que hay en un recinto solamente varía
por los individuos que entran y salen de éste. Deducimos que
\[ \frac{\partial}{\partial t} \left( \int_B u(x,t) \diff x\right) = \text{num. de individuos que
    entran por el borde} - \text{num. de individuos que salen}. \] Denotamos por $J(x,t)$ al vector
que indica hacia dónde se mueven los individuos de $x$ y cuántos lo hacen. Tenemos que
\begin{equation}
  \label{eq:mov:1}
  \frac{\partial}{\partial t} \left( \int_B u(x,t) \diff x\right) = - \int_{\partial B} J \cdot n \diff S,
\end{equation}
donde $n$ es la normal exterior de $\Omega$.

Necesitaremos el siguiente resultado.

\begin{theorem}[Teorema de la Divergencia de Gauss]
  \label{thm:divergencia}
  Sea $F \colon \overline{\Omega} \to \R^N$ de clase $1$. Se define
  $\mathrm{div}(F) \colon \overline{\Omega} \to \R$ dada por
  $\mathrm{div}(F)(x) = \sum_{j = 1}^N \frac{\partial}{\partial x_i} F_i(x)$.  Si $\partial\Omega$
  es regular, entonces
  \[ \int_{\Omega} \mathrm{div}(F)(x) \diff x = \int_{\delta \Omega} F \cdot n \diff S, \] donde $n$
  es la normal exterior de $\Omega$.
\end{theorem}

Por este teorema deducimos
\begin{equation}
  \label{eq:mov:2}
  \frac{\partial}{\partial t} \left( \int_B u(x,t) \diff x\right) = - \int_{B} \mathrm{div}(J)(x) \diff x.
\end{equation}
Asumiendo hipótesis de regularidad obtenemos
\begin{equation}
  \label{eq:mov:3}
  \left( \int_B \frac{\partial}{\partial t} u(x,t) + \mathrm{div}(J)(x) \right) \diff x = 0.
\end{equation}
De la arbitrariedad de $B$ deducimos
\begin{equation}
  \label{eq:mov:4}
  \frac{\partial}{\partial t} u(x,t) + \mathrm{div}(J)(x) = 0,
\end{equation}
que se denomina \emph{ley de movimiento}. En este punto necesitamos proponer una función $J$ de
manera que podamos determinar $u$. Una de las principales propuestas es la denominada \emph{Ley de
  Fick}. Recordemos que la dirección en la que un potencial más crece viene dada por el gradiente de
éste mientras la dirección en la que menos crece se corresponde con el opuesto del gradiente. Debido
a esta observación Fick propone que $J = - D \nabla u$, donde $D$ es una constante de difusión que
depende de la población y del medio. En definitiva, esta ley dice que las partículas se mueven de
donde hay mayor concentración a menos. Fourier en 1822 propuso la misma función $J$ cuando estudiaba
el movimiento del calor. Utilizando esta $J$ obtenemos la denominada ecuación del calor o de
difusión
\begin{equation}
  \label{eq:mov:calor}
  0 = \frac{\partial}{\partial t}u + \mathrm{div}(-D \nabla u) = \frac{\partial}{\partial t}u - D \Delta u.
\end{equation}

\subsubsection{Desde el random walk a la ecuación del calor}

En este apartado deducimos la ecuación del calor a partir del problema denominado \emph{random
  walk}, que estudia el movimiento aleatorio de una partícula en una recta. Esta deducción fue
realizada por Einstein y tiene su importancia física. Brown estudió antes que Einstein el mismo
problema al observar que el movimiento aleatorio de particulas de polen suspendidas en el agua
seguía un coportamiento similar a la dispersión del calor.

Imaginamos una partícula que se mueve en una recta. Inicialmente se encuentra en la posición $0$ de
ésta. La partícula se mueve en cada paso una distancia fija $\delta > 0$ a izquierda o a derecha. El
sentido lo elige de forma aleatoria con probabilidad $1/2$ para ambas opciones. Realiza un paso
periódicamente con periodo $\tau > 0$. Llamamos $P(m,n)$ a la probabilidad de que tras $n$ pasos
(tiempo $n \tau$) esté en la posición $m \delta$, donde $n \in \N$, $m \in \Z$. Usando argumentos
básicos de combinatoria deducimos que
\[ P(m, n) =
  \begin{cases}
    0 & \text{si } n < |m| \text{ o } (m+n) \text{ es impar};\\
    \frac{1}{2^n} \frac{n!}{((n+m) / 2)! ((n-m) / 2)!} & \text{si } |m| \le n \text{ y } m+n \text{
      es par}.
  \end{cases}
\]
Nótese que $P(m,n+1) = (P(m-1, n) + P(m+1,n))/2$. Supongamos que existe una función $u(x,t)$ tal que
$P(m,n) = u(m\delta, n\tau)$. Tenemos que
\[ P(m,n+1) - P(m,n) = \frac{1}{2}(P(m-1,n) - 2P(m,n) + P(m+1,n)). \] Sea $x = m\delta$ y
$t = n\tau$. Deducimos que
\[ \frac{u(x,t+\tau) - u(x,t)}{\tau} = \frac{\delta^2}{2\tau}\frac{u(x-\delta,t) - 2u(x,t) +
    u(x+\delta,t)}{\delta^2}. \] Por las fórmulas de aproximación de derivadas deducidas a partir
del teorema de Taylor obtenemos
\[ \partial_t u + \theta(\tau) = \frac{\delta^2}{2\tau} \partial_{xx}^2u + \theta(\delta^4 /
  \tau). \] Tomamos límite cuando $\delta \to 0$ y $\tau \to 0$. Asumimos que se cumple la
\emph{hipótesis parabólica}, que dice que $\delta^2 / (2\tau) \to D \in \R$. En este caso
\[ \partial_t u = D \partial_{xx}^2u, \] que es la ecuación del calor en una dimensión.  En este
punto cabe mencionar que $\delta / \tau$ es la velocidad de la partícula. Según la hipótesis
parabólica se tiene que $\delta / \tau = \frac{\delta^2}{2\tau} \frac{2}{\delta} \to +\infty$.

\subsubsection{Resolución de la ecuación del calor}

En este apartado resolvemos la ecuación del calor para $x \in \R$. Concretamente, pretendemos
resolver el problema de contorno
\begin{equation}
  \label{eq:calor:1}
  \partial_t v = D \partial_{xx}^2 v; \\
  v(x,0) = v_0(x) \quad \forall x \in \R.
\end{equation}
Para resolver esta ecuación recurriremos a la transformada de Fourier y la convolución.

\begin{definition}
  La \emph{clase de funciones de Schwartz} es
  \[ \mathcal{S} = \mathcal{S}(\R) = \left\{u \in \mathcal{C}^{\infty}(\R, \C) : \sup_{x\in\R} |x^k
      \partial^{\alpha} u(x)| < +\infty \quad \forall k, \alpha \in \N\right\}. \]
\end{definition}
Nótese que $\mathcal{C}_0^\infty(\R) \subset \mathcal{S}(\R)$. Denotamos $G(x) = e^{-\pi
  x^2}$. Nótese que si $f \in \mathcal{S}(\R)$, entonces $f'$ y $x^k f$ son elementos de
$\mathcal{S}(\R)$.

\begin{definition}
  La \emph{transformada de Fourier} es la función $\mathcal{F} \colon \mathcal{S} \to \mathcal{S}$
  dada por
  \[ \mathcal{F}[f](y) = \int_{-\infty}^{+\infty} f(x) e^{-2\pi i xy} \diff x. \] La
  \emph{transformada inversa de Fourier} es la función
  $\mathcal{F}^{-1} \colon \mathcal{S} \to \mathcal{S}$ dada por
  \[ \mathcal{F}^{-1}[g](x) = \int_{-\infty}^{+\infty} g(y) e^{2\pi i xy} \diff y. \]
\end{definition}
\begin{remark}
  Sean $f,g \in \mathcal{S}$.  Tenemos que
  \[ \int_{-\infty}^{+\infty} \mathcal{F}[f](y)g(y) \diff y = \int_{-\infty}^{+\infty}
    f(x)\mathcal{F}[g](x) \diff x. \] Gracias a esta igualdad se puede definir un operador
  transformada de Fourier de cualquier función de $f \in \mathrm{L}^2(\R, \C)$. Este operador
  viene dado por
  \[ \left\langle \mathcal{F}[f], g \right\rangle = \int_{-\infty}^{+\infty} f(x) \mathcal{F}[g](x)
    \diff x\] para todo $g \in \mathcal{S}$.
\end{remark}

\begin{theorem}
  \label{thm:transformada}
  Se cumplen las siguientes propiedades.
  \begin{enumerate}
  \item\label{item:fourier:inversa} La función $\mathcal{F}$ es una biyección sobre $\mathcal{S}$ y
    $\mathcal{F}^{-1}$ es su inversa.
  \item Se cumple $\mathcal{F}[G] = G = \mathcal{F}^{-1}[G]$.
  \item Para cada $f \in \mathcal{S}$ se tiene $\mathcal{F}[f'](y) = 2 \pi i y \mathcal{F}[f](y)$.
  \item Relación con homotecias. Sea $h_a(x) = ax$. Denotamos $h_a f := f(ax)$. Se tiene que
    \begin{itemize}
    \item $\mathcal{F}[h_a f](y) = \mathcal{F}[f](y/a)/a$;
    \item $\mathcal{F}^{-1}[h_a f](x) = \mathcal{F}[f](x/a)/a$.
    \end{itemize}
  \end{enumerate}
\end{theorem}
\begin{proof}
  Demostramos algunas de estas propiedades.
  \begin{enumerate}
  \item No podemos demostrarla en este curso, necesitamos el teorema de los residuos.
  \item Es fácil ver que $G$ y $\mathcal{F}[G]$ resuelven el siguiente PVI
    \[
      \begin{cases}
        G'(x) = (-2\pi x)G(x);\\
        G(0) = 1.
      \end{cases}
    \]
    Puesto que este PVI tiene una única solución (es lineal) deducimos que $\mathcal{F}[G] = G$. El
    mismo argumento de aplica a $\mathcal{F}^{-1}$.
  \item Es una consecuencia de la integración por partes.
  \item Basta realizar el cambio de variables $z = ax$. \qedhere
  \end{enumerate}
\end{proof}

\begin{definition}[Convolución de funciones]
  Sean $f,g : \R \to \R$ medibles. Se define la convolución de $f$ y $g$ en caso de que exista como la
  función
  \[ (f * g)(x) = \int_{-\infty}^{+\infty} f(x-y)g(y) \diff y. \]
\end{definition}

\begin{proposition}[Propiedades de la convolución]~

  \begin{enumerate}
  \item $f * g = g*f$.
  \item \emph{Desigualdad de Young}. Si $f \in \mathrm{L}^p(\R)$ y $g \in L^q(\R)$ con
    $1+1/r = 1/p + 1/q$. Entonces, existe $f * g$ y $||f*g||_{L^r} \le ||f||_{L^p}||g||_{L^q}$.
  \item $\mathcal{F}(f*g) = \mathcal{F}(f) \mathcal{F}(g)$.
    $\mathcal{F}(fg) = \mathcal{F}(f) * \mathcal{F}(g)$
  \item Si $f \in \mathrm{L}^2(\R)$ y
    $G_{\varepsilon}(x) = G(x/ \sqrt{\varepsilon}) / \sqrt{\varepsilon}$, que se llama aproximación
    de la unidad o sucesión regularizante, entonces
    $f * G_{\varepsilon} \in \mathcal{C}^{+\infty}(\R)$ y $f * G_{\varepsilon} \to f$ cuando
    $\varepsilon \to 0$ en $\mathrm{L}^2$.
  \item Transformada de la delta. $\mathcal{F}(\delta_0) = 1$.
  \item Si $f\in \mathrm{L}^1$ y $g \in \mathcal{C}^k$ es acotada, entonces $f*g \in \mathcal{C}^k$
    y es acotada.
  \end{enumerate}
\end{proposition}
\begin{proof}
  Las propiedades b) y d) no las podemos deostrar en este curso. El resto de las propiedades son
  fáciles de demostrar y se dejan como ejercicio.
\end{proof}

Ya podemos resolver la ecuación del calor en $\R$. Tomamos el cambio de variable
$u(t,x) = v(\sqrt{D}x, t)$. Tenemos que $\partial_t u = \partial_{xx}^2 u$. Por tanto, basta
resolver la ecuación del calor para $D = 1$.

\begin{theorem}
  Dada $f \in \mathcal{S}$ (resp. $\mathrm{L}^2$). Entonces la función
  \[ v(x,t) = \frac{1}{\sqrt{4 D \pi t}} \int_{\R} \exp\left(- \frac{(x-y)^2}{4 D t}\right) f(y)
    \diff y \] resuelve la ecuación del calor con la condición inicial $v(x,0) = f(x)$ en el sentido
  de la propiedad d) de la convolución.
\end{theorem}
\begin{proof}
  Resolvemos el problema de contorno
  \begin{equation}
    \label{eq:calor:1}
    \begin{cases}
      u_t = u_{xx}, \quad x \in \R, t \ge 0;\\
      u(x, 0) = \delta_0(x).
    \end{cases}
  \end{equation}
  Consideramos el cambio de variable $\mathcal{F}[u]$ (aplicar la transformada de Fourier en la
  variable $x$), mediante el cual obtenemos la ecuación equivalente
  \begin{equation}
    \label{eq:calor:fourier}
    \begin{cases}
      \partial_t \mathcal{F}[u] =- 4 \pi^2 x^2 \mathcal{F}[u], \quad x \in \R, t \ge 0;\\
      \mathcal{F}[u](x, 0) = 1.
    \end{cases}
  \end{equation}
  Deducimos que $\mathcal{F}[u](x,t) = \exp(-4 \pi^2 x^2 t) = (h_{\sqrt{4 \pi t}} G)(x)$.  Aplicando
  la transformada inversa de Fourier deducimos que
  \[u(x,t) = \mathcal{F}^{-1}[h_{\sqrt{4 \pi t}} G](x) = \frac{1}{\sqrt{4 \pi t}}
    \mathcal{F}^{-1}[G(\frac{x}{\sqrt{4 \pi t}})] = \frac{1}{\sqrt{4 \pi t}} \exp(-x^2 7 t). \] En
  este punto pretendemos resolver el problema de contorno
  \begin{equation}
    \label{eq:calor:4}
    \begin{cases}
      u_t = u_{xx}, \quad x \in \R, t \ge 0;\\
      u(x, 0) = f_0(x).
    \end{cases}
  \end{equation}
  Para ello definimos $w(x,t) = u(x,t) * f_0(x)$.  Por las propiedades de la convolución es fácil
  comprobar que $w$ es solución de \eqref{eq:calor:4}. Por último, recordemos que a partir de una
  solución de \eqref{eq:calor:4} podemos construir una solución de la ecuación del calor mediante el
  cambio $w(t,x) = v(t, \sqrt{D}x)$. Deducimos que la función dada en el enunciado es solución de la
  ecuación del calor.
\end{proof}

\begin{remark}
  La ecuación del calor no tiene en genreal solución única. En efecto, la función
  $u(x,t) = \sum_{k=0}^{+\infty} \frac{x^{2k}}{(2k)!} \frac{\partial^k}{\partial t^k}\left(
    e^{-1/t^2} \right)$ cumple
  \begin{equation}
    \label{eq:calor:5}
    \begin{cases}
      u_t = u_{xx}, \quad x \in \R, t \ge 0;\\
      u(x, 0) = 0.
    \end{cases}
  \end{equation}
  No obstante, si buscamos soluciones acotadas en $|x| \to +\infty$, entonces la única solución de
  la ecuación del calor es la dada en el teorema anterior.
\end{remark}

  
\begin{proposition}[Propiedades de las soluciones de la ecuación del calor]
  Las soluciones dadas en el teorema previo verifican las siguientes propiedades.
  \begin{enumerate}
  \item Conservación del digno. Si $f \ge 0$, entonces $u > 0$ para todo $t > 0$.
  \item Conservación de la masa (temperatura).
    \[ \int_{\R} v(x,t) \diff x = \int_{\R} f(x) \diff x \quad \forall t >0. \]
  \item Decaimiento en $t \to +\infty$. $\sup \{|v(x,t)| : x \in \R\} \le C / \sqrt{t}$.
  \item Velocidad infinita de propagación. Aunque inicialmente $\mathrm{sop}(f)$ esté acotado, para
    todo $t > 0$ $\mathrm{sop}(v) = \R$.
  \item Disipación de energía.
    \[ \frac{\partial}{\partial t}\int_{\R} v^2(x,t) \diff x = - \int_{\R} \left|
        \frac{\partial}{\partial x}v \right|^2 \diff x. \]
  \end{enumerate}
\end{proposition}
\begin{proof}
  Son un mero ejercicio.
\end{proof}

\subsection{Ecuaciones de reacción difusión}

Sea $u(x,t)$ la densidad de población que se mueve por difusión y que crece según la tasa
\[\alpha(u) =
  \begin{cases}
    \alpha_0 \text{(constante)}; \\
    \alpha_0 (1 - u / u_0); \\
    \alpha_0 (1 - u / u_0) (u / u_{min} -1).
  \end{cases}
\]

Estamos mezclando los conceptos estudiados en la secciones anteriores. Obtenemos la ecuación
\begin{equation}
  \label{eq:rea-dif}
  \partial_t u = D \Delta_x u + f(u)
\end{equation}

Solo vamos a estudiar esta ecuación en dos casos particulares. El primero se denomina FKPP (Fischer,
Kolmogorov, Petrovsky, Piskunov) y se corresponde con la ecuación
\begin{equation}
  \label{eq:rea-dif:1}
  \partial_t u = D \Delta_x u + \alpha_0 u \left(1- \frac{u}{ u_{\infty}}\right).
\end{equation}
El segundo caso se denomina biestable y se corresponde con la ecuación
\begin{equation}
  \label{eq:rea-dif:2}
  \partial_t u = D \Delta_x u + \alpha_0 u \left(1- \frac{u}{ u_{\infty}}\right)\left(\frac{u}{ u_{min}}-1\right).
\end{equation}
No tenemos herramientas para encontrar todas las solucines de estas ecuaciones o hacer teoremas de
unicidad. Nuestro objetivo es estudiar la existencia de soluciones del tipo \emph{onda viajera}. Una
onda viajera es una solución del tipo $u(x,t) = \phi(x-ct)$, donde $\phi \colon \R \to \R$ se
denommina \emph{perfil de la onda} y $c \in \R$ es la \emph{velocidad de la onda}. Trabajaremos en
dimensión 1, $x \in \R$.

En primer lugar vamos a adimensionalizar las soluciones. Distinguimos dos casos en función de la
ecuación con la eque trabajamos.
\begin{enumerate}
\item En FKPP, tomamos el cambio de variable
  $v(y, \tau) = u(\sqrt{D / \alpha_0} y, \tau / \alpha_0) / u_{\infty}$. Recordemos que
  $[[ \alpha_0 ]] = 1 / \text{tiempo}$ y $[[ \sqrt{D / \alpha_0} ]] = \text{espacio}^2$. Obtenemos que
  \begin{equation}
    \label{eq:rea-dif:1:ad}
    \partial_{\tau} v = \partial^2_{yy} v + v(1-v).
  \end{equation}
  De aquí en adelante denotaremos por $u$ a las soluciones de la ecuación anterior. No se deben
  confundir con las soluciones de la ecuación original.
\item En el caso biestable realizamos el cambio
  \[ v(y, \tau) = u \left( \sqrt{\frac{D u_{min}}{\alpha u_{\infty}}}, \frac{\tau u_{min}}{\alpha
        u_{\infty}} \right) / u_{\infty}. \] Obtenemos la ecuación
  \begin{equation}
    \label{eq:rea-dif:2:ad}
    \partial_{\tau} v = \partial_{yy}^2 v + v(1-v)(v-\beta),
  \end{equation}
  donde $0 < \beta < u_{min}/u_{\infty} < 1$.
\end{enumerate}

Veamos qué ha de cumplir una onda viajera $u(x,t) = \phi(x-ct)$ para ser solución de
\begin{equation}
  \label{eq:rea-dif:f:1}
  \partial_t u = \partial_{xx}^2 u + f(u).
\end{equation}
Buscamos ondas viajeras tales que $\lim_{x \to -\infty} \phi(x) = 1$, $\lim_{x \to -\infty} \phi(x) = 0$
y $\phi$ es decreciente. Deducimos que $\phi$ es solución de la ecuación
\begin{equation}
  \label{eq:rea-dif:f:phi}
  -c \phi' = \phi'' + f(\phi).
\end{equation}
Es decir, $\phi$ cumple una ecuación diferencial ordinaria. 

Multiplicando por $\phi'$ e integrando
obtenemos que
\[ c \int_{-\infty}^{+\infty} (\phi'(\xi))^2 \diff \xi = \int_0^1 f(z) \diff z.\]

ya que
\[ \int_{-\infty}^{+\infty} \phi'' \phi' \diff \xi = \frac{1}{2} \int_{-\infty}^{\infty}
  \frac{\partial}{\partial \xi} (\phi'(\xi))^2 \diff \xi = \frac{\phi'(+\infty)^2 -
    \phi'(-\infty)^2}{2} = 0\] y
\[ \int_{-\infty}^{+\infty} f(\phi(\xi)) \phi'(\xi) \diff \xi = \int_1^0 f(z) \diff z.\]
Si el problema es FKPP, entonces $\int_0^1 f(z) \diff z > 0$, obteniendo que $c >0$. Si el problema es biestable, entonces
\[ \int_0^1 f(z) \diff z = \int_0^1 z(1-z)(z-\beta) \diff z = \frac{1}{6}(\frac{1}{2} - \beta).\]
Por tanto, el signo de $c$ depende de $\beta$. 

\subsubsection{Ondas viajeras en la biestable}

En este caso particular la función $\phi$ verifica la ecuación
\begin{equation}
  \label{eq:rea-dif:2:phi}
  \phi'' + c \phi' + \phi(1-\phi)(\phi - \beta) = 0.
\end{equation}
Buscamos $\phi$ cumpliendo $\phi'(\xi) = A\phi(\xi)(1-\phi(\xi))$ para cierto $A$. Obtenemos en tal caso que
$\phi'' = A \phi'(1-\phi) - A \phi \phi'$. Podemos substituir en \eqref{eq:rea-dif:2:phi} obteniendo la ecuación equivalente 
\[ \phi' \left[ A + c - \frac{\beta}{A} + \phi \left( -2A + \frac{1}{A} \right) \right] = 0.\]
Puesto que queremos que $\phi$ sea estrictamente decreciente, debe cumplirse que $A + c - \frac{\beta}{A} = 0$ y $-2A + \frac{1}{A} = 0$. Por tanto, $A = 1 / \sqrt{2}$ y $c = \sqrt{2}(1/2 - \beta)$. Podemos resolver para este $A$ la ecuación $\phi'(\xi) = A\phi(\xi)(1-\phi(\xi))$ mediante el método de variables separadas. Obtenemos que $\phi(\xi) = 1 / (1 + k \exp(\xi / \sqrt{2}))$ para $k > 0$. Esta solución verifica las hipótesis que buscábamos, luego es solución por el razonamiento previo de \eqref{eq:rea-dif:2:phi} para $c = \sqrt{2} (1/2  \beta)$. Hemos encontrado ondas viajeras para $c$ específicos.

\subsection{Ondas viajeras en FKPP}

En este caso particular la función $\phi$ verifica la ecuación
\begin{equation}
  \label{eq:rea-dif:1:phi}
  \phi'' + c \phi' + \phi(1-\phi) = 0.
\end{equation}

\begin{lemma}
  Para cada $c \ge 2$ existe una única $\phi$ tal que $u(x,t) = \phi(x-ct)$ es solución de
  \eqref{eq:rea-dif:1:ad}.
\end{lemma}
\begin{proof}
  Sabemos que \eqref{eq:rea-dif:1:phi} es equivalente al sistema
  \begin{equation}
    \label{eq:rea-dif:1:phi:s}
    \begin{cases}
      u' = v; \\
      v' = -c v + u (1-u).
    \end{cases}
  \end{equation}
  Nótese que $(0,0)$ y $(1,0)$ son puntos de equilibrio de esta ecuación. Utilizamos el primer
  método de Lyapunov para estudiar la estabilidad asintótica. Nótese que
  \[\mathrm{J}f(0,0) =\left(
      \begin{matrix}
        0 & 1 \\ -1 & -c
      \end{matrix}
    \right). \] Deducimos que $\mu < 0$ si $c > 0$, donde $\mu$ es el máximo de la parte real de los
  valores propios. En tal caso, $(0,0)$ es un atractor. Si $0 < c < 2$, entonces es un atractor en
  espiral, luego todas las soluciones tomarán valores positivos en $u$ en algún momento, por lo que
  $\phi$ no será creciente. Suponemos pues que $c \ge 2$, en cuyo caso los valores propios son
  números negativos. Nótese que
  \[\mathrm{J}f(0,0) =\left(
      \begin{matrix}
        0 & 1 \\ 1 & -c
      \end{matrix}
    \right). \] Los valores propios son $\lambda_+ = (-c + \sqrt{c^2 + 4})/ 2 > 0$ y
  $\lambda_- = (-c - \sqrt{c^2 + 4})/ 2 < 0$. $(1,0)$ es un punto de silla. Vamos a demostrar que la
  solución que sale de $(1,0)$ con $t_0 = -\infty$ tiene límite $(0,0)$ en $+\infty$ con $u$
  decreciente. Por el estudio del punto de equilibrio $(1,0)$ sabemos que una de las soluciones que
  salen de este se mantiene con $u < 0$ cerca de $(1,0)$. Esta es la solución que tomamos. Me he
  perdido en la demostración, la mitad de las cosas no las hemos estudiado en ecuacines
  diferenciales.
\end{proof}



\section{Bibliografía}

- Elsgoltz....

\end{document}
