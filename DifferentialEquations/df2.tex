%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Apuntes de la asignatura ecuaciones diferenciales 2.
%
% Autores: Andrés Herrera Poyatos (https://github.com/andreshp)
%          Paco Luque Sánchez (https://github.com/pacron)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%-----------------------------------------------------------------------------------------------------
%	INCLUSIÓN DE PAQUETES BÁSICOS
%-----------------------------------------------------------------------------------------------------

\documentclass{article}

% Utiliza el paquete de español.
\usepackage{spanish}
% Utiliza la plantilla para reports.
\usepackage{template}
% Utiliza una portada (elija una de las portadas disponibles y comente el resto).
\usepackage{title1}
%\usepackage{title2}

%-----------------------------------------------------------------------------------------------------
%	OTROS PAQUETES
%-----------------------------------------------------------------------------------------------------

\usepackage{mathematics}

%-----------------------------------------------------------------------------------------------------
%	DATOS DEL DOCUMENTO
%-----------------------------------------------------------------------------------------------------

\newcommand{\doctitle}{Apuntes}
\newcommand{\docsubtitle}{}
\newcommand{\docdate}{\date}
\newcommand{\subject}{Ecuaciones Diferenciales 2}
\newcommand{\docauthor}{Andrés Herrera Poyatos \\ Paco Luque Sánchez}
\newcommand{\docaddress}{Universidad de Granada}
\newcommand{\docemail}{andreshp9@gmail.com}
\newcommand{\docabstract}{}

\begin{document}

\maketitle

\section{Introducción}

\subsection{Notación y terminología}

En esta sección haremos una pequeña introducción a los problemas que abordaremos en esta
asignatura. Vamos a estudiar propiedades de las soluciones de una ecuación diferencial de la que no
podemos calcular explícitamente las mismas. Estudiaremos ecuaciones diferenciales ordinarias (que
abreviaremos EDO). Una EDO es una ecuación de la forma
\[x'(t) = f(t,x(t)) \text{ con } (t,x(t)) \in D,\]

donde $D \subset \R \times \R^d$ es un conjunto abierto y arcoconexo y $f: D \to \R^d$ es una
función continua. Los elementos que intervienen en una EDO tienen una terminología específica que
introducimos a continuación:

\begin{itemize}
\item $D$: dominio de la ecuación.
\item $f$: campo de la ecuación.
\item $t$: variable independiente.
\item $x(t)$: función incógnita o variable dependiente. En lo que sigue, por comodidad, la notaremos
  simplemente por $x$, sin especificar la variable de la que depende.
\end{itemize}

\begin{ex} Veamos algunos ejemplos de ecuaciones diferenciales ordinarias.
  
  \begin{itemize}
  \item EDO escalar:
    \[x' = \frac{x}{t} \text{ con } t > 0,\] donde $D = (0, +\infty)* \R$.
  \item Sistema de EDOs:
    \[
      \left.
        \begin{array}{r}
          x_1' = x_1x_2 + t \\
          x_2' = x_1 + x_2 + t^2
        \end{array}
      \right\}
    \]
    donde $D = \R \times \R^2$ y $f(t, x_1, x_2) = (x_1x_2 + t, x_1 + x_2 + t^2)$. \qedhere
  \end{itemize}
\end{ex}

  \begin{definition}[Concepto de solución]
    Una solución de una EDO es una función $\varphi: I \to \R^d$ donde $I$ es un intervalo abierto
    no vacío, tal que:
    \begin{enumerate}
    \item $\varphi \in \mathcal{C}^1(I, \R^d)$;
    \item $(t, \varphi(t)) \in D$;
    \item $\varphi'(t) = f(t, \phi(t))$ para todo $t \in I$.
    \end{enumerate}

  \end{definition}

  \begin{definition}[Problema de valores iniciales]
    Un problema de valores iniciales o problema de Cauchy (de aquí en adelante lo abreviaremos PVI)
    consiste en añadir a una EDO un dato o condición inicial, esto es, un par $(t_0, x_0) \in D$.
    Normalmente se nota como:
    \begin{equation}
      \label{eq:pvi}
      \left\{
        \begin{array}{l}
          x' = f(t,x); \\
          x(t_0) = x_0.
        \end{array}
      \right.
      \tag{P}
    \end{equation}
    Una solución del PVI es una solución de la EDO que cumple, además:
    \begin{enumerate}
    \item $t_0 \in I$;
    \item $\varphi(t_0) = x_0$.
    \end{enumerate}
  \end{definition}

  En lo que sigue nos referiremos a \eqref{eq:pvi} cuando trabajemos con un PVI genérico. 
  
  \subsection{Unicidad de solución y soluciones maximales}

  Consideremos un PVI
  \begin{equation}
    \left\{
      \begin{array}{l}
        x' = f(t,x); \\
        x(t_0) = x_0.
      \end{array}
    \right.
    \tag{P}
  \end{equation}

  Denotamos como
  $\sum = \sum(P) = \{(I, \varphi) \ | \ \varphi: I \to \R^d \text{ es solución de \eqref{eq:pvi}}\}$. Diremos que
  $(\widetilde{I}, \widetilde{\varphi}) \in \sum$, es una prologación de $(I, \varphi) \in \sum$ si
  $I \subsetneq \widetilde{I}$ y $\widetilde{\varphi}_{|I} = \varphi$.  Un elemento de $\sum$ es prolongable
  si admite una prolongación. Si $(\widetilde{I}, \widetilde{\varphi})$ es una prolongación de
  $(I, \varphi)$, lo notaremos como $(I, \varphi) >> (\widetilde{I}, \tilde{\varphi})$. Diremos que
  $(I, \varphi)$ es maximal si no es prolongable.

  \subsubsection{Conceptos de unicidad}

  Diremos que $(P)$ verifica la propiedad de unicidad local si dadas
  $(I_1, \varphi_1), (I_2, \varphi_2) \in \sum, \exists H$ intervalo abierto, tal que
  $\varphi_1(t) = \varphi_2(t)\,\,\, \forall t \in I_1 \cap I_2 \cap H$, $t_0 \in H$.

  Diremos que $(P)$ verifica la propiedad de unicidad en $H$, con $H$ intervalo abierto y
  $t_0 \in H$ si dadas $(I_1, \varphi_1), (I_2, \varphi_2) \in \sum$, se cumple que
  $\varphi_1(t) = \varphi_2(t)\,\,\, \forall t \in I_1 \cap I_2 \cap H$.

  Finalmente, diremos que $(P)$ verifica la propiedad de unicidad global si dadas
  $(I_1, \varphi_1), (I_2, \varphi_2) \in \sum$, se cumple que
  $\varphi_1(t) = \varphi_2(t)\,\,\, \forall t \in I_1 \cap I_2$.

\begin{lem}
  Sean $\varphi_1: I_1 \to \R^d$ y $\varphi_2: I_2 \to \R^d$ soluciones de un PVI tales que
  $\exists \tau \in I_1 \cap I_2$ tal que $\varphi_1(\tau) = \varphi_2(\tau)$.  Entonces
  \[
    \psi(t) = \left\{
      \begin{array}{l}
        \varphi_1(t) \quad t \leq \tau \\
        \varphi_2(t) \quad t > \tau
      \end{array}
    \right.
  \]
  es solución del PVI.
\end{lem}

\begin{lem}
  Si $\forall (t_0, x_0) \in D$ el PVI
  \[
    \left\{
      \begin{array}{l}
        x' = f(t,x) \\
        x(t_0) = x_0
      \end{array}
    \right.
  \]
  unicidad global
\end{lem}

\begin{proof}
  Sean $(I_1, \varphi_1), (I_2, \varphi_2) \in \sum (P)$. Definimos
  $H = \{ t \in I_1 \cap I_2; \varphi_1(t) = \varphi_2(t)\}$. Tenemos que:
  \begin{itemize}
  \item $H \neq \emptyset \quad (t_0 \in H)$
  \item $H$ es un cerrado relativo por ser el conjunto donde coinciden dos funciones continuas.
  \item $H$ es abierto. Veamos la demostración:\\
    Sea $\tau \in H$ y consideremos el PVI $(\tilde{P})=\{x'= f(t, x), x(\tau) =
    \varphi_1(\tau)\}$. Por la propiedad de unicidad local $\exists \tilde{H}$ intervalo con
    $\tau \in \tilde{H} = \dot{\tilde{H}}$ tal que
    $\varphi_1(t) = \varphi_2(t) \quad \forall t \in \tilde{H} \cap I_1 \cap I_2 \Rightarrow
    \tilde{H} \cap I_1 \cap I_2 \subset H$
  \end{itemize}
  Esto implica que $H = I_1 \cap I_2$, y por tanto se verifica la propiedad de unicidad local.
\end{proof}

\subsection{Ecuación integral de Volterra}

Dada una solución del PVI
\[
\left\{
  \begin{array}{l}
    x' = f(t,x) \\
    x(t_0) = x_0
  \end{array}
\right.
\]
$x'(s) = f(s,x(s))$ para todo $s$ en un intervalo. Si integramos la
expresión, obtenemos:
$$ \int_{t_0}^t x'(s)ds = \int_{t_0}^tf(s,x(s))ds \Rightarrow x(t) = x_0 + \int_{t_0}^t f(s, x(s))ds $$
A esta ecuación se le conoce como ecuación integral de Volterra. Sea
$\varphi: I \to \R^d$ con $I$ intervalo abierto. Diremos que es
solución de la ecuación integral de Volterra si:

\begin{itemize}
\item $\varphi \in \mathcal{C}(I, \R^d)$
\item $(t, \varphi(t)) \in D \quad \forall t \in I$
\item $t_0 \in I$
\item
  $\forall t \in I \Rightarrow \varphi(t) = x_0 +
  \displaystyle\int_{t_0}^t f(s, \varphi(s))ds$
\end{itemize}

Veamos ahora una proposición que conecta el concepto de PVI con la
ecuación integral de Volterra:

\begin{prop}
  Sea $\varphi: I \to \R^d$, $I$ intervalo abierto. Son equivalentes:
  \begin{enumerate}
  \item $\varphi$ es solución del PVI
  \item $\varphi$ es solución de la ecuación integral de Volterra
  \end{enumerate}
\end{prop}

\begin{proof}
  La demostración se basa en deducir las propiedades de las soluciones
  del PVI a partir de las de las soluciones de la EIV y viceversa. Las
  propiedades 2 y 3 son comunes para las soluciones del PVI y de la
  EIV. Empezamos deduciendo las propiedades de la EIV a partir de las
  del PVI:
  \begin{enumerate}
  \item La derivabilidad de la solución del PVI nos implica la
    continuidad de la solución de la EIV
  \item Para ver la propiedad cuatro, integramos entre $t_0$ y $t$ la
    igualdad $\varphi'(t) = f(t, \varphi(t))$ y la obtenemos
    inmediatamente
  \end{enumerate}
  Vemos ahora las propiedades de las soluciones del PVI a partir de
  las de la EIV.  Usando el teorema fundamental del cálculo, tenemos
  que $\varphi'(t) = 0 + f(t, \varphi(t))$.  Esto implica que
  $\varphi$ es derivable en $I$, y que cumple la tercera propiedad de
  las soluciones del PVI. Finalmente, tenemos que
    $$ \varphi(t_0) = x_0 + \sum_{t_0}^{t_0} f(s, \varphi(s))ds = x_0 $$
  \end{proof}

  Vamos a ver un ejemplo de cómo se relacionan los dos conceptos que
  hemos estado tratando:

\begin{ex}
  \textbf{Enunciado:} Resolver la EIV: $x(t) = 8 + \displaystyle\int_0^t x(s)^2 ds$\\

  \textbf{Solución:} Derivando la EIV respecto de $t$, obtenemos el
  PVI:
  \[
  \left\{
    \begin{array}{l}
      x'(t) = x(t)^2 \\
      x(0) = 8
    \end{array}
  \right. \Rightarrow \frac{dx}{dt} = x^2 \Rightarrow \frac{dx}{x^2} =
  dt
  \]
  Discutimos el caso de las soluciones constantes primero. Para que la
  solución sea constante, tenemos que $x' = x^2$, que sólo ocurre si
  $x(t) = 0 \quad \forall t$.  Esto no es posible ya que tenemos que
  $x(0) = 8$. Por tanto, no tenemos soluciones constantes. Discutimos
  ahora el caso de las soluciones no constantes. Integrando en ambos
  miembros de la igualdad de la derecha, obtenemos lo siguiente:

    $$ \int \frac{dx}{x^2} = \int dt \Rightarrow \frac{-1}{x} = t + c \Rightarrow
    x = \frac{1}{-t-c} $$

    Y usando el dato inicial tenemos que
    $ 8 = \frac{1}{-c} \Rightarrow c = \frac{-1}{8}$, por lo que
    tenemos que el candidato a solución es $x =
    \frac{8}{1-8t}$.
    Definimos $\varphi: (-\infty, \frac{1}{8}) \to \R$ con
    $\varphi(t) = \frac{8}{1-8t}$ y comprobamos que sea solución:

    $$ \varphi(0) = 8 \quad \quad \varphi'(t) = \frac{64}{(1-8t)^2} = \varphi^2(t) $$

    Es solución del PVI, lo que implica que es solución de la EIV de
    partida por el teorema anterior.
  \end{ex}

  \textbf{Operador integral}\\

  Dada la EIV
  $ x(t) = x_0 + \displaystyle\int_{t_0}^t f(s, x(s)) ds $, queremos
  definir un operador de la siguiente manera:
  \[\arraycolsep=1pt\def\arraystretch{1}
  \begin{array}{llll}
    V: & E \to F     &           & \\
       & y \to V(y): & I \to R^d & \\
       &             & t \to V(y)(t) & := x_0 + \displaystyle\int_{t_0}^t f(s,y(s))ds
  \end{array}
  \]
  Para definir después la siguiente sucesión recurrente:
  \[
  \left\{
    \begin{array}{l}
      y_0 \in E \\
      y_{n+1} = V(y_n), \quad y_n \in E
    \end{array}
  \right.
  \]

  Tendremos una solución $\Leftrightarrow V(x) = x \quad (E=F)$.

  \subsection{Algunos teoremas de existencia y unicidad}

\begin{thm}[Existencia y unicidad en variables separadas]
  Sean $ a \in \mathcal{C}(J_1)$ y $g \in \mathcal{C}(J_2)$,
  $J_1, J_2$ intervalos abiertos.  Sean $t_0 \in J_1, x_0 \in
  J_2$. Consideramos:

\begin{equation}
  \left\{
    \begin{array}{l}
      x' = a(t)g(x), (t,x) \in J_1 \times J_2 \\
      x(t_0) = x_0
    \end{array}
  \right.
  \tag{P}
\end{equation}

Entonces, se verifican:
\begin{description}
\item[i)] El PVI $(P)$ tiene solución
\item[ii)] Si $g(x_0) \neq 0$ el PVI $(P)$ verifica la propiedad de
  unicidad local.
\item[iii)] Si $g(x_0) = 0$ y existe $ G \in \mathcal{C} (J_2)$ tal
  que $G(x_0) = 0$ y existe
  $\delta > 0: G'(x) = \frac{1}{g(x)} \forall x \in J_2 \cap ]x_0, x_0
  + \delta[$
  y además $a(t_0) \neq 0$, entonces el PVI no verifica la propiedad
  de unicidad local.
\end{description}
\end{thm}

\begin{proof}
  Comenzamos demostrando \textbf{i)}. Distinguimos dos casos:\\

  \textbf{Caso 1:} $g(x_0) = 0$. Entonces, $\varphi: \R \to \R$ tal
  que
  $\varphi(t) = x_0$ es una solución de $(P)$.\\

  \textbf{Caso 2:} $g(x_0) \neq 0$. Entonces, existe $I_1$ abierto tal
  que $x_0 \in I_1, g(x) \neq 0 \quad \forall x \in I_1$. Tomamos
  entonces la aplicación que asigna a $x$ el valor
  $\frac{1}{g(x)} \in \mathcal{C}(I_1)$.  Sea ahora la aplicación
  $ G: I_1 \to \R$ tal que $G(x_0) = 0, G'(x) = \frac{1}{g(x)}$.
  Tenemos que $G$ es estrictamente monótona. Tomamos $I_2 = G(I_1)$
  intervalo abierto. Entonces, $\exists G^{-1}: I_2 \to \R$ con
  $G^{-1}(I_2) = I_1$. Además, tenemos que
  $G^{-1} \in \mathcal{C}(I_2)$, con
  $(G^{-1})' (x) = \frac{1}{G'(G^{-1}(x))} = g(G^{-1}(x)) \forall x
  \in I_2$.
  Sea ahora $A = A(t)$ una primitiva de $a(t)$ tal que
  $A(t_0) = 0 \in I_2$.  Por continuidad, $\exists I_3 \subset J_1$
  abierto tal que $t_0 \in I_3$, $A(I_3) \subset I_2$. Definimos:
  \begin{align*}
    \varphi : & I_3 \to \R \in \mathcal{C}^1(I_3) \\
              & t \to G^{-1}(A(t))
  \end{align*}

  Tenemos que $t_0 \in I_3$,
  $\varphi(t_0) = G^{-1}(a(t_0)) = G^{-1}(0) = x_0$. Tenemos que
  $(t, \varphi(t)) \in J_1 \times J_2$ y
  $\varphi'(t) = g(G^{-1}(A(t))a(t) = a(t)g(\varphi(t)) \quad \forall
  t \in I_3$ \\

  Pasamos ahora a demostrar \textbf{ii)}. Sean
  $\varphi_1: H_1 \to \R$, $\varphi_2: H_2 \to \R$ dos soluciones de
  $(P)$.
  % TODO: Terminar demostración
\end{proof}

\begin{definition}
  \label{def:unicidad-futuro}
  Sea $D \subset \mathbb{R} \times \mathbb{R}$ abierto y
  $f \in \mathcal{C}(D)$. Fijamos $(t_0, x_0) \in D$ y consideramos el
  PVI asociado. Diremos que Diremos que el PVI verifica la propiedad
  de unicidad en el futuro si tiene unicidad en el intervalo
  $[t_0, +\infty[$ y, análogamente, diremos que el PVI verifica la
  propiedad e unicidad en el pasado si tiene unicidad en el intervalo
  $]-\infty, t_0]$.
\end{definition}

\begin{thm}[Teorema de unicidad de Peano]
  Sea $D \subset \mathbb{R} \times \mathbb{R}$ abierto y
  $f \in \mathcal{C}(D)$. Fijamos $(t_0, x_0) \in D$ y consideramos el
  PVI (P) asociado.
  \begin{enumerate}
  \item\label{item:peano:a} Si para cada $t \ge t_0$ la función
    $g(x) = f(t,x)$ es decreciente, entonces (P) verifica la unicidad
    en el futuro.
  \item\label{item:peano:b} Si para cada $t \le t_0$ la función
    $g(x) = f(t,x)$ es creciente, entonces (P) verifica la unicidad en
    el pasado.
  \end{enumerate}
\end{thm}

\section{Existencia y unicidad de solución} \label{sec:eu}

\subsection{Herramientas previas}

\subsubsection{Funciones lipschitzianas}

\subsubsection{Operador integral de Volterra}

Introducimos la siguiente notación. Dado $(t_0, x_0) \in \mathbb{R} \times \mathbb{R}^d$ y dados
$a,b > 0$ denotamos $R_{a,b}(t_0, x_0) = [t_0+a, t_0-a] \times \overline{B}(x_0, b)$. Consideramos
el conjunto $E = B(x_0, b) \subset \mathcal{C}([t_0-a, t_0+a]; \mathbb{R}^d)$ con la norma infinito.

\begin{lem}
  Si $aM \le b$, entonces $V(\varphi) \in E$
\end{lem}

\begin{lem}
  Si la función $f$ es lipschitziana respecto de la segunda variable en $R_{a.b}(t_0, x_0)$,
  entonces
  \[||V(\varphi) - V(\Psi)||_{\infty} \le La||\varphi - \Psi||_\infty.\]
\end{lem}

\begin{proof}
  Sea $t \in [t_0-a, t_0+a]$. Tenemos que
  \[ (V(\varphi) - V(\Psi))(t) = \int_{t_{0}}^t \left[f(s, \varphi(s)) - f(s, \Psi(s))\right] \diff
    s.\] Tomamos normas y acotamos la integral
  \[|(V(\varphi) - V(\Psi))(t)| \le \left|\int_{t_{0}}^t \left|f(s, \varphi(s)) - f(s,
        \Psi(s))\right| \diff s\right| \le \left|\int_{t_{0}}^t L |\varphi(s) - \Psi(s)| \diff s
    \right| \le L a ||\varphi - \Psi||_{\infty}\] \qedhere
\end{proof}

\begin{rem}
  Si $a M \le B$ y $\varphi: [t_0-a, t_0+a] \to \mathbb{R}^d$ es solución del PVI, entonces
  $(t, \varphi(t)) \in R_{a,b}$ para todo $t \in (t_0-a, t_0+a)$.
\end{rem}

\subsection{Teorema de Picard-Lindelöf}

En este apartado estudiamos el Teorema de Picard-Lindelöf, que también se conoce como Teorema de
Picard, Teorema de Cauchy - Lipschitz o Teorema de Existencia y Unicidad. Es el principal resultado
de existencia y unicidad de solución para PVIs. Existen numerosas versiones del resultado y, además,
múltiples demostraciones.

\begin{thm}
  Sean $D \subset \mathbb{R} \times \mathbb{R}^d$, $f: D \to \mathbb{R}^d$ continua y localmente
  lipschitziana respecto de la segunda variable. Dado $(t_0, x_0) \in D$, el PVI
  \begin{equation}
    \label{eq:pl:pvi}
    \begin{cases}
      x' = f(t,x); \\ x(t_0) x_0;
    \end{cases}
  \end{equation}
  tiene solución y es única tanto en sentido local como global.
\end{thm}
\begin{proof}
  Existe $U \subset D$ entorno de $(t_0, x_0)$ y $L \ge 0$ tal que $f$ es lipschitziana respecto de
  la segunda variable en $U$ con constante de Lipschitz $L \ge 0$. Existen
  $\overline{a}, b \in \mathbb{R}^+$ tal que $R_{\overline{a},b}(t_0, x_0) \subset U$. Por el
  teorema de Weierstrass, existe $M = \max R_{\overline{a},b}(t_0, x_0)$. Tomamos
  $0 < a < \overline{a}$ tal que $a M < b$ y $a L < 1$. En el nuevo recinto $R_{a,b}(t_0, x_0)$ se
  cumplen todas las propiedades que se requieren para finalizar la demostración. Definimos
  \[E = \{\varphi \in \mathcal{C}([t_0-a, t_0+a], \mathbb{R}^d): ||\varphi(t)-x_0|| \le b \ \forall
    t \in [t_0-a, t_0+a]\}.\] Por los lemas anteriores tenemos que $V(E) \subset E$ y $V$ es
  contractiva. La existencia de solución se deduce del Teorema del punto fijo de Banach. Estudiemos
  ahora la unicidad del problema. Dadas dos soluciones de \eqref{eq:pl:pvi},
  $\varphi_1: I_1 \to \mathbb{R}$ y $\varphi_2: I_2 \to \mathbb{R}$ ,existe que además nos
  proporciona unicidad local en $(t_0, x_0)$.  De la arbitrariedad de $(t_0, x_0)$ deducimos que la
  EDO verifica la propiedad de unicidad local en cualquier punto $(t_0, x_0) \in D$.
\end{proof}

Recuérdese en este punto que el Teorema del punto fijo de Banach nos dice además que dado un
elemento $\varphi_0 \in E$, la sucesión $\varphi_n = V^n(\varphi)$ converge en norma a la solución
de \ref{eq:pl:pvi}. Puesto que estamos usando la norma infinito, esta convergencia equivale a la
convergencia uniforme. A la sucesión $\varphi_n$ se le denomina iterantes de Picard.

\begin{ex}[Iterantes de Picard]
  Consideramos el PVI
  \begin{equation}
    \begin{cases}
      x' = x^2; \\ x(0) = 1.
    \end{cases}
  \end{equation}
  Para este PVI obtenemos $f(t,x) = x^2$. En el entorno $U = \mathbb{R} \times [0,2]$ de $(0,1)$
  tenemos que $f$ es lipschitziana respecto de la segunda variable con constante de Lipschitz
  $L = 4$ y está acotada por $M = 4$. Tomamos pues $a = 1/8$. Podemos definir en $R_{a,b}(0,1)$ las
  iterantes de Picard.
\end{ex}

\subsection{Existencia y unicidad de soluciones maximales}

\begin{thm} \label{thm:sol-maximal} Sea $D \subset \mathbb{R} \times \mathbb{R}^d$ un conjunto
  abierto y $f : D \to \mathbb{R}^d$ continua y localmente lipschitziana. Entonces, para cualquier
  $(t_0, x-0) \in D$ el PVI
  \begin{equation}
    \label{eq:sol-maximal:pvi}
    \begin{cases}
      x' = f(t,x); x(t_0) = x_0;
    \end{cases}
  \end{equation}
    tiene una única solución maximal.
\end{thm}

\begin{rem}
  Para deducir la tesis del Teorema \ref{thm:sol-maximal} es suficiente que exista unicidad
  global.
\end{rem}

\begin{proof}
  Consideramos la familia
  $\Sigma(P) = \{(I, \varphi) : \varphi:I \to \mathbb{R} \text{ es solución de
    \eqref{eq:sol-maximal:pvi}}\}$. Definimos $J = \cup_{(I, \varphi) \in \Sigma(P)} I$, que es un
intervalo ya que es unión de conexos de $\mathbb{R}$ que tienen un punto en común. Además, $J$ es abierto porque es unión de abiertos. Definimos la función $\Psi : J \to \mathbb{R}^d$ como $\Psi(t) = \varphi(t)$ para algún $(\varphi, I) \in \Sigma(P)$ con $t \in I$. Nótese que la función está bien definida gracias a la unicidad global. Además, $\Psi$ es solución de \eqref{eq:sol-maximal:pvi}. Es claro por construcción que $\Psi$ es solución maximal.
\end{proof}

Utilizaremos la siguiente notación para indicar el dominio de una solución maximal
\[\varphi: (\alpha, \omega) \to \mathbb{R}^d \text{ con } -\infty \leq \alpha < t_0 < \omega \leq +\infty.\]
Algunos autores escriben $(\omega_-, \omega_+)$ en lugar de $(\alpha, \omega)$. No obstante, la notación que hemos escogido nos facilita la escritura.

\subsection{Solución general}

Dado $D \subset \mathbb{R} \times \mathbb{R}^d$ y $f : D \to \mathbb{R}^d$ continua y localmente lipschitziana. Fijado $(t_0, x_0) \in D$ denotaremos $\alpha(t_0, x_0)$ y $\omega(t_0, x_0)$ al extremo inferior y superior,, respectivamente, de la solución maximal del PVI asociado a la condición inicial $x(t_0) = x_0$. Definimos el conjunto
\[\Omega = \{(t, t_0, x_0) \in \mathbb{R}\times\mathbb{R}\times\mathbb{R}^d : (t_0, x_0) \in D, \alpha(t_0, x_0) < t < \omega(t_0, x_0)\}\]
y la llamada \emph{solución general} $X: \Omega \to \mathbb{R}^d$ a partir del Teorema de Picard-Lindelöf como aquella función diferenciable en la primera variable que verifica $X_t(t, t_0, x_0) = f(t, X(t, t_0, x_0))$ y $X(t_0, t_0, x_0) = x_0$. Esto es, la función $\varphi(t) = X(t, t_0, x_0)$ es la solución del PVI asociado a $(t_0, x_0)$.

\section{EDOs autónomas escalares}

\begin{definition}
Una EDO autónoma escalar es una EDO de la forma
\begin{equation}
  \label{eq:edo:ae}
  x' = f(x), \ x \in I,
  \tag{AE}
\end{equation}
donde $I \subset \R$ es un intervalo abierto y $f : I \to \R$ es una función localmente
lipschitziana. Para cada $x_0 \in I$ denotamos por $X(t; x_0)$ a la única solución maximal de
\eqref{eq:edo:ae} que verifica $x(0) = x_0$. 
\end{definition}

Nótese que $X(t; x_0)$ está bien definida gracias al Teorema de Picard-Lindelöf. De aquí en adelante nos referiremos a \eqref{eq:edo:ae} cuando utilicemos EDOs autónomas escalares en un contexto general.

\begin{definition}
  Se define la órbita de \eqref{eq:edo:ae} asociada a $x_0$ como el conjunto imagen de $X(t; x_0)$ y
  se denota $\Theta(x_0)$.
\end{definition}

Nótese que la órbita de \eqref{eq:edo:ae} asociada a $x_0$ es un intervalo, que solamente es trivial
cuando la solución es constante, lo que sucede si, y solo si, $f(x_0) = 0$.

Como consecuencia del Teorema de Picard-Lindelöf obtenemos fácilmente el siguiente resultado.

\begin{prop}
  Las órbitas de \eqref{eq:edo:ae} constituyen una partición de $I$. Como consecuencia, si $p$ es un
  punto de equilibrio de \eqref{eq:edo:ae}, esto es, $f(p) = 0$, y $x_0 \ne p$, entonces
  $X(t, x_0) \ne p$ para todo $t \in (\alpha(x_0), \omega(x_0))$. Por tanto,
  $\Theta(x_0) \subset (-\infty, p)$ o $\Theta(x_0) \subset (p, \infty)$.
\end{prop}
\begin{proof}
  Es claro que $\cup_{x_0 \in I} \Theta(x_0) = I$. Sean ahora $x_0, x_0' \in I$ tales que
  $\Theta(x_0) \cap \Theta(x_0') \ne \emptyset$. Denotamos $\varphi_1(t) = X(t; x_0)$ y
  $\varphi_2(t) = X(t; x_0')$. Existen $t_1$ y $t_2$ tales que $\varphi(t_1) =
  \varphi_2(t_2)$. Definimos $\phi(t) = \varphi_2(t + (t_2 - t_1))$, que es solución de \eqref{eq:edo:ae} y verifica $\phi(t_1) = \varphi_2(t_2) = \varphi_1(t_1)$. Por el Teorema de Picard-Lindelöf obtenemos que $\phi = \varphi_1$ y, por tanto, $\Theta(x_0) = \Theta(x_0')$.
\end{proof}

\begin{cor}
  Las soluciones de \eqref{eq:edo:ae} o son constantes o son estrictamente monótonas. Por tanto, las
  órbitas o son conjuntos unitarios o son intervalos abiertos.
\end{cor}

Una representación de algunas órbitas de \eqref{eq:edo:ae} recibe el nombre de \emph{diagrama de
  fases}. Nótese el diagrama de fases viene determinado por el diagrama de signos de $f$. Un signo
positivo indica que la solución asociada a esa órbita es estrictamente creciente mientras que un
signo negativo indica que dicha solución es estrictamente decreciente.

\begin{lemma}[Barbalet, versión débil]
  \label{lem:barbalet}
  Sea $\varphi \in D(]\alpha, +\infty[)$ tal que $\lim_{t \to +\infty} \varphi(t) = L \in
  \R$. Entonces, existe $\{t_n\} \subset ]\alpha, +\infty[$ estrictamente creciente con
  $\{t_n\} \to +\infty$ tal que $\{f'(t_n)\} \to 0$.
\end{lemma}
\begin{proof}
  Es una consecuencia sencilla del teorema del valor medio.
\end{proof}

\begin{prop}
  Sea $\varphi \in \mathcal{C}^1(]\alpha, +\infty[)$ solución de \eqref{eq:edo:ae} tal que
  $\lim_{t \to +\infty} \varphi(t) = L \in \R$. Entonces, $p \in \mathrm{Z}_f$.
\end{prop}
\begin{proof}
  Es una consecuencia sencilla del Lema \ref{lem:barbalet}.
\end{proof}

\begin{lemma}
  Sea $\varphi \in \mathcal{C}^1(]\alpha, \omega[)$ solución de \eqref{eq:edo:ae} y sea $\tau >
  0$. Entonces, la función $\Psi: ]\alpha-\tau, \omega-\tau[ \to \R$ dada por
  $\Psi(t) = \varphi(t+\tau)$ es solución de \eqref{eq:edo:ae}.
\end{lemma}

\begin{cor}
  Sean $p_1$ y $p_2$ dos puntos de inflexión de \eqref{eq:edo:ae} consecutivos con $p_1 < p_2$. Sea $\varphi$ solución maximal de \eqref{eq:edo:ae} tal que su imagen es $(p_1, p_2)$. Entonces, el dominio de $\varphi$ es $\R$. A la solución $\varphi$ se le llama sigmoide. 
\end{cor}

\begin{definition}
[DIAGRAMA DE FASES]
\end{definition}

\subsection{Región de atracción}

\begin{definition}
  \label{def:ra}
  Sea $I \subset \R$ intervalo abierto, $f: I \to \R$ localmente lipschitziana y $p \in I$ tal que
  $f(p) = 0$. Se define la región de atracción de p como
  \[ \mathcal{R}(p) = \{x_0\in I: \omega(x_0) = +\infty \text{ y } \lim_{t \to +\infty} X(t;x_0) =
    p\}. \]
\end{definition}

Claramente tenemos que $p \in \mathcal{R}(x_0)$.

\begin{definition}
  \label{def:atractor}
  En el contexto de la Definición \ref{def:ra}:
  \begin{itemize}
  \item Si $p \in \mathrm{int}(\mathcal{R}(p))$, entonces diremos que $p$ es un atractor.
  \item Si el diagrama de fases es de la forma $\rightarrow p \leftarrow$, entonces diremos que $p$
    es un sumidero.
  \item Si $\mathcal{R}(p) = I$, entonces diremos que $p$ es un atractor global.
  \item Si el diagrama de fases es de la forma $\leftarrow p \rightarrow$, entonces diremos que $p$
    es una fuente.
  \item Si $\mathcal{R}(p) = \{p\}$ y $p$ es un cero aislado de $f$, entonces diremos que $p$ es un
    repulsor.  Si $\mathrm{int}(\mathcal{R}(p)) \ne \emptyset$ y $p \in \partial \mathcal{R}(p)$,
    entonces diremos que $p$ es un semiatractor.
  \end{itemize}
\end{definition}

\begin{prop}[Test de la derivada primera]
  Sean $I \subset \R$ intervalo abierto, $f \in \mathcal{C}^1(I)$ y $p\in I$ tal que $f(p) = 0$.
  
  \begin{enumerate}
  \item Si $f'(p) < 0$, entonces $p$ es un atractor de $x' = f(x)$.
  \item Si $f'(p) > 0$, entonces $p$ es un repulsor de $x' = f(x)$.
  \end{enumerate}
\end{prop}
\begin{proof}
  \begin{enumerate}
  \item En tal caso el diagrama de fases en $p$ es de la forma $\rightarrow p \leftarrow$, de donde
    se sigue el resultado.
  \item En tal caso el diagrama de fases en $p$ es de la forma $\leftarrow p \rightarrow$, de donde
    se sigue el resultado. \qedhere
  \end{enumerate}
\end{proof}

\begin{ex}[Ecuación logística]
  Sean $\lambda, L > 0$. Consideramos la EDO autónoma escalar
\begin{equation}
\label{eq:log}
x' = \lambda x(L-x)
\end{equation}
La función $f(x) = \lambda x (x -L)$ definida en $\R$ es de clase $1$ y, por tanto, localmente lipschitziana. Tenemos que $\mathrm{Z}_f = \{0, L\}$. El diagrama de fases de la ecuación es
\[-\infty \leftarrow 0 \rightarrow  L \leftarrow +\infty.\]
Por tanto, si $0 < x_0 < L$, entonces $\omega(x_0) = +\infty$ y $\lim_{t \to +\infty} X(t,x_0) = L$.
\end{ex}


\section{Prolongación y acotación de soluciones}

\begin{lemma}
  Sea $\varphi : ]\alpha, \omega[ \to \R^d$ una solución de \eqref{eq:pvi} tal que $\lim_{t \to \omega} \varphi(t) = \xi \in \R^d$. Si $(\omega, \xi) \in D$, entonces la solución es prolongable.
\end{lemma}
\begin{proof}
  Consideramos el PVI
  \[\begin{cases}x' = f(t, x); \\ x(\omega) = \xi. \end{cases}\]
  Existe $a > 0$ tal que $\widetilde{\varphi}: ]\omega-a, \omega+a[ \to \R^d$ es solución del nuevo PVI.
\end{proof}

\begin{lemma}
  Sea $\varphi : ]\alpha, \omega[ \to \R^d$ una solución de \eqref{eq:pvi} tal que existe una sucesión $\{t_n\} \subset ]\alpha, \omega[$ con $\{t_n\} \to $
\end{lemma}




\end{document}
