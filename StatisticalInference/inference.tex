%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Plantilla básica de Latex en Español.
%
% Autor: Andrés Herrera Poyatos (https://github.com/andreshp)
%
% Es una plantilla básica para redactar documentos. Utiliza el paquete fancyhdr para darle un
% estilo moderno pero serio.
%
% La plantilla se encuentra adaptada al español.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%-----------------------------------------------------------------------------------------------------
%	TEX OPTIONS
%-----------------------------------------------------------------------------------------------------

% !TEX program = pdflatex
% !TEX option = -shell-escape
% !TEX language = es

%-----------------------------------------------------------------------------------------------------
%	INCLUSIÓN DE PAQUETES BÁSICOS
%-----------------------------------------------------------------------------------------------------

\documentclass{article}

%-----------------------------------------------------------------------------------------------------
%	SELECCIÓN DEL LENGUAJE
%-----------------------------------------------------------------------------------------------------

% Paquetes para adaptar Látex al Español:
\usepackage[spanish,es-noquoting, es-tabla, es-lcroman]{babel} % Cambia
\usepackage[utf8]{inputenc}                                    % Permite los acentos.
\selectlanguage{spanish}                                       % Selecciono como lenguaje el Español.

%-----------------------------------------------------------------------------------------------------
%	SELECCIÓN DE LA FUENTE
%-----------------------------------------------------------------------------------------------------

% Fuente utilizada.
\usepackage{courier}                    % Fuente Courier.
\usepackage{microtype}                  % Mejora la letra final de cara al lector.

%-----------------------------------------------------------------------------------------------------
%	LICENCIA
%-----------------------------------------------------------------------------------------------------

\usepackage[
    type={CC},
    modifier={by},
    version={4.0},
]{doclicense}

%-----------------------------------------------------------------------------------------------------
%	ESTILO DE PÁGINA
%-----------------------------------------------------------------------------------------------------

% Paquetes para el diseño de página:
\usepackage{fancyhdr}               % Utilizado para hacer títulos propios.
\usepackage{lastpage}               % Referencia a la última página. Utilizado para el pie de página.
\usepackage{extramarks}             % Marcas extras. Utilizado en pie de página y cabecera.
\usepackage[parfill]{parskip}       % Crea una nueva línea entre párrafos.
\usepackage{geometry}               % Asigna la "geometría" de las páginas.

% Se elige el estilo fancy y márgenes de 3 centímetros.
\pagestyle{fancy}
\geometry{left=3cm,right=3cm,top=3cm,bottom=3cm,headheight=1cm,headsep=0.5cm} % Márgenes y cabecera.
% Se limpia la cabecera y el pie de página para poder rehacerlos luego.
%\fancyhfb{}

% Espacios en el documento:
\linespread{1.1}                        % Espacio entre líneas.
\setlength\parindent{0pt}               % Selecciona la indentación para cada inicio de párrafo.

% Cabecera del documento. Se ajusta la línea de la cabecera.
\renewcommand\headrule{
	\begin{minipage}{1\textwidth}
	    \hrule width \hsize
	\end{minipage}
}

% Texto de la cabecera:
\lhead{\docauthor}                          % Parte izquierda.
\chead{}                                    % Centro.
\rhead{\subject \ - \doctitle}              % Parte derecha.

% Pie de página del documento. Se ajusta la línea del pie de página.
\renewcommand\footrule{
\begin{minipage}{1\textwidth}
    \hrule width \hsize
\end{minipage}\par
}

\lfoot{}                                                 % Parte izquierda.
\cfoot{}                                                 % Centro.
\rfoot{Página\ \thepage\ de\ \protect\pageref{LastPage}} % Parte derecha.

%-----------------------------------------------------------------------------------------------------
%	PORTADA
%-----------------------------------------------------------------------------------------------------

% Elija uno de los siguientes formatos.
% No olvide incluir los archivos .sty asociados en el directorio del documento.
\usepackage{title1}
%\usepackage{title2}
%\usepackage{title3}

%----------------------------------------------------------------------------------------
%   MATEMÁTICAS
%----------------------------------------------------------------------------------------

\usepackage{mathematics}

%----------------------------------------------------------------------------------------
%   GRÁFICOS
%----------------------------------------------------------------------------------------

\usepackage{pgfplots}
\usepackage{tikz}
% Load the library
\usetikzlibrary{external}
% Enable the library !!!>>> MUST be in the preamble <<<!!!!
\tikzexternalize
\pgfplotsset{compat=newest}

\usepackage{float}

%----------------------------------------------------------------------------------------
%   ENLACES
%----------------------------------------------------------------------------------------
\usepackage{hyperref}
\hypersetup{
    colorlinks   = true,   % Quita las cajas y añade un color al texto.
    % Tipos de enlaces cuyo color se puede configurar:
    linkcolor    = [rgb]{0,0.2,0.5},        % Por defecto red
    anchorcolor  = gray,        % Por defecto black
    citecolor    = magenta,     % Por defecto green
    filecolor    = red,         % Por defecto cyan
    menucolor    = green,       % Por defecto red
    runcolor     = red,         % Por defecto cyan
    urlcolor     = cyan        % Por defecto magenta
}

%-----------------------------------------------------------------------------------------------------
%	TÍTULO, AUTOR Y OTROS DATOS DEL DOCUMENTO
%-----------------------------------------------------------------------------------------------------

% Título del documento.
\newcommand{\doctitle}{Apuntes}
% Subtítulo.
\newcommand{\docsubtitle}{}
% Fecha.
\newcommand{\docdate}{\date}
% Asignatura.
\newcommand{\subject}{Inferencia Estadística}
% Autor.
\newcommand{\docauthor}{Andrés Herrera Poyatos}
\newcommand{\docaddress}{Universidad de Granada}
\newcommand{\docemail}{andreshp9@gmail.com}


%-----------------------------------------------------------------------------------------------------
%	RESUMEN
%-----------------------------------------------------------------------------------------------------

% Resumen del documento. Va en la portada.
% Puedes también dejarlo vacío, en cuyo caso no aparece en la portada.
\newcommand{\docabstract}{}
%\newcommand{\docabstract}{En este texto puedes incluir un resumen del documento. Este informa al lector sobre el contenido del texto, indicando el objetivo del mismo y qué se puede aprender de él.}

\begin{document}

\hypersetup{pageanchor=false}
\maketitle
\hypersetup{pageanchor=true}

%-----------------------------------------------------------------------------------------------------
%	ÍNDICE
%-----------------------------------------------------------------------------------------------------

% Profundidad del Índice:
%\setcounter{tocdepth}{1}

\newpage
\tableofcontents
\vspace*{\fill}
\doclicenseThis
\newpage

%-----------------------------------------------------------------------------------------------------
%	SECCIÓN 1
%-----------------------------------------------------------------------------------------------------

\section{Familias de distribuciones}

\subsection{Distribuciones discretas}

En esta sección se desarrollan varias de las distribuciones discretas más importantes de la estadística.

    \subsubsection{Distribución uniforme}
La distribución uniforme es una distribución de probabilidad que asume un número finito de valores con la misma probabilidad. Es fácil comprobar que la función masa de probabilidad es $f(x|n) = \frac{1}{n}$. Claramente $\sum^n_{i=1} \frac{1}{n} = 1$.

La función generatriz de momentos es fácil calcularla y viene definida por $\varphi_X(t) = \frac{e^t (1 - e^tN)}{N(1-e^t)}$. De ella podemos obtener su media y varianza las cuales quedan de la siguiente forma:

\begin{center}
	$E[X] = \frac{N+1}{2}$
	\\$Var(X) =  E[X^2] - (E[X])^2 =  \frac{(N+1)(N-1)}{12}$
\end{center}

\subsubsection{Distribución de Poisson}
Esta distribución expresa, a partir de una frecuencia de ocurrencia media, la probabilidad de que ocurra un determinado número de eventos durante cierto período de tiempo. La función de masa o probabilidad de la distribución de Poisson es $f(x| \lambda) = \frac{e^{-\lambda}{\lambda}^x}{x!}$. \\Claramente $\sum^n_{i=1}  \frac{e^{-\lambda}{\lambda}^x}{x!} = e^{-\lambda} \sum^n_{i=1}  \frac{{\lambda}^x}{x!}  = 1$.


La función generatriz de momentos de dicha distribución se calcula de la siguiente manera $\varphi_X(t) = \sum^n_{i=0} \frac{e^{tx}e^{-\lambda}{\lambda}^x}{x!} = e^{-\lambda} \sum^n_{i=0}   \frac{(e^{t}  \lambda)^x}{x!} =  e^{-\lambda}  e ^{e^{t} \lambda} = e ^{\lambda (e^t -1 )}$.

A partir de la función generatriz de momentos podemos fácilmente deducir la media y la varianza:
\begin{center}
	$E[X] = \lambda $
	\\$Var(X) =  E[X^2] - (E[X])^2 =  \lambda$
\end{center}

\subsubsection{Distribución binomial}

Considérese un experimento de Bernoulli con probabilidad $\theta \in [0,1]$. Repetimos el experimento $n$ veces y nos preguntamos cuál es la probabilidad de que se hayan conseguido $x$ aciertos, donde $x = 0, 1, \ldots, n$. Es fácil ver que esta probabilidad viene dada por $\binom{n}{x} \theta^x (1-\theta)^{n-x}$. Esta cuestión, que es habitual en la estadística, origina la distribución binomial.

\begin{definition}
    Una variable aleatoria sigue una distribución binomial con parámetros $n \in \mathbb{N}$ y $\theta \in [0,1]$  si su función masa de probabilidad viene dada por $f(x|n,\theta) = \binom{n}{x} \theta^x (1-\theta)^{n-x}$. En tal caso se denota $X \sim B(x|n,\theta)$.
\end{definition}

\subsection{Distribuciones continuas}

En esta sección se desarrollan varias de las distribuciones continuas más importantes de la estadística.

\subsubsection{Distribución uniforme}

La distribución uniforme asigna una credibilidad uniforme a todos los puntos de un intervalo $[a,b]$. Esto es, su función de densidad viene dada por
\[f(x|a,b) = \begin{cases}\frac{1}{b-a} \text{ si } x \in [a,b], \\ 0 \text{ en otro caso.}\end{cases}\]
Claramente tenemos que $\int_{-\infty}^{\infty} f(x |a,b) dx = 1$. Además, podemos calcular fácilmente sus momentos como sigue (y, por tanto, también su varianza)
\[E[X^j] = \int_a^b \frac{x^j}{b-a} dx = \frac{b^{j+1} - a^{j+1}}{(b-a) (j+1)},\]
\[Var(X) = E[X^2] - E[X]^2 = \frac{a^2 + ab + b^2}{3} - \frac{(a+b^2)}{4} = \frac{(b-a)^2}{12}.\]

\subsubsection{Distribución normal}

La distribución normal, también llamada distribución gaussiana, es la distribución más importante de la estadística. Esto se debe a sus numerosas aplicaciones en análisis de poblaciones y al teorema central del límite.

\begin{definition}
    Sean $\mu \in \mathbb{R}$ y $\sigma^2 > 0$. Definimos la distribución $N(x | \mu, \sigma^2)$ como la distribución que tiene función de densidad
    \[f(x | \mu, \sigma^2) = \frac{1}{\sqrt{2\pi}\sigma}e^{-(x-\mu)^2 / (2\sigma^2)}, x \in \mathbb{R}.\]
\end{definition}

La distribución normal está bien definida como consecuencia del siguiente lema.
\begin{lem}
    Sean $\mu \in \mathbb{R}$ y $\sigma > 0$. Tenemos que $\int_{-\infty}^\infty e^{-(x-\mu)^2 / (2\sigma^2)}dx = \sqrt{2\pi}\sigma.$
\end{lem}
\begin{proof}
    En primer lugar, vamos a calcular la integral para $\mu = 0$ y $\sigma = 1$. La demostración consiste en reducir el problema en calcular una integral en dos variables. Para ello, elevamos al cuadrado y obtenemos
    \[\left(\int_{-\infty}^\infty e^{-x^2 / 2}dx\right)^2 = \left(\int_{-\infty}^\infty e^{-t^2 / 2}dt\right) \left(\int_{-\infty}^\infty e^{-s^2 / 2}ds \right) = \int_{-\infty}^\infty \int_{-\infty}^\infty e^{-(t^2+s^2) / 2} dt ds. \]
    Resolvemos esta última integral mediante un cambio a polares
    \[\int_{-\infty}^\infty \int_{-\infty}^\infty e^{-(t^2+s^2) / 2} dt ds = \int_{-\pi}^\pi \left(\int_{0}^\infty \rho e^{-\rho^2 / 2} d\rho \right) d\theta = 2\pi \int_{0}^\infty \rho e^{-\rho^2 / 2} d\rho = 2\pi.\]
    Por último, utilizamos el cambio de variable $y = (x - \mu) / \sigma$ para obtener
    \[\int_{-\infty}^\infty e^{-(x-\mu)^2 / (2\sigma^2)}dx = \int_{-\infty}^\infty \sigma e^{-y^2 / 2}dy = \sqrt{2\pi}\sigma. \qedhere\]
\end{proof}

Nótese que si $X \sim N(x | \mu, \sigma^2)$, entonces $Y = (X - \mu)/\sigma$ sigue una distribución $N(x|0,1)$.

\begin{prop} \label{prop:normal:cf}
    La función característica de la distribución $N(x|\mu, \sigma^2)$ viene dada por $\varphi_X(t) = e^{it\mu - t^2 \sigma^2 / 2}$.
\end{prop}
\begin{proof}
    En primer lugar, tenemos que
    \[\varphi_X(t) = E[e^{itX}] = \frac{1}{\sqrt{2\pi}\sigma} \int_{-\infty}^{\infty} e^{itx-(x-\mu)^2 / (2\sigma^2)} dx = \frac{1}{\sqrt{2\pi}\sigma} \int_{-\infty}^{\infty} e^{-((x-\mu)^2 - 2itx\sigma^2) / (2\sigma^2)} dx.\]
    Completamos cuadrados como sigue
    \[(x-\mu)^2 - 2 itx\sigma^2 = (x - (it \sigma^2 + \mu))^2 + t^2 \sigma^4 - 2it\sigma^2 \mu.\]
    Esto sugiere utilizar el cambio de variable $g(y) = y + it \sigma^2$. Obtenemos
    \begin{align*}
        \sqrt{2\pi}\sigma \varphi_X(t) = \int_{-\infty}^{\infty} e^{-((x-\mu)^2 - 2itx\sigma^2) / (2\sigma^2)} = e^{it\mu - t^2 \sigma^2 / 2} \int_{-\infty}^{\infty} e^{-((x-(it \sigma^2 + \mu))^2 ) / (2\sigma^2)} dx \\
        = e^{it\mu - t^2 \sigma^2 / 2} \int_{-\infty}^{\infty} e^{-(y - \mu)^2 ) / (2\sigma^2)} dy = \sqrt{2\pi}\sigma e^{it\mu - t^2 \sigma^2 / 2},
    \end{align*}
    como se quería.
    Nótese que a pesar de ser una integral de contorno compleja el cambio de variable es válido. En efecto, el cambio de variable es afín y la función a integrar es entera. Por tanto, utilizando el camino cerrado $g([0, \infty]) + [\infty, 0]$ se puede probar que el cambio es válido.
\end{proof}

Análogamente se puede probar el siguiente resultado.

\begin{prop} \label{prop:normal:gm}
    La función generatriz de momentos de la distribución $N(x|\mu, \sigma^2)$ viene dada por $\varphi_X(t) = e^{t\mu - t^2 \sigma^2 / 2}$.
\end{prop}

\begin{cor} \label{cor:normal:rec}
    Los momentos de la distribución $N(x|\mu,\sigma^2)$ verifican la ecuación recurrente
    \[E[X^k] = -(k-1)\sigma^2 E[X^{k-2}] + (\mu - t \sigma^2) E[X^{k-1}], \ \  k \ge 2.\]
\end{cor}
\begin{proof}
    Sabemos que $E[X^k] = \varphi_X^{(k)}(t)$. Tenemos $\varphi_X^{(1)}(t) = (\mu - t \sigma^2) \varphi_X(t)$. Consecuentemente,
    \[\varphi_X^{(2)}(t) = -\sigma^2 \varphi_X(t) + (\mu - t \sigma^2) \varphi_X^{(1)}(t).\]
    Por inducción se extiende el resultado fácilmente para $k \ge 2$.
\end{proof}

\begin{cor}
    Si $X \sim N(x|\mu,\sigma^2)$, entonces $E[X] = \mu$ y $E[X^2] = \sigma^2 + \mu^2$. Consecuentemente, $Var(X) = \sigma^2$. Como consecuencia de este resultado al parámetro $\mu$ se le llama media y al parámetro $\sigma^2$ varianza.
\end{cor}

Podemos utilizar los dos corolarios anteriores para calcular los momentos de la distribución normal resolviendo una ecuación recurrente de segundo orden. Evidentemente, la fórmula obtenida será bastante larga. Sin embargo, esta ecuación se simplifica en el caso de los momentos centrados, como pone de manifiesto el siguiente resultado, que se puede demostrar fácilmente por inducción a partir del Corolario \ref{cor:normal:rec}.

\begin{cor}
    Si $X \sim N(x|0,\sigma^2)$, entonces
    \[E[X^k] = \begin{cases} 0 & \text{ si } k \text{ es impar;} \\ (k-1)!! \sigma^{k} & \text{ si } k \text{ es par;} \end{cases}\]
    donde $n!!$ denota al doble factorial, definido como el producto de los números desde $1$ hasta $n$ con la misma paridad que $n$.
\end{cor}

La Figura \ref{fig:normal} muestra la función de densidad de una distribución normal. Podemos ver que la densidad se concentra en torno a la media. De hecho, $P(|X - \mu| \ge 2\sigma) \approx 0.046$. Es más, $P(|X - \mu| \ge 3\sigma) \approx 0.03$.

\begin{figure}[H]
\centering
\begin{tikzpicture}[
     declare function={gauss(\x,\mu,\sigma)=1/(\sigma*sqrt(2*pi))*exp(-((\x-\mu)^2)/(2*\sigma^2));}
    ]
\begin{axis}[
    no markers,
    domain=0:6,
    samples=100,
    ymin=0,
    axis lines*=left,
    xlabel=$x$,
    every axis y label/.style={at=(current axis.above origin),anchor=south},
    every axis x label/.style={at=(current axis.right of origin),anchor=west},
    height=5cm,
    width=15cm,
    xtick=\empty,
    ytick=\empty,
    enlargelimits=false,
    clip=false,
    axis on top,
    grid = major,
    hide y axis
]

\addplot[very thick,cyan!50!black] {gauss(x, 3, 1)};

        \pgfmathsetmacro\valueA{gauss(1,3,1)}
        \pgfmathsetmacro\valueB{gauss(2,3,1)}
        \draw [gray] (axis cs:1,0) -- (axis cs:1,\valueA)
            (axis cs:5,0) -- (axis cs:5,\valueA);
            \draw [gray] (axis cs:2,0) -- (axis cs:2,\valueB)
            (axis cs:4,0) -- (axis cs:4,\valueB);
            \draw [yshift=1.4cm, latex-latex](axis cs:2, 0) -- node [fill=white] {$0.683$} (axis  cs:4, 0);
            \draw [yshift=0.3cm, latex-latex](axis cs:1, 0) -- node [fill=white] {$0.954$} (axis cs:5, 0);

            \node[below] at (axis cs:1, 0)  {$\mu - 2\sigma$};
            \node[below] at (axis cs:2, 0)  {$\mu - \sigma$};
            \node[below] at (axis cs:3, 0)  {$\mu$};
            \node[below] at (axis cs:4, 0)  {$\mu + \sigma$};
            \node[below] at (axis cs:5, 0)  {$\mu + 2\sigma$};
\end{axis}

\end{tikzpicture}
\caption{Función de densidad de una distribución normal.}
\label{fig:normal}
\end{figure}

\begin{prop}
    Sean $X_1$ e $Y_2$ dos variables aleatorias independientes que siguen una distribución $N(x|\mu_1,\sigma_1^2)$ y $N(x|\mu_2,\sigma_2^2)$ respectivamente. Entonces $X+Y$ sigue una distribución $N(x|\mu_1+\mu_2,\sigma_1^2+\sigma_2^2)$.
\end{prop}
\begin{proof}
    Basta darse cuenta de que $\varphi_{X+Y}(t) = \varphi_{X}(t)\varphi_{Y}(t) = e^{t(\mu_1 + \mu_2) - t^2 (\sigma_1^2 + \sigma_2^2) / 2}$ es la función característica asociada a la distribución $N(x|\mu_1+\mu_2,\sigma_1^2+\sigma_2^2)$. Recordemos que la función característica determina de forma unívoca a la distribución.
\end{proof}

El recíproco del resultado anterior también es cierto.

\begin{thm}[Cramer]
    Sean $X$ e $Y$ dos variables aleatorias independientes. Si $X+Y$ es normal, entonces $X$ e $Y$ son normales.
\end{thm}

\subsubsection{Distribución gamma}

La famila de distribuciones gamma se encuentra definida sobre el intervalo $[0, \infty)$. En su definición entra en juego la famosa función gamma, de ahí su nombre.

\begin{definition}
    Se define la función gamma como la aplicación $\Gamma: (0, \infty) \to (0, \infty)$ dada por
    \[\Gamma(\alpha) = \int_0^\infty t^{\alpha-1}e^{-t}dt.\]
\end{definition}
\begin{prop}
    La función gamma está bien definida.
\end{prop}
\begin{proof}
    Sea $\alpha > 0$. Tenemos que probar que $\int_0^\infty t^{\alpha-1}e^{-t}dt < \infty$. Tomando $b > 0$, escribimos
    \[\int_0^\infty t^{\alpha-1}e^{-t}dt = \int_0^b t^{\alpha-1}e^{-t}dt + \int_b^\infty t^{\alpha-1}e^{-t}dt.\]
    Sabemos que la función $t^{\alpha - 1}$ tiene a $t^{\alpha} / \alpha$ como primitiva y, por tanto, es integrable en $[0,b]$. Puesto que $t^{\alpha-1}e^{-t} \le t^{\alpha-1}$, obtenemos que $t^{\alpha-1}e^{-t}$ es integrable en $[0,b]$. Por otro lado tenemos que
    \[\lim_{t \to \infty} \frac{t^{\alpha-1}e^{-t}}{e^{-t / 2}} = 0.\]
    Consecuentemente, para cierto $b > 0$ se verifica $t^{\alpha-1}e^{-t} \le e^{-t / 2}$ para todo $t \ge b$. Puesto que $e^{-t / 2}$ es integrable en $[b, \infty)$, deducimos que $t^{\alpha-1}e^{-t}$ también lo es, lo que termina la demostración.
\end{proof}

\begin{prop}[Propiedades de la función gamma]
    Sea $\alpha > 0$. Se verifica:
    \begin{enumerate}
        \item $\Gamma(1) = 1$;
	\item $\Gamma(\alpha+1) = \alpha\Gamma(\alpha)$;
    \item $\Gamma(n+1) = n!$ para cualquier $n \in \mathbb{N}$;
    \item (Fórmula de reflexión de Euler) si $0 < \alpha < 1$, entonces $\Gamma(\alpha) \Gamma(1- \alpha) = \frac{\pi}{\sin(\alpha \pi)}$;
    \item $\Gamma(1/2) = \sqrt{\pi}$;
    \item $\Gamma(\alpha) = \beta^\alpha\int_0^\infty t^{\alpha-1}e^{-\beta t} dt$ para todo $\beta > 0$.
    \end{enumerate}
\end{prop}
\begin{proof}
    \
    \begin{enumerate}
        \item Es fácil ver que $\int_{0}^\infty e^{-t} dt = 1$.
        \item Integrando por partes obtemos
        \[\Gamma(\alpha+1) = \int_0^{\infty}{t^{\alpha}e^{-t}dt} = \bigg[-e^{-t}t^\alpha\bigg]_0^{\infty} +
            \int_0^{\infty}{xt^{\alpha-1}e^{-t}dt} = \alpha\int_0^{\infty}{t^{\alpha-1}e^{-t}dt} = \alpha\Gamma(\alpha).\]
        \item Es consecuencia directa de los apartados a) y b).
        \item Se obtiene utilizando definiciones alternativas de la función gamma tras extenderla a $\mathbb{C} \setminus \mathbb{Z}^-_0$. Para más información véase \cite{gamma}. No desarrollamos esta demostración pues solo la necesitamos para el siguiente apartado.
        \item Se obtiene al evaluar la fórmula de reflexión en $\alpha = 1/2$.
        \item Se obtiene realizando el cambio de variable $t = \beta s$. \qedhere
    \end{enumerate}
\end{proof}

\begin{definition}
    Sean $\alpha, \beta > 0$. Definimos la distribución $Gamma(x | \alpha, \beta)$ como la distribución que tiene función de densidad
    \[f(x | \alpha, \beta) = \frac{\beta^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x}, x > 0.\]
\end{definition}

El parámetro $\alpha$ se conoce como parámetro de forma ya que influencia la forma de la distribución, como muestra el siguiente resultado.

\begin{prop}
    La función de densidad de la distribución $Gamma(\alpha, \beta)$ verifica las siguientes propiedades:
    \begin{itemize}
        \item Si $0< \alpha <1$, entonces $f(x | \alpha, \beta)$ es decreciente y $f(x) \to \infty$ para $x \to 0$.
        \item Si $\alpha = 1$, entonces $f(x | \alpha, \beta)$ es decreciente con $f(0) = 1$.
        \item Si $\alpha > 1$, entonces $f(x | \alpha, \beta)$ crece en $[0, (\alpha-1) / \beta]$ y decrece en $[(\alpha-1) / \beta,\infty]$.
        \item Si $0 < \alpha \le 1$, entonces $f(x | \alpha, \beta)$ es convexa.
        \item Si $1 < \alpha \le 2$, entonces $f(x | \alpha, \beta)$ es cóncava en $[0,(\alpha-1 + \sqrt{\alpha - 1}) / \beta]$ y convexa en $[(\alpha-1 + \sqrt{\alpha - 1}) / \beta, \infty]$.
        \item Si $2 < \alpha$, entonces $f(x | \alpha, \beta)$ es cóncava en $[(\alpha-1 - \sqrt{\alpha - 1}) / \beta,(\alpha-1 + \sqrt{\alpha - 1}) / \beta]$ y convexa en $[0, (\alpha-1 - \sqrt{\alpha - 1}) / \beta]$ y $[(\alpha-1 + \sqrt{\alpha - 1}) / \beta, \infty]$.
    \end{itemize}
\end{prop}
\begin{proof}
Los resultados se obtienen mediante las herramientas habituales del cálculo. Basta estudiar la derivada primera y la derivada segunda
\begin{align*}
f^\prime(x) &= \frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha-2} e^{-\beta x}[(\alpha - 1) - \beta x]; \\
f^{\prime \prime}(x) &= \frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha-3} e^{-\beta x} \left[(\alpha - 1)(\alpha - 2) - 2 \beta (\alpha - 1) x + \beta^2 x^2\right]. \qedhere
\end{align*}
\end{proof}

La Figura \ref{fig:gamma:alpha} muestra la función de densidad de la distribución gamma para distintos valores de $\alpha$.  El parámetro $\beta$ se denomina parámetro de escala debido a su influencia en la escala de la función de densidad. La Figura \ref{fig:gamma:beta} muestra la función de densidad de la distribución gamma para distintos valores de $\beta$.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}[
        declare function={gamma(\z)=
        2.506628274631*sqrt(1/\z)+ 0.20888568*(1/\z)^(1.5)+ 0.00870357*(1/\z)^(2.5)- (174.2106599*(1/\z)^(3.5))/25920- (715.6423511*(1/\z)^(4.5))/1244160)*exp((-ln(1/\z)-1)*\z;},
        declare function={gammapdf(\x,\k,\theta) = 1/(\theta^\k)*1/(gamma(\k))*\x^(\k-1)*exp(-\x/\theta);}
        ]
        \begin{axis}[
            ylabel={$f(x | \alpha, \beta)$},
            domain=0.000001:10, samples=100,
            axis lines=left,
            every axis y label/.style={at=(current axis.above origin),anchor=east},
            every axis x label/.style={at=(current axis.right of origin),anchor=north},
            height=6cm, width=12cm,
            enlargelimits=false,
            clip=false,
            axis on top,
            grid = major,
            legend pos=outer north east
        ]
            \addplot [very thick,cyan!20!black] {gammapdf(x,0.98,2)};
            \addlegendentry{$\alpha = 0.9, \beta = 2$}
            \addplot [very thick,cyan!35!black] {gammapdf(x,1,2)};
            \addlegendentry{$\alpha = 1, \beta = 2$}
            \addplot [very thick,cyan!60!black] {gammapdf(x,2,2)};
            \addlegendentry{$\alpha = 2, \beta = 2$}
            \addplot [very thick,cyan] {gammapdf(x,3,2)};
            \addlegendentry{$\alpha = 3, \beta = 2$}
        \end{axis}
    \end{tikzpicture}
    \caption{Densidad de la distribución gamma con distintos valores de $\alpha$.}
    \label{fig:gamma:alpha}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{tikzpicture}[
        declare function={gamma(\z)=
        2.506628274631*sqrt(1/\z)+ 0.20888568*(1/\z)^(1.5)+ 0.00870357*(1/\z)^(2.5)- (174.2106599*(1/\z)^(3.5))/25920- (715.6423511*(1/\z)^(4.5))/1244160)*exp((-ln(1/\z)-1)*\z;},
        declare function={gammapdf(\x,\k,\theta) = 1/(\theta^\k)*1/(gamma(\k))*\x^(\k-1)*exp(-\x/\theta);}
        ]
        \begin{axis}[
            ylabel={$f(x | \alpha, \beta)$},
            domain=0:10, samples=100,
            axis lines=left,
            every axis y label/.style={at=(current axis.above origin),anchor=east},
            every axis x label/.style={at=(current axis.right of origin),anchor=north},
            height=6cm, width=12cm,
            enlargelimits=false, clip=false, axis on top,
            grid = major,
            legend pos=outer north east
        ]
            \addplot [very thick,magenta!10!black] {gammapdf(x,2,0.5)};
            \addlegendentry{$\alpha = 2, \beta = 0.5$}
            \addplot [very thick,magenta!40!black] {gammapdf(x,2,1)};
            \addlegendentry{$\alpha = 2, \beta = 1$}
            \addplot [very thick,magenta!75!black] {gammapdf(x,2,2)};
            \addlegendentry{$\alpha = 2, \beta = 2$}
            \addplot [very thick,magenta] {gammapdf(x,2,3)};
            \addlegendentry{$\alpha = 2, \beta = 3$}
        \end{axis}
    \end{tikzpicture}
    \caption{Densidad de la distribución gamma con distintos valores de $\beta$.}
    \label{fig:gamma:beta}
\end{figure}

\begin{prop} \label{prop:gamma:cf}
    La función característica de la distribución $Gamma(x|\alpha, \beta)$ viene dada por $\varphi_X(t) = \left(\frac{\beta}{\beta -it}\right)^\alpha$.
\end{prop}
\begin{proof}
    Basta utilizar el cambio de variable $g(y) = y / (\beta - it)$ como sigue
    \[E[e^{itX}] = \frac{\beta^\alpha}{\Gamma(\alpha)} \int_{0}^{\infty} x^{\alpha-1}e^{-(\beta - it) x} dx = \frac{\beta^\alpha}{\Gamma(\alpha) (\beta -it)^\alpha} \int_{0}^{\infty} y^{\alpha-1}e^{-y} dy = \left(\frac{\beta}{\beta -it}\right)^\alpha.\]
    Nótese que a pesar de ser una integral de contorno compleja el cambio de variable afín es válido como se comentó en la Proposición \ref{prop:normal:cf}.
\end{proof}

\begin{cor}
    El momento $k$-ésimo de la distribución $Gamma(x|\alpha,\beta)$ es $\alpha (\alpha+1) \ldots (\alpha + k -1) / \beta^k$.
\end{cor}
\begin{proof}
    Tenemos que $i^k E[X^k]= \varphi_X^{(k)}(t) = i^k \alpha (\alpha+1) \ldots (\alpha + k -1) / \beta^k$.
\end{proof}

\begin{prop}
    La función generatriz de momentos de la distribución $Gamma(x|\alpha, \beta)$ viene dada por $\varphi_X(t) = \left(\frac{\beta}{\beta - t}\right)^\alpha$.
\end{prop}
\begin{proof}
    La demostración es análoga a la dada en la Proposición \ref{prop:gamma:cf}.
\end{proof}

\begin{cor}
    La distribución $Gamma(x|\alpha,\beta)$ tiene media $\alpha / \beta$ y varianza $\alpha / \beta^2$.
\end{cor}

\begin{prop}
    Sea $n \ge 1$. Consideremos $X_1, \ldots, X_n$ variables aleatorias independientes tales que $X_j$ sigue una distribución $Gamma(x|\alpha_i, \beta)$. Entonces, $\sum_{i=1}^n X_j$ sigue una distribución $Gamma(x|\sum_{i=1}^n \alpha_i, \beta)$.
\end{prop}
\begin{proof}
    En primer lugar, calculamos la función característica de $\sum_{i=1}^n X_j$ como sigue
    \[E[e^{i\sum X_j}] = E[\prod e^{iX_j}] = \prod E[e^{iX_j}] = \left(\frac{\beta}{\beta - it}\right)^{\sum \alpha_j},\]
    donde se ha utilizado que la esperanza del producto de dos variables aleatorias independientes es el producto de las esperanzas. Por último, nótese que la función característica de la variable $\sum X_j$ es la función característica de $Gamma(x|\sum_{i=1}^n \alpha_i, \beta)$. El hecho de que la función característica de una distribución la determina de forma unívoca finaliza la prueba.
\end{proof}

\begin{prop} \label{prop:normal-square}
    Sea $X \sim N(x|0,\sigma^2)$. La variable aleatoria $Y = X^2$ sigue una distribución \\ $Gamma(y,1/2,1/(2\sigma^2))$. En particular, para $\sigma = 1$, $Y = X^2$ sigue una distribución $\chi^2_1$.
\end{prop}
\begin{proof}
    Sean $F$ y $G$ las funciones de distribución de las variables $X$ e $Y$ respectivamente. Tenemos que $G(y) = P(X^2 \le y) = P(- \sqrt{y} \le X \le \sqrt{y}) = F(\sqrt{y}) - F(-\sqrt{y})$. Derivando, obtenemos
    \[G'(y) = \frac{F'(\sqrt{y}) + F'(-\sqrt{y})}{2\sqrt{y}} = \frac{1}{\sqrt{y}} \frac{1}{\sqrt{2\pi}\sigma} e^{-y/(2\sigma^2)} = \frac{(1/(2\sigma^2))^{1/2}}{\Gamma(1/2)} y^{-1/2} e^{-y/(2\sigma^2)}.\]
    Por último, basta darse cuenta de que $G'(y)$ es la función de densidad de $Gamma(y,1/2,1/(2\sigma^2))$.
\end{proof}

\subsubsection{Distribución beta}

La famila de distribuciones beta se encuentra definida sobre el intervalo $(0, 1)$. En su definición entra en juego la denominada función beta, de ahí su nombre.

\begin{definition}
    Se define la función beta como la aplicación $\beta : (0, \infty) \times (0, \infty) \to (0, \infty)$ dada por
    \[\beta(x, y) = \int_0^1 t^{x-1}(1-t)^{y-1}\,dt.\]
\end{definition}
\begin{prop} \label{prop:beta-gamma}
    Para cada $x, y > 0$ se tiene que $\frac{\Gamma(x)\Gamma(y)}{\Gamma(x+y)} = \beta(x,y)$. Como consecuencia, la función beta está bien definida.
\end{prop}
\begin{proof}
    En primer lugar escribimos $\Gamma(x)\Gamma(y)$ como una integral doble
    \begin{equation*}
        \Gamma(x)\Gamma(y) =\int_{0}^{\infty }\ e^{-u}u^{x-1}\,d u\int_{0}^{\infty }\ e^{-v}v^{y-1}\,d v
        =\int_{0}^{\infty }\int_{0}^{\infty }\ e^{-u-v}u^{x-1}v^{y-1}\,d u\,d v.
    \end{equation*}
    La expresión anterior nos sugiere utilizar el cambio de variable $(u, v) = J(t,s) = (st, (1-t)s)$. Nótese que $|J(t,s)| = s$. Aplicamos el cambio a continuación
    \begin{gather*}
        \Gamma(x)\Gamma(y) = \int_{0}^{\infty} \left( \int_{0}^{1}e^{-s}(st)^{x-1}(s(1-t))^{y-1}|J(t,s)|\, d t \right) ds \\
        = \int_{0}^{\infty }e^{-s}s^{x+y-2}s \left(\int_{0}^{1}t^{x-1}(1-t)^{y-1}\,dt \right) d s =\Gamma(x+y)\beta(x,y).  \qedhere
    \end{gather*}
\end{proof}

En la práctica siempre se utiliza la función gamma para evaluar la función beta. Ya podemos definir la distribución beta.

\begin{definition}
    Sean $p, q > 0$. Definimos la distribución $beta(x | p, q)$ como la distribución que tiene función de densidad
    \[f(x | p, q) = \frac{1}{\beta(p,q)}x^{p-1}(1-x)^{q-1}, 0 < x < 1.\]
\end{definition}

Claramente, la función de densidad integra $1$. Esta distribución asigna probabilidad $1$ al intervalo $(0,1)$. Por ello, es útil en modelos de proporciones. Las Figuras \ref{fig:beta:p} y \ref{fig:beta:q} muestran la distribución beta cambiando los valores $p$ y $q$ respectivamente. Podemos observar que las funciones de densidad de $beta(x|p,q)$ y $beta(x|q,p)$ son simétricas respecto del punto $1/2$. Esto se puede demostrar fácilmente a partir de la definición. La Figura \ref{fig:beta:pq} muestra la distribución beta con iguales valores de $p$ y $q$. Vemos que las densidades son simétricas en el eje $x = 1/2$, hecho que también puede demostrarse fácilmente a partir de la definición.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}[
        declare function={gamma(\z)=
        2.506628274631*sqrt(1/\z)+ 0.20888568*(1/\z)^(1.5)+ 0.00870357*(1/\z)^(2.5)- (174.2106599*(1/\z)^(3.5))/25920- (715.6423511*(1/\z)^(4.5))/1244160)*exp((-ln(1/\z)-1)*\z;},
        declare function={betapdf(\x,\p,\q) = gamma(\p+\q)/(gamma(\p)*gamma(\q)) * \x^(\p-1)*(1-x)^(\q-1);}
        ]
        \begin{axis}[
            ylabel={$f(x | p, q)$},
            domain=0.05:1, samples=100,
            axis lines=left,
            every axis y label/.style={at=(current axis.above origin),anchor=east},
            every axis x label/.style={at=(current axis.right of origin),anchor=north},
            height=6cm, width=12cm,
            enlargelimits=false, clip=false, axis on top,
            grid = major,
            legend pos=outer north east
        ]
            \addplot [very thick,cyan!10!black] {betapdf(x,0.5,2)};
            \addlegendentry{$p = 0.5, q = 2$}
            \addplot [very thick,cyan!40!black] {betapdf(x,1,2)};
            \addlegendentry{$p = 1, q = 2$}
            \addplot [very thick,cyan!75!black] {betapdf(x,2,2)};
            \addlegendentry{$p = 2, q = 2$}
            \addplot [very thick,cyan] {betapdf(x,3,2)};
            \addlegendentry{$p = 3, q = 2$}
        \end{axis}
    \end{tikzpicture}
    \caption{Densidad de la distribución beta con distintos valores de $p$.}
    \label{fig:beta:p}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{tikzpicture}[
        declare function={gamma(\z)=
        2.506628274631*sqrt(1/\z)+ 0.20888568*(1/\z)^(1.5)+ 0.00870357*(1/\z)^(2.5)- (174.2106599*(1/\z)^(3.5))/25920- (715.6423511*(1/\z)^(4.5))/1244160)*exp((-ln(1/\z)-1)*\z;},
        declare function={betapdf(\x,\p,\q) = gamma(\p+\q)/(gamma(\p)*gamma(\q)) * \x^(\p-1)*(1-x)^(\q-1);}
        ]
        \begin{axis}[
            ylabel={$f(x | p, q)$},
            domain=0:0.95, samples=100,
            axis lines=left,
            every axis y label/.style={at=(current axis.above origin),anchor=east},
            every axis x label/.style={at=(current axis.right of origin),anchor=north},
            height=6cm, width=12cm,
            enlargelimits=false, clip=false, axis on top,
            grid = major,
            legend pos=outer north east
        ]
            \addplot [very thick,magenta!10!black] {betapdf(x,2,0.5)};
            \addlegendentry{$p = 2, q = 0.5$}
            \addplot [very thick,magenta!40!black] {betapdf(x,2,1)};
            \addlegendentry{$p = 2, q = 1$}
            \addplot [very thick,magenta!75!black] {betapdf(x,2,2)};
            \addlegendentry{$p = 2, q = 2$}
            \addplot [very thick,magenta] {betapdf(x,2,3)};
            \addlegendentry{$p = 2, q = 3$}
        \end{axis}
    \end{tikzpicture}
    \caption{Densidad de la distribución beta con distintos valores de $q$.}
    \label{fig:beta:q}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{tikzpicture}[
        declare function={gamma(\z)=
        2.506628274631*sqrt(1/\z)+ 0.20888568*(1/\z)^(1.5)+ 0.00870357*(1/\z)^(2.5)- (174.2106599*(1/\z)^(3.5))/25920- (715.6423511*(1/\z)^(4.5))/1244160)*exp((-ln(1/\z)-1)*\z;},
        declare function={betapdf(\x,\p,\q) = gamma(\p+\q)/(gamma(\p)*gamma(\q)) * \x^(\p-1)*(1-x)^(\q-1);}
        ]
        \begin{axis}[
            ylabel={$f(x | p, q)$},
            domain=0.05:0.95, samples=100,
            axis lines=left,
            every axis y label/.style={at=(current axis.above origin),anchor=east},
            every axis x label/.style={at=(current axis.right of origin),anchor=north},
            height=6cm, width=12cm,
            enlargelimits=false, clip=false, axis on top,
            grid = major,
            legend pos=outer north east
        ]
            \addplot [very thick,green!10!black] {betapdf(x,0.5,0.5)};
            \addlegendentry{$p = 0.5, q = 0.5$}
            \addplot [very thick,green!40!black] {betapdf(x,1,1)};
            \addlegendentry{$p = 1, q = 1$}
            \addplot [very thick,green!75!black] {betapdf(x,2,2)};
            \addlegendentry{$p = 2, q = 2$}
            \addplot [very thick,green] {betapdf(x,3,3)};
            \addlegendentry{$p = 3, q = 3$}
        \end{axis}
    \end{tikzpicture}
    \caption{Densidad de la distribución beta con $p = q$.}
    \label{fig:beta:pq}
\end{figure}

\begin{prop}
    La función característica de la distribución $beta(x|p,q)$ viene dada por
    \[\varphi_X(t) = 1 + \sum_{k = 1}^\infty \frac{(it)^k}{k!} \frac{\beta(p+k,q)}{\beta(p,q)}.\]
\end{prop}

\begin{proof}
Desarrollamos la función característica utilizando el desarrollo de la exponencial
\begin{gather*}
E[e^{itX}] = \frac{1}{\beta(p,q)}\int_0^1 e^{itx} x^{p-1}(1-x)^{q-1} dx = \frac{1}{\beta(p,q)}\int_0^1 \sum_{k = 0}^\infty \frac{(itx)^{k}}{k!} x^{p-1}(1-x)^{q-1} dx \\
= \frac{1}{\beta(p,q)}\sum_{k = 0}^\infty \frac{(it)^k}{k!} \int_0^1x^{p+k-1}(1-x)^{q-1} dx = \sum_{k = 0}^\infty \frac{(it)^k}{k!} \frac{\beta(p+k,q)}{\beta(p,q)} = 1 + \sum_{k = 1}^\infty \frac{(it)^k}{k!} \frac{\beta(p+k,q)}{\beta(p,q)}. \qedhere
\end{gather*}
\end{proof}

\begin{cor} \label{cor:beta:moments}
    Sea $X \sim beta(x|p,q)$. Entonces, para cada $k \ge 1$ se tiene que
    \[E[X^k] = \frac{\beta(p+k,q)}{\beta(p,q)}.\]
\end{cor}

\begin{cor} \label{cor:beta:esp}
    Sea $X \sim beta(x|p,q)$. Entonces, $E[X] = \frac{p}{p+q}$ y $Var(X) = \frac{pq}{(p+q)^2(p+q+1)}$.
\end{cor}
\begin{proof}
    Por el Corolario \ref{cor:beta:moments} y la Proposición \ref{prop:beta-gamma} tenemos que
    \[E[X] = \frac{\beta(p+1,q)}{\beta{p,q}} = \frac{\Gamma(p+1)\Gamma(q)}{\Gamma(p+q)} \frac{\Gamma(p+q)}{\Gamma(p)\Gamma(q)} = \frac{\Gamma(p+1)}{\Gamma(p)} \frac{\Gamma(p+q)}{\Gamma(p+q+1)} = \frac{p}{p+q}\]
    y
    \[E[X^2] = \frac{\beta(p+2,q)}{\beta{p,q}} = \frac{\Gamma(p+2)\Gamma(q)}{\Gamma(p+q+2)} \frac{\Gamma(p+q)}{\Gamma(p)\Gamma(q)} = \frac{\Gamma(p+2)}{\Gamma(p)} \frac{\Gamma(p+q)}{\Gamma(p+q+2)} = \frac{p(p+1)}{(p+q)(p+q+1)}.\]
    Por último, es directo calcular $Var(X) = E[X^2] - E[X]^2$.
\end{proof}

\subsubsection{Distribución de Cauchy}

\begin{definition}
    Sea $\mu \in \mathbb{R}$ y $\sigma > 0$. Definimos la distribución $Cauchy(x | \mu, \sigma)$ como la distribución que tiene función de densidad
    \[f(x | \mu, \sigma) = \frac{1}{\sigma \pi} \frac{1}{1+\left(\frac{x-\mu}{\sigma}\right)^2} = \frac{\sigma}{\pi(\sigma^2 + (x-\mu)^2)}, \ x \in \mathbb{R}.\]
\end{definition}

La distribución está bien definida. En efecto, utilizando el cambio de variable $x = \sigma y + \mu$ obtenemos
\[\int_{-\infty}^\infty \frac{1}{1+\left(\frac{x-\mu}{\sigma}\right)^2} dx = \int_{-\infty}^\infty \frac{\sigma}{1+y^2} dy = \sigma \pi.\]

\begin{prop}
    La función característica de la distribución $Cauchy(x|\mu,\sigma)$ viene dada por
    \[\varphi_X(t) = e^{i\mu t - \sigma |t|}.\]
\end{prop}
\begin{proof}
    En primer lugar, demostramos el resultado para $Cauchy(x|0,1)$. Tenemos que
    \[\varphi_X(t)  = \frac{1}{\pi}\int_{-\infty}^\infty \frac{e^{itz}}{1+z^2} dz = e^{-|t|},\]
    donde la última igualdad se explica en \cite{cauchy}. Ahora, si $X \sim Cauchy(x|\mu,\sigma)$, entonces $Y = (X - \mu) / \sigma \sim Cauchy(x|0,1)$ y, por tanto, obtenmos
    \[\varphi_X(t) = E[e^{itX}] = E[e^{it(\sigma Y+\mu)}] = e^{it\mu} \varphi_Y(\sigma t) = e^{i\mu t - \sigma |t|}. \qedhere\]
\end{proof}

Nótese que la función característica de la distribución de Cauchy no es diferenciable en $0$. Consecuentemente, esta distribución no tiene momentos de orden mayor o igual que 1. El recíproco no sería cierto, esto es, existen distribuciones que no tienen esperanza y su función característica es diferenciable en $0$ \cite{char}.

\begin{prop}
    Sean $X$ e $Y$ dos variables aleatorias independientes con distribuciones $Cauchy(x|\mu_1, \sigma_1)$ y $Cauchy(x|\mu_2, \sigma_2)$ respectivamente. Entonces, $X+Y \sim Cauchy(x|\mu_1+\mu_2,\sigma_1+\sigma_2)$.
\end{prop}
\begin{proof}
    Nótese que $\varphi_{X+Y}(t) = \varphi_{X}(t)\varphi_{Y}(t) = e^{it(\mu_1+\mu_2) - |t| (\sigma_1+\sigma_2)}$. La prueba finaliza al darse cuenta de que ésta es la función característica de $Cauchy(x|\mu_1+\mu_2,\sigma_1+\sigma_2)$.
\end{proof}

\begin{figure}[H]
    \begin{tikzpicture}[
            declare function={gauss(\x,\mu,\sigma)=1/(\sigma*sqrt(2*pi))*exp(-((\x-\mu)^2)/(2*\sigma^2));},
            declare function={cauchy(\x,\mu,\sigma) = 1/((\sigma*pi)*(1+((\x-\mu)/\sigma)^2));}
        ]
        \begin{axis}[
            domain=-5:5, samples=100,
            axis lines=left,
            every axis y label/.style={at=(current axis.above origin),anchor=east},
            every axis x label/.style={at=(current axis.right of origin),anchor=north},
            height=6cm, width=12cm,
            enlargelimits=false, clip=false, axis on top,
            grid = major,
            legend pos=outer north east
        ]
            \addplot [very thick,cyan!70!black] {cauchy(x,0,1)};
            \addlegendentry{Cauchy, $\mu = 0, \sigma = 1$}
            \addplot [very thick,cyan!40!black] {cauchy(x,0,2)};
            \addlegendentry{Cauchy, $\mu = 0, \sigma = 2$}
            \addplot [very thick,magenta!75!black] {gauss(x,0,1)};
            \addlegendentry{Normal, $\mu = 0, \sigma = 1$}
        \end{axis}
    \end{tikzpicture}
    \caption{Densidad de la distribución de Cauchy comparada con la distribución normal.}
    \label{fig:cauchy}
\end{figure}


\subsubsection{Distribución de Laplace}

\begin{definition}
    Sea $\mu \in \mathbb{R}$ y $\sigma > 0$. Definimos la distribución de Laplace, y la denotamos $Laplace(x | \mu, \sigma)$ como la distribución que tiene función de densidad
    \[f(x | \mu, \sigma) = \frac{1}{2 \sigma} e^{-|x - \mu| / \sigma}, \ x \in \mathbb{R}.\]
\end{definition}

\begin{figure}[H]
    \begin{tikzpicture}[
         declare function={gauss(\x,\mu,\sigma)=1/(\sigma*sqrt(2*pi))*exp(-((\x-\mu)^2)/(2*\sigma^2));},
         declare function={laplace(\x,\mu,\sigma) = exp(-abs(\x-\mu) / \sigma)/(2*\sigma);}
        ]
        \begin{axis}[
            domain=-5:5,
            samples=200,
            axis lines=left,
            every axis y label/.style={at=(current axis.above origin),anchor=east},
            every axis x label/.style={at=(current axis.right of origin),anchor=north},
            height=6cm, width=12cm,
            enlargelimits=false,
            clip=false,
            axis on top,
            grid = major,
            legend pos=outer north east
        ]
            \addplot [very thick,cyan!70!black] {laplace(x,0,1)};
            \addlegendentry{Laplace, $\mu = 0, q = 1$}
            \addplot [very thick,cyan!40!black] {laplace(x,0,2)};
            \addlegendentry{Laplace, $\mu = 0, q = 2$}
            \addplot [very thick,magenta!80!black] {gauss(x,0,1)};
            \addlegendentry{Normal, $\mu = 0, q = 1$}
        \end{axis}
    \end{tikzpicture}
    \caption{Densidad de la distribución de Laplace comparada con la densidad de la distribución normal.}
    \label{fig:laplace}
\end{figure}

\subsubsection{Distribución T de Student}

\subsubsection{Distribución de Dirichlet}

\section{Estimación de parámetros}

Supongamos que estamos estudiando un fenómeno aleatorio que sabemos que sigue una distribución $f(X | \theta_0)$, donde $\theta_0 \in \Theta$ es un parámetro que no es conocido. Nuestro objetivo es estimar el parámetro $\theta_0$ a partir de una muestra $x_1, \ldots, x_n$. Para ello buscamos una función $T_n$ de manera que podamos decir $\theta_0 \approx T_n(x_1, \ldots, x_n)$.

\begin{definition}
    Un estimador puntual es una función medible $T_n(X_1, \ldots, X_n)$ que toma valores en $\Theta$, donde $\Theta$ es el dominio del parámetro a estimar. Una estimación es la evaluación obtenida por un estimador sobre una muestra $x_1, \ldots, x_n$, esto es, $T_n(x_1, \ldots, x_n)$.
\end{definition}

Nótese que la nomenclatura es ambigua. Para nosotros una muestra es una secuencia finita de variables aleatorias independientes e idénticamente distribuidas. Sin embargo, a los valores $x_1, \ldots, x_n$ obtenidos en la práctica también se le denomina muestra. Algunos autores evitan esta abigüedad denominando a $x_1, \ldots, x_n$ realización de la muestra. Nosotros distinguiremos entre ambos casos mediante el uso de mayúsculas para denotar variables aleatorias y el uso de minúsculas para denotar valores concretos.

En múltiples situaciones encontramos estimadores de calidad de forma natural. Por ejemplo, imaginemos que el parámetro $\theta_0$ se corresponde con la media de la distribución $f(X | \theta_0)$. En tal caso, parece claro que el mejor estimador para $\theta_0$ será la media muestral $\overline{x} = \frac{1}{n}\sum_{i = 1}^n x_i$. Sin embargo, en general no sabemos qué estimador hay que utilizar. Buscamos técnicas que nos proporcionen estimadores que sean razonables. En ocasiones querremos estimar $g(\theta_0)$, donde $g$ es determinada transformación de $\Theta$ en otro espacio más manejable.

\subsection{Método de los momentos}

El método de los momentos es, probablemente, el método más antiguo para estimar parámetros. Fue propuesto por Pearson al finales del siglo XIX. En muchos casos los resultados de este método son mejorables. Sin embargo, siempre es un último recurso en el caso de que no podamos aplicar otros métodos.

Sea $X_1, \ldots, X_n$ una muestra de un fenómeno con función de distribución $f(X |\theta)$ con $\theta = (\theta_1, \ldots, \theta_m) \in \Theta \subset \mathbb{R}^m$. Definimos los momentos de la muestra como $m_j = \frac{1}{n} \sum_{i = 1}^n X_i^j$. En media se debería cumplir que $m_j = E_\theta X^j$ para todo $j$ tal que $E_\theta X^j$ existe. Nótese que $E_\theta X^j = \mu_j(\theta_1, \ldots, \theta_m)$ es una función que depende de $\theta_1, \theta_2, \ldots, \theta_k$. El método de los momentos propone como estimador a una solución del sistema de ecuaciones
\begin{equation} \label{eq:sistema-momentos}
    \begin{matrix}
        m_1 = \mu_1(\theta_1, \ldots, \theta_k), \\
        m_2 = \mu_2(\theta_1, \ldots, \theta_k), \\
        \vdots \\
        m_k = \mu_k(\theta_1, \ldots, \theta_k). \\
    \end{matrix}
\end{equation}

\begin{ex}[Distribución normal]
    Supongamos que $X_1, \ldots, X_n$ son muestras de una distribución normal $N(\theta, \sigma^2)$. En el contexto anterior, los parámetros a estimar son $\theta_1 = \theta, \theta_2 = \sigma^2$. En este caso el sistema \eqref{eq:sistema-momentos} viene dado por las ecuaciones $\overline{X} = \theta$ y $m_2 = \theta^2 + \sigma^2$. La solución claramente es $\theta = \overline{X}$ y
    \[\sigma^2 = \frac{1}{n} \sum_{i = 1}^n X_i^2 - \overline{X}^2 = \frac{1}{n} \sum_{i = 1}^n (X_i - \overline{X})^2.\]
    En este caso, los estimadores obtenidos coinciden con nuestra intuición. Este método es más útil cuando no disponemos de un estimador intuitivo.
\end{ex}

\subsection{Método de la máxima verosimilitud de Fisher}

    El método de la máxima verosimilitud es una de las técnicas más utilizada para obtener estimadores de calidad.

    \begin{definition}
        Sea $x_1, \ldots, x_n$ una muestra de un fenómeno con función de distribución $f(X | \theta_0)$, donde $\theta_0 \in \Theta$. Se define la función de verosimilitud para cada $\theta \in \Theta$ como $L(\theta | x) = \prod_{i = 1}^n f(x_i| \theta)$.
    \end{definition}

    Para cada posible valor $\theta$ del parámetro a estimar, la verosimilitud proporciona la credibilidad que se le da a $\theta$ para los datos $x_1, \ldots, x_n$. Buscamos una aproximación $\hat{\theta}$ de $\theta_0$ en base a la muestra obtenida. Parece lógico que si asumimos que los datos son correctos, entonces una buena aproximación será aquella en la que los datos sean coherentes, esto es, la probabilidad de que se den datos similares a la muestra observada debe ser lo más alta posible.

    \begin{definition}
        Para cada elemento $x = (x_1, \ldots, x_n)$ del espacio muestral, definimos $\hat{\theta}(x) \in \Theta$ como un máximo global de $L(\theta | x)$. El estimador máximo verosímil (EMV) de una muestra $X$ se define como $\hat{\theta}(X)$.
    \end{definition}

    El estimador máximo verosímil presenta principalmente dos problemas.
    \begin{itemize}
        \item Cálculo del estimador. Para calcular $\hat{\theta}(X)$ es necesario maximizar una función. Muchas veces esto es complejo incluso para funciones de densidad comunes. Es más, puede suceder que la verosimilitud presente múltiples máximos globales y, por tanto, el estimador máximo verosímil no está bien definido. Necesitaremos condiciones sobre la distribución que nos permitan asegurar la buena definición del estimador máximo verosímil.
        \item Sensibilidad numérica. El valor $\hat{\theta}(x)$ puede cambiar considerablemente para pequeñas variaciones de $x$. Nos preguntamos qué condiciones debe verificar la función de distribución para evitar este comportamiento.
    \end{itemize}

    Para adentrarnos en el estudio de estos problemas necesitaremos teoría general de estimadores. Antes de desarrollarla realizaremos varios ejemplos de cálculo de estimadores máximo verosímiles.

    \begin{remark} \label{rem:emv:log}
        Los máximos globales de la función $L(\theta | x)$ se corresponden con los máximos globales de la función $\log L(\theta | x) = \sum_{i = 1}^n \log f(x_i | \theta)$. En múltiples ocasiones es más sencillo maximizar esta última expresión.
    \end{remark}

    \begin{ex}[Distribución normal]
        Consideremos una muestra $X_1, \ldots, X_n$ de un fenómeno con distribución $N(\theta,1)$. En primer lugar, calculamos la función de verosimilitud
        \[L(\theta | x) = \prod_{i = 1}^n \frac{1}{\sqrt{2\pi}} e^{-(x_i - \theta)^2 / 2} = \frac{1}{(2\pi)^{n/2}}e^{-\sum_{i = 1}^n (x_i - \theta)^2 / 2}.\]
        En virtud del Comentario \ref{rem:emv:log} maximizamos la función $-\sum_{i = 1}^n (x_i - \theta)^2 / 2 - n/2 \log(2\pi)$. Maximizar esta función equivale a minimizar $h(\theta) = \sum_{i = 1}^n (x_i - \theta)^2$. Derivando, obtenemos que $h'(\theta) = 0$ si, y solo si, $\theta = \overline{x}$. Además, es rutinario comprobar que $\overline{x}$ es el mínimo absoluto de $h$. Por tanto, $\overline{x}$ es el máximo absoluto de $L(\theta | x)$. Tenemos pues $\hat{\theta}(x) = \overline{x}$.
    \end{ex}

    A continuación pretendemos extender el método de la máxima verosimilitud para estimar $g(\theta)$, donde $g : \Theta \to \Theta'$ sobreyectiva. Si la aplicación $g$ fuese inyectiva, entonces podemos definir de norma natural la verosimilitud de $\eta \in \Theta'$ como $L^*(\eta | x) = L(g^{-1}(\eta) | x)$. Claramente, el valor que maximiza $L^*(\eta | x)$, que denotaremos $\hat{g}(x)$, es $g(\hat{\theta}(x))$. Sin embargo, los casos que presentan relevancia práctica son aquellos en los que $g$ no es inyectiva ya que de esta forma conseguimos reducir la dimensionalidad del espacio de parámetros. Necesitamos extender la definición de verosimilitud para abordar esta problemática.

    \begin{definition}
        En el contexto anterior, definimos la verosimilitud inducida por $g$ como
        \[L^*(\eta|x) = \sup\{L(\theta | x): \theta \in g^{-1}(\eta)\}.\]
        El valor $\hat{g}(x)$ que maximiza $L^*(\eta|x)$ se denomina estimador maximo verosímil de $g(\theta)$.
    \end{definition}

    La definición anterior es artificial en el sentido de que se realiza con el fin de poder mantener la propiedad de invarianza del estimador máximo verosímil, que se recoge en el siguiente teorema.

    \begin{thm}[Invarianza de Zehna]
        Para cualquier aplicación sobreyectiva $g: \Theta \to \Theta'$ se tiene que $\hat{g}(X) = g(\hat{\theta}(X))$.
    \end{thm}
    \begin{proof}
        En primer lugar, la definición de la verosimilitud inducida proporciona
        \[\sup_{\eta \in \Theta'} L^*(\eta|x) = \sup_{\eta \in \Theta'} \sup\{L(\theta | x): \theta \in g^{-1}(\eta)\} = \sup_{\theta \in \Theta} L(\theta | x).\]
        Por tanto, si la verosimilitud tiene un máximo global $\hat\theta(x)$, entonces lo tiene la verosimilitud inducida (el recíproco puede no ser cierto) y se alcanza en $g(\hat\theta(x))$.
    \end{proof}

    \subsection{Teoría general de estimadores}

    En esta sección introduciremos conceptos y definiciones relacionados con estimadores arbitrarios. El objetivo de esta teoría es dotarnos de herramientas que nos permitan abordar el estudio práctico de estimadores concretos, como el estimador máximo verosímil.

    \subsubsection{Estadísticos suficientes}

        Fijemos $\{f(x|\theta): \theta \in \Theta\}$ una familia de distribuciones. Sea $X = (X_1 , \ldots, X_n)$ una muestra de la distribución $f(x|\theta_0)$. Nuestro objetivo es inferir el parámetro $\theta_0$ a partir de la muestra. El concepto de estadístico suficiente nos permitirá separar la información contenida en $X$ en dos partes. Una parte contiene toda la información útil sobre $\theta_0$ mientras que la otra parte no dependerá del parámetro $\theta_0$. Consecuentemente, podemos ignorar esta última parte.

        Intuitivamente, un estadístico $T$ es suficiente para la familia de distribuciones considerada si $T(X)$ nos permite estimar $\theta_0$ tan bien como lo permite toda la muestra $X$. Procedemos a dar la definición matemática.

        \begin{definition}
            Un estadístico $T(X_1, X_2, \ldots, X_n)$ es suficiente si para cada $\theta \in \Theta$ y $t$ la distribución condicional de $X_1, X_2, \ldots, X_n$ respecto de $\theta$ y $T(X) = t$ no depende de $\theta$.
        \end{definition}

        El teorema de factorización de Neyman nos proporciona un criterio práctio para ver si un estadístico es suficiente.

        \begin{thm}
            Sea $\{f(x|\theta): \theta \in \Theta\}$ una familia de distribuciones. Sea $X = (X_1 , \ldots, X_n)$ una muestra de la distribución $f(x|\theta)$. Sea $T(X_1, X_2, \ldots, X_n)$ un estadístico. Entonces, $T$ es  suficiente si y solo si la función de verosimilitud puede factorizarse de la siguiente forma
            \[L(x_1, x_2, \ldots, x_n) = h(t;\theta) g(x_1, x_2, \ldots, x_n),\]
            donde $t = T(x_1, \ldots, x_n)$ y $g(x_1, x_2, \ldots, x_n)$ no depende de $\theta$.
        \end{thm}

        Si encontramos un estadístico suficiente, entonces podemos inferir el parámetro $\theta_0$ utilizando solamente la función $h(t;\theta)$. Interesa pues que el codominio del estadístico suficiente sea lo más simple posible. Los estadísticos suficientes son especialmente interesantes al aplicar el método de la máxima verosimilitud.

        \begin{ex}[Distribución normal, media desconocida]
            Sea $X = (X_1, \ldots, X_n)$ una muestra de $N(x |\mu, \sigma^2)$ donde solamente $\sigma^2$ es conocido ($\theta = \mu$). Es fácil verificar que
            \[\sum_{i = 1}^n (x_i - \mu)^2 = \sum_{i = 1}^n (x_i - \overline{x})^2 + n (\overline{x} - \mu)^2 = (n-1)S^2 + n(\overline{x} - \mu)^2.\]
            A partir de la igualdad anterior obtenemos
            \[f(x|\theta) = \frac{1}{(2\pi\sigma^2)^{n/2}} \exp(-\sum_{i = 1}^n (x_i - \mu)^2 / (2\sigma^2)) = \frac{1}{(2\pi\sigma^2)^{n/2}} \exp(-((n-1)S^2 + n(\overline{x} - \mu)^2) / (2\sigma^2)).\]
            Definimos
            \[g(x_1, x_2, \ldots, x_n) = \frac{1}{(2\pi\sigma^2)^{n/2}} \exp(-(n-1)S^2 / (2\sigma^2)) \text{ y } h(t|\mu) = \exp(n(t - \mu)^2) / (2\sigma^2)).\]
            Tenemos que $f(x|\theta) = h(\overline{x}|\theta) g(x_1, x_2, \ldots, x_n)$ y, por tanto, $T(x) = \overline{x}$ es suficiente.
        \end{ex}

        \begin{ex}[Distribución normal, ambos parámetros son desconocidos]
            Sea $X = (X_1, \ldots, X_n)$ una muestra de $N(x |\mu, \sigma^2)$ donde $\mu$ y $\sigma^2$ son desconocidos ($\theta = (\mu, \sigma^2)$).
            Tenemos que
            \[f(x|\theta) = \frac{1}{(2\pi\sigma^2)^{n/2}} \exp(-\sum_{i = 1}^n (x_i - \mu)^2 / (2\sigma^2)) = \frac{1}{(2\pi\sigma^2)^{n/2}} \exp(-(\sum_{i = 1}^n x_i^2 - 2\mu \sum_{i = 1}^n x_i + n \mu^2) / (2\sigma^2)). \]
            Por tanto, el estadístico $T(X_1, \ldots , X_n) = (\sum_{i = 1}^n X_i^2, \sum_{i = 1}^n X_i)$ es suficiente (tomamos $g(x_1, x_2, \ldots, x_n) = 1$). También podemos desarrollar $f(x|\theta)$ como sigue
            \[f(x|\theta) = \frac{1}{(2\pi\sigma^2)^{n/2}} \exp(-(\sum_{i = 1}^n (x_i - \overline{x})^2 + n(\overline{x} - \mu)^2) / (2\sigma^2)). \]
            Consecuentemente, el estadístico $T(X_1, \ldots , X_n) = (\overline{x}, S^2)$ también es suficiente. Nótese que el estadístico $T(X_1, \ldots , X_n) = (X_1, \ldots , X_n)$ es trivialmente suficiente, pero no aporta ninguna información.
        \end{ex}

    \subsubsection{Score, hipótesis de regularidad y función de información de Fisher}

    \begin{definition}
        Sea $\Theta \subset \mathbb{R}^m$ un abierto y sea $\{f(X|\theta): \theta \in \Theta\}$ una familia de funciones de densidad. Sea $X = (X_1, \ldots, X_n)$ una muestra que sigue una distribución con función de densidad $f(X|\theta_0)$. Si la función de verosimilitud para los valores $x = (x_1, \ldots, x_n)$ es diferenciable en $\theta \in \Theta$, entonces definimos el score de $\theta$ como el gradiente de la función $\log L(x; \theta)$ y lo denotamos $S(x; \theta)$.
    \end{definition}

    Intuitivamente el score indica la sensibilidad de la verosimilitud en un punto. Nos centraremos en el estudio del score cuando $\Theta$ es un abierto de $\mathbb{R}$. En tal caso
    \[S(x; \theta) = \frac{\partial}{\partial \theta} \log f(x | \theta) = \frac{\frac{\partial}{\partial \theta} f(x | \theta)}{f(x | \theta)}.\]

    Supongamos que el score de $\theta$ existe para cualesquiera valores de la muestra $x_1, \ldots, x_n$. En tal caso es natural considerar la función $E_{X|\theta}[S(X;\theta)]$, que depende solamente de $\theta$. Si $\theta$ fuese el parámetro a estimar, entonces $E_{X|\theta}[S(X;\theta)]$ mide la sensibilidad media de la verosimilitud en $\theta$.

    \begin{lem} \label{lem:score:esp}
        Sea $\Theta \subset \mathbb{R}$ un abierto y sea $\{f(X|\theta): \theta \in \Theta\}$ una familia de funciones de densidad que verifican las siguientes condiciones de regularidad:
        \begin{enumerate}
            \item Para cualesquier muestra $x=(x_1, \ldots, x_n)$ la función $L(x; \theta)$ es diferenciable para todo $\theta \in \Theta$.
            \item Se verifica
            \[\frac{\partial}{\partial \theta}\int_{X} f(x| \theta) dx = \int_{X} \frac{\partial}{\partial \theta} f(x| \theta) dx.\]
        \end{enumerate}
        Entonces, $E_{X|\theta}[S(X;\theta)] = 0$.
    \end{lem}
    \begin{proof}
        Tenemos que
        \[E_{X|\theta}[S(X;\theta)] = \int_{X} \frac{\frac{\partial}{\partial \theta} f(x | \theta)}{f(x | \theta)}  f(x | \theta) dx = \int_{X} \frac{\partial}{\partial \theta} f(x | \theta) dx = \frac{\partial}{\partial \theta} \int_{X} f(x; \theta) dx = \frac{\partial}{\partial \theta} 1 = 0. \qedhere\]
    \end{proof}

    En el resultado anterior aparecen por primera vez hipótesis de regularidad sobre las distribuciones a estudiar. Nótese que en la práctica normalmente vamos a trabajar con distribuciones que satisfagan estas hipótesis. La hipótesis b) se verifica si la derivada de la verosimilitud es continua \cite{leibniz}. Consecuentemente, todas las distribuciones continuas estudiadas, exceptuando la distribución de Laplace, cumplen estas hipótesis de regularidad (su función de densidad es de clase infinito con respecto a $\theta$).

    \begin{definition}
        Sea $\Theta \subset \mathbb{R}$ un abierto y sea $\{f(X|\theta): \theta \in \Theta\}$ una familia de funciones de densidad para la cual siempre existe el score. Dado $\theta \in \Theta$, definimos la función de información de Fisher en $\theta$ como el segundo momento de la variable aleatoria $S(X;\theta)$, donde $X = (X_1, \ldots, X_n)$ es una muestra de la distribución con función de densidad $f(X|\theta)$. Se denota $\mathcal{I}(\theta) := E_{X|\theta}[S(X;\theta)^2] \ge 0.$
    \end{definition}

    Si en determinado contexto no está clara la muestra $X$ para la cual calculamos la información de Fisher, entonces la denotamos $\mathcal{I}_X$ o $\mathcal{I}^X$.

    El siguiente resultado nos permite explicar por qué se define de esta forma la información de Fisher.

    \begin{cor}
        Bajo las hipótesis de regularidad del Lema \ref{lem:score:esp}, tenemos que  $\mathcal{I}(\theta) = Var_{X|\theta}(S(X;\theta))$.
    \end{cor}
    \begin{proof}
        Nótese que $Var_{X|\theta}(S(X;\theta)) = \mathcal{I}(\theta) - E_{X|\theta}[S(X; \theta)]^2$. El Lema \ref{lem:score:esp} nos indica que $E_{X|\theta}[S(X; \theta)] = 0$.
    \end{proof}

    Como consecuencia, la información de Fisher nos informa de cómo varía la sensibilidad de la verosimilitud en $\theta$. Si la información de Fisher es pequeña, entonces la sensibilidad de la verosimilitud en $\theta$ no depende prácticamente de la muestra utilizada y, por tanto, siempre será cercana a cero. Si por el contrario la información de Fisher es muy grande, entonces la sensibilidad de la verosimilitud en $\theta$ varía mucho en función de la muestra con la que se trabaje. Si utilizamos el estimador máximo verosímil, entonces estamos maximizando el logaritmo de la verosimilitud. Buscamos pues aquellos $\theta$ que sean extremos relativos de $\log L(x; \theta)$ y, por tanto, verifiquen $S(x; \theta) = 0$. Consecuentemente, nos interesa que $\mathcal{I}(\theta)$ sea grande para todo $\theta$ ya que de esta forma podremos discriminar aquellos $\theta$ que tengan score no nulo (no son extremos relativos de $\log L(x; \theta)$). Si en determinado $\theta$ la información de Fisher es muy pequeña, obtendremos que $\theta$ es un candidato a estimador máximo verosímil para casi cualquier muestra, incluso para muestras poco probables bajo ese parámetro, lo cual dificulta el correcto cómputo del estimador.

    En lo que sigue habitualmente exigiremos unas hipótesis de regularidad más fuertes, denominadas hipótesis o condiciones de regularidad de Cramer-Rao. Estas hipótesis son las siguientes:

    \begin{enumerate}[label=\roman*)]
        \item $\Theta$ es un abierto de $\mathbb{R}$.
        \item Para cualquier muestra $x = (x_1, \ldots, x_n)$, la verosimilitud $L(x | \theta)$ es dos veces derivable en $\Theta$.
        \item $\frac{\partial^i}{\partial\theta^i} \int_X f(x | \theta) dx = \int_X \frac{\partial^i}{\partial\theta^i} f(x | \theta) dx$ para $i=1,2$.
        \item Para cada $\theta \in \Theta$ se tiene $0 < \mathcal{I}(\theta) < +\infty$.
        %\item La función $\Psi(\theta) = \mathbb{E}_{\theta_0} \frac{\partial}{\partial \theta} f(x | \theta)$ es continua en $\theta_0$.
    \end{enumerate}

    Todas las distribuciones continuas estudiadas, exceptuando la distribuciónd de Laplace, verifican estas hipótesis de regularidad.

    El siguiente lema profundiza en nuestro entendimiento de la función de información de Fisher.

    \begin{lem} \label{lem:fisher:2dev}
        Bajo hipótesis de regularidad de Cramer-Rao tenemos que
        \[\mathcal{I}(\theta) = E_{X|\theta} \left[-\frac{\partial^2}{\partial\theta^2} \log f(X;\theta) \right].\]
    \end{lem}
    \begin{proof}
        En primer lugar, podemos escribir
        \[\frac{\partial^2}{\partial\theta^2} \log f(X|\theta)=\frac{\frac{\partial^2}{\partial\theta^2} f(X|\theta)}{f(X| \theta)}\;-\;\left( \frac{\frac{\partial}{\partial\theta} f(X|\theta)}{f(X| \theta)} \right)^2=\frac{\frac{\partial^2}{\partial\theta^2} f(X|\theta)}{f(X| \theta)}\;-\;\left( \frac{\partial}{\partial\theta} \log f(X|\theta)\right)^2.\]
        La demostración finaliza al tomar esperanzas en la expresión anterior y darse cuenta de que
        \[E_{X|\theta}\left[\frac{\frac{\partial^2}{\partial\theta^2} f(X|\theta)}{f(X| \theta)}\right] = \int_X \frac{\partial^2}{\partial\theta^2} f(x | \theta)\, dx = \frac{\partial^2}{\partial\theta^2} \int_X f(x | \theta)\, dx = \frac{\partial^2}{\partial\theta^2} \; 1 = 0. \qedhere\]
    \end{proof}

    Como consecuencia, la información de Fisher también indica cuál es la curvatura media de la función $\log L(x; \theta)$, que como vemos, en media es negativa ($\mathcal{I}(\theta) \ge 0$). Para calcular el estimador máximo verosímil intentamos maximizar $\log L(x; \theta)$. Si la función de información de Fisher es habitualmente grande, entonces en media tendremos máximos relativos muy claros.

    El Lema \ref{lem:fisher:2dev} nos permite calcular la información de Fisher de forma más sencilla, como muestran los siguientes ejemplos.

    \begin{ex} \label{ex:fisher:binom}
        Calculamos la función de información de Fisher de $X \sim B(x | n, \theta)$ donde $n$ es conocido. Recordemos que $\log f(X | n, \theta) = \log \binom{n}{X} + X \log \theta + (n - X) \log (1 - \theta)$. Derivando dos veces respecto de $\theta$ obtenemos
        \[\frac{\partial^2}{\partial \theta^2} f(X | n, \theta) = \frac{-X}{\theta^2} + \frac{-(n-X)}{(1 - \theta)^2}.\]
        Por tanto, la función de información de Fisher responde a
        \[\mathcal{I}_X(\theta) =  E_{X|\theta} \left[\frac{X}{\theta^2} + \frac{(n-X)}{(1 - \theta)^2}\right] = n \left(\frac{1}{\theta} + \frac{1}{1 - \theta}\right) = \frac{n}{\theta (1 - \theta)}. \qedhere\]
    \end{ex}

    \begin{ex}
        Calculamos la función de información de Fisher de $X \sim N(x|\mu, \sigma^2)$ para varias configuraciones de la distribución normal.
        \begin{itemize}
            \item El parámetro $\sigma^2$ es conocido. Tenemos que $\log f(X|\mu, \sigma^2) = - (X-\mu)^2 / (2\sigma^2) - \log(\sqrt{2\pi}) - \log(\sigma^2)/2$. Consecuentemente, deducimos que \[\frac{\partial^2}{\partial\mu^2} f(X|\mu,\sigma^2) = \frac{-1}{\sigma^2}.\]
            Por tanto, $\mathcal{I}(\mu) = 1 / \sigma^2$.
            \item El parámetro $\mu$ es conocido. Obtenemos que
            \[\frac{\partial^2}{\partial(\sigma^2)^2} f(X|\mu,\sigma^2) = -\frac{(X-\mu)^2}{\sigma^6} + \frac{1}{2\sigma^4}.\]
            Por tanto, podemos calcular $\mathcal{I}(\sigma^2)$ utilizando que $E[(X-\mu)^2] = Var(X) = \sigma^2$. Obtenemos que
            \[\mathcal{I}(\sigma^2) = E_{X|\sigma^2}[\frac{(X-\mu)^2}{\sigma^6} - \frac{1}{2\sigma^4}] = \frac{1}{\sigma^6} Var((X-\mu)^2) - \frac{1}{2\sigma^4} = \frac{1}{2\sigma^4}. \qedhere\]
        \end{itemize}
    \end{ex}

    \begin{remark}
        Bajo hipótesis de regularidad de Cramer-Rao, si $X=(X_1, \ldots, X_n)$ es una muestra de $f(X|\theta)$, entonces tenemos que
        \[\frac{\partial^2}{\partial \theta^2}\log(f(X;\theta)) = \frac{\partial^2}{\partial \theta^2} \left(\sum_{i = 1}^n \log(f(X_i;\theta))\right) = \sum_{i = 1}^n \frac{\partial^2}{\partial \theta^2}\log(f(X_i;\theta)).\]
        Consecuentemente, $\mathcal{I}^{X_1, \ldots, X_n}(\theta) = \sum_{i = 1}^n \mathcal{I}^{X_i}(\theta) = n \mathcal{I}^{X_i}(\theta)$.
    \end{remark}

    \begin{lem}
        Bajo hipótesis de regularidad de Cramer-Rao, sea $T(X_1, \ldots, X_n)$ un estadístico tal que su ditribución inducida también verifica las hipótesis de regularidad de Cramer-Rao. Entonces, para cualquier $\theta \in \Theta$ se tiene
        \[\mathcal{I}_{T(X)}(\theta) \le \mathcal{I}_{X}(\theta).\]
        Además, la igualdad se da para todo $\theta \in \Theta$ si, y solo si, $T$ es suficiente.
    \end{lem}

    En lo que sigue necesitaremos el siguiente lema.

    \begin{lem}[Desigualdad de Jenssen]
        Sean $X$ una variable aleatoria cuya imagen está contenida en un intervalo $I$. Sea $g: I \to \mathbb{R}$ una función.
        \begin{enumerate}
            \item Si $g$ es convexa, entonces $E[g(X)] \ge g(E[X])$.
            \item Si $g$ es cóncava, entonces $E[g(X)] \le g(E[X])$
        \end{enumerate}
    \end{lem}

    \begin{prop} \label{prop:desigualdad}
        Sea $X = (X_1, \ldots, X_n)$ una muestra de $f(X;\theta_0)$. Entonces, para cada $\theta_1 \in \Theta$ se tiene
        \[E_{X|\theta_0} \log f(X|\theta_0) \ge E_{X|\theta_0} \log f(X|\theta_1).\]
    \end{prop}
    \begin{proof}
        Por la desigualdad de Jenssen obtenemos
        \[E_{X|\theta_0} \log \frac{f(X|\theta_1)}{f(X|\theta_0)} \le \log \int_X \frac{f(X|\theta_1)}{f(X|\theta_0)} f(X|\theta_0) \, dx = \log \int_X f(X|\theta_1) \, dx = 0,\]
        de donde se deduce el resultado.
    \end{proof}

    Cabe mencionar que la información de Fisher puede definirse cuando $\Theta \subset \mathbb{R}^m$. Incluimos la definición por complitud, aunque no entraremos en ella a fondo.

    \begin{definition}
        Sea $\Theta \subset \mathbb{R}^m$ un abierto y sea $\{f(X|\theta): \theta \in \Theta\}$ una familia de funciones de densidad para la cual siempre existe el score. Dado $\theta \in \Theta$, definimos la función de información de Fisher en $\theta$ como
        \[{\left(\mathcal{I} \left(\theta \right) \right)}_{i, j} = E_{X|\theta} \left[
          \left(\frac{\partial}{\partial\theta_i} \log f(X;\theta)\right)
          \left(\frac{\partial}{\partial\theta_j} \log f(X;\theta)\right)\right], \ 1 \le i,j \le m,\]
        donde $X = (X_1, \ldots, X_n)$ es una muestra de la distribución con función de densidad $f(X|\theta)$.
    \end{definition}

    Bajo determinadas hipótesis de regularidad se puede probar que para cada $1 \le i, j \le n$ se verifica

    \[{\left(\mathcal{I} \left(\theta \right) \right)}_{i, j} =
      -E_{X|\theta}\left[\frac{\partial^2}{\partial\theta_i \, \partial\theta_j} \log f(X;\theta)
    \right].\]

    \begin{ex}
        Calculamos la función de información de Fisher de una variable aleatoria $X$ que siga una distribución $Beta(x | p, q)$, donde $\theta = (p, q)$. Recordemos que
        \begin{equation} \label{eq:log-beta}
            \log f(x | p, q) = (p-1) \log x + (q-1) \log (1-x) - \log \beta(p, q).
        \end{equation}
        Recordemos que $\beta(p,q) = \Gamma(p) \Gamma(q) / \Gamma(p+q)$. Habitualmente al cociente $\Gamma'(p)/\Gamma(p)$ se le llama función digamma y se denota $\psi(p)$. Las derivadas parciales de \eqref{eq:log-beta} son las siguientes:
        \begin{enumerate}
            \item $\frac{\partial}{\partial p} \log f(x | p, q) = \log x + \psi(p+q) - \psi(p).$
            \item $\frac{\partial}{\partial q} \log f(x | p, q) = \log(1-x) + \psi(p+q) - \psi(q).$
            \item $\frac{\partial^2}{\partial p^2} \log f(x | p, q) = \psi'(p+q) - \psi'(p).$
            \item $\frac{\partial^2}{\partial q^2} \log f(x | p, q) = \psi'(p+q) - \psi'(q).$
            \item $\frac{\partial^2}{\partial p\partial q} \log f(x | p, q) = \psi'(p+q).$
        \end{enumerate}

        Nótese que las derivadas obtenidas no dependen de $x$ y, por tanto, al tomar esperanzas obtenemos las mismas derivadas. Consecuentemente, la función de información de Fisher de $X$ viene dada por
        \[\mathcal{I}_X(p, q) = - \left(\begin{matrix} \psi'(p+q) - \psi'(p) & \psi'(p+q) \\ \psi'(p+q) & \psi'(p+q) - \psi'(q) \end{matrix}\right). \qedhere\]

    \end{ex}

    \subsubsection{Estimadores insesgados}

    Para comprobar cómo de bueno es un estimador $T$ podemos definir una función de pérdida $L(\theta,T(X))$ que indique la pérdida asociada a estimar un parámetro mediante $T$ si su verdadero valor es $\theta$. A partir de la función de pérdida definimos la función de riesgo, que asocia a cada posible valor del parámetro la pérdida media producida por el estimador. La función de riesgo viene dada por
    \[ R^L_T(\theta) = E_{X|\theta} [L(\theta,T(X))].\]
    Un estimador $T$ que ``minimice uniformemente'' la función de riesgo hará mejores estimaciones en media. Con minimizar uniformemente queremos decir que para cada estimador $T'$ se tiene que
    \[ R^L_T(\theta) \leq R^L_{T'}(\theta) \ \forall \ \theta \in \Theta.\]

    En esta sección introducimos un tipo particular de estimadores que minimizan determinada función de riesgo.

    \begin{definition}
        Se denomina sesgo de un estimador $T$ de $g(\theta)$ a la diferencia entre la esperanza del estimador y el verdadero valor del parámetro a estimar. Diremos que un estimador es insesgado si para cualquier posible valor del parámetro a estimar su sesgo es nulo.
    \end{definition}

    Nótese que el sesgo de un estimador es la función de riesgo asociada a la pérdida $L(\theta,T(X)) = g(\theta) - T(X)$. Un estimador insesgado verifica $0 = g(\theta) - E_{X|\theta} T(X)$ y, por tanto, minimiza uniformemente la función de riesgo. Aunque esta propiedad puede parecer a priori interesante, puede suceder que en la práctica el estimador insesgado no proporcione estimaciones de calidad si la varianza $Var_{X|\theta}(T(X))$ es muy alta.

    Claramente, la media muestral es un estimador insesgado de la media de la distribución. El siguiente resultado nos muestra otro ejemplo de un estimador insesgado.

    \begin{prop}
        Sea $X_1, \ldots, X_n$ una muestra de alguna población con función de densidad $f(X | \theta_0)$. Definimos la varianza muestral como
        \[S^2 = \frac{1}{n-1}\sum_{i = 1}^n(X_i - \overline{X})^2.\]
        Entonces, $S^2$ es un estimador insesgado de la varianza de la distribución.
    \end{prop}
    \begin{proof}
        Nótese que $\sum_{i = 1}^n(X_i - \overline{X})^2 = \sum_{i = 1}^nX_i^2 - n\overline{X}^2$. Consecuentemente tenemos
        \[E\left[\sum_{i = 1}^n(X_i - \overline{X})^2\right] = \sum_{i = 1}^nE\left[X_i^2\right] -     nE[\overline{X}^2] = n(E\left[X_i^2\right] - E[\overline{X}^2]).\]
        Utilizando que $Var(\overline{X}) = Var(X_i) / n$ y $E[\overline{X}] = E[X_i]$ obtenemos
        \[E[X_i^2] - E[\overline{X}^2] = Var(X_i) + E[X_i]^2 - Var(\overline{X}) - E[\overline{X}]^2 = \frac{n-1}{n} Var(X_i).\]
        Por tanto, $E[S^2] = Var(X_i)$ como se quería.
    \end{proof}

    La función de información de Fisher juega un papel importante en el estudio de los estimadores insesgados como muestra el siguiente Teorema.

    \begin{thm}[Cota de Cramer-Rao]
        Supongamos que se verifican las hipótesis de regularidad de Cramer-Rao. Sea $g: \Theta \to  \mathbb{R}$ de clase 1. Sea $\hat{\theta}$ un estimador insesgado de $g(\theta)$ tal que
        \[\int_X \left|\hat{\theta}(x) \frac{\partial}{\partial \theta}f(x | \theta)\right| dx < \infty.\]
        Entonces, para todo $\theta \in \Theta$
        \[Var_{X|\theta}(\hat{\theta}) \ge \frac{g'(\theta)^2}{\mathcal{I}(\theta)}.\]
    \end{thm}
    \begin{proof}
        Puesto que $\hat{\theta}$ es insesgado tenemos que
        \[g(\theta) = \int_X \hat{\theta}(x) f(x|\theta)\,dx.\]
        Podemos derivar respecto de $\theta$ la expresión anterior y utilizar que $\int_X \frac{\partial}{\partial \theta}f(x|\theta) \, dx = 0$, obteniendo
        \begin{equation}\label{eq:proof-cr}
        g'(\theta) = \int_X \hat{\theta}(x)\frac{\partial}{\partial \theta}f(x|\theta)\,dx = \int_X \left(\hat{\theta}(x) - g(\theta)\right)\frac{\partial}{\partial \theta}f(x|\theta)\,dx.
        \end{equation}
        Aplicamos la desigualdad de Cauchy-Schwarz al miembro de la derecha de \eqref{eq:proof-cr}, obteniendo
        \[g'(\theta)^2  \le \left( \int \left(\hat\theta(x) - g(\theta)\right)^2 f(x|\theta) \, dx \right) \left(\int \left( \frac{\partial}{\partial\theta} (\log f(x|\theta)) \right)^2 f(x|\theta) \, dx \right) = Var_{X|\theta}(\hat\theta) \, \mathcal{I}(\theta). \qedhere\]
    \end{proof}

    \begin{cor}
        Supongamos que se verifican las hipótesis de regularidad de Cramer-Rao. Sea $\hat{\theta}$ un estimador insesgado de $\theta$ tal que
        \[\int_X \left|\hat{\theta}(x) \frac{\partial}{\partial \theta} f(x | \theta)\right| dx < \infty.\]
        Entonces, para todo $\theta \in \Theta$
        \[Var_{X|\theta}(\hat{\theta}) \ge \frac{1}{\mathcal{I}_X(\theta)} = \frac{1}{n\mathcal{I}_{X_i}(\theta)}.\]
    \end{cor}

    La cota de Cramer-Rao nos dice que si la información de Ficher en $\theta$ es pequeña, entonces cualquier estimador insesgado tendrá una gran varianza y, por tanto, será inestable ante pequeños cambios en la muestra.

    \begin{definition}
        Un estimador se dice eficiente si alcanza la cota de Cramer-Rao para todo $\theta \in \Theta$.
    \end{definition}

    \subsubsection{Consistencia de sucesiones de estimadores}

    Nos interesa que los estimadores tiendan al parámetro de la distribución cuando el tamaño de la muestra diverge. En tal caso, podemos mejorar el resultado del estimador recurriendo a una mayor muestra de la población.

    \begin{definition}
        Consideremos una familia de densidades $\{f(x | \theta) : \theta \in \Theta\}$. Una sucesión de estimadores $\hat\theta_n$ de $g(\theta)$ es consistente para $\theta_0 \in \Theta$ si toda sucesión $X_n$ de variables aleatorias independientes e idénticamente distribuidas con función de distribución $f(x | \theta_0)$ la sucesión $\hat\theta_n(X_1, \ldots, X_n)$ converge en probabilidad ($P_{\theta_0}$) a $g(\theta_0)$. Si $\hat\theta_n$ es consitente para todo $\theta_0 \in \Theta$, entonces decimos que es consistente.
    \end{definition}

    \begin{thm}
        Sea $\hat\theta_n$ una sucesión de estimadores de $g(\theta)$ verificando
        \begin{enumerate}
            \item $\lim_{n \to \infty} E_\theta[\hat\theta_n] = g(\theta)$;
            \item $\lim_{n \to \infty} Var_\theta(\hat\theta_n) = 0$.
        \end{enumerate}
        Entonces, $\hat\theta_n$ es consistente para $\theta$.
    \end{thm}
    \begin{proof}
        Sea $\varepsilon > 0$. La desigualdad de Markov nos proporciona
        \[P_\theta[|\hat\theta_n - g(\theta)| \ge \varepsilon] \le \varepsilon^{-2} E[(\hat\theta_n - g(\theta))^2] = \varepsilon^{-2}  \left(Var(\hat\theta_n) + (E\hat\theta_n -g(\theta))^2\right).\]
        La prueba finaliza al recordar que el último término converge a $0$.
    \end{proof}

    Otra propiedad interesante de un estimador cuando la muestra tiene a infinito es la siguiente.

    \begin{definition}
        Consideremos una familia de densidades $\{f(x | \theta) : \theta \in \Theta\}$. Una sucesión de estimadores $\hat\theta_n$ de $g(\theta)$ es asintóticamente normal para $\theta_0 \in \Theta$ si toda sucesión $X_n$ de variables aleatorias independientes e idénticamente distribuidas con función de distribución $f(x | \theta_0)$ la sucesión $\sqrt{n}(\hat\theta_n(X_1, \ldots, X_n) - g(\theta_0))$ converge en ley a una distribución $N(X|0,\sigma^2)$ para cierto $\sigma^2 > 0$.
    \end{definition}

    \begin{prop}
        Todo estimador asintóticamente normal es consistente.
    \end{prop}
    \begin{proof}
        Sea $\hat\theta_n$ un estimador asintóticamente normal de $g(\theta)$. Tenemos que $n (\hat\theta_n - g(\theta))^2$ converge en ley a $Gamma(X|1/2, 1/(2\sigma^2))$ por la Proposición \ref{prop:normal-square}. Sea $F$ la función de distribución de $Gamma(X|1/2, 1/(2\sigma^2))$ y sea $\varepsilon > 0$. Vamos a probar que $P[(\hat\theta_n - g(\theta))^2 < \varepsilon] \to 1$. En efecto, sea $1 > \alpha \ge 0$. Tomamos $y$ tal que $F(y) = \alpha$. Tenemos que
        \[P[n(\hat\theta_n - g(\theta))^2 < y] \to F(y) = \alpha.\]
        Por tanto, para cada $\delta > 0$ existe $n_0$ tal que $\varepsilon > y /n$ y para cada $n \ge n_0$ tenemos
        \[P[(\hat\theta_n - g(\theta))^2 < \varepsilon] \ge P[n(\hat\theta_n - g(\theta))^2 < y] \ge \alpha - \delta.\]
        Deducimos que $\liminf P[(\hat\theta_n - g(\theta))^2 < \varepsilon] \ge \alpha - \delta.$ De la arbitrariedad de $\delta$ y $\alpha$ se deduce el resultado.
    \end{proof}

    Como es natural, el recíproco del anterior no es cierto.

    \subsection{Estudio teórico del estimador máximo verosímil}

    En este punto nos preguntamos cuándo está bien definido el estimador máximo verosímil. En tal caso nos interesa saber si el método de la máxima verosimilitud nos proporciona un estimador consistente. Para ello aplicamos los resultados teóricos vistos en la sección anterior.

    \begin{prop}
        Si existe un estadístico suficiente $T$ par ala familia de distribuciones $\{f(X|\theta): \theta \in \Theta\}$ y $\hat\theta$ es un estimador máximo verosímil, entonces $\hat\theta$ depende solamente de $T(X)$.
    \end{prop}
    \begin{proof}
        Por el teorema de factorización de estimadores suficientes podemos escribir $f(X|\theta) = h(X) g(T(X), \theta)$. Maximizar $L(x; \theta) = h(x) g(T(x); \theta)$ equivale a maximizar $g(T(x); \theta)$. Por tanto, $\hat\theta$ depende solamente de $T(x)$.
    \end{proof}

    \begin{thm}
        Bajo las hipótesis de regularidad de Cramer-Rao se verifican las siguientes afirmaciones:
        \begin{enumerate}
            \item Existe $n_0$ tal que para cada $n \ge n_0$ la ecuación en probabilidad $0 =\sum_{i=0}^n \frac{\partial}{\partial \theta} \log f(X_i | \theta)$ tiene solución única. A esta solución se le llama $\hat{\theta}_n(X_1, \ldots, X_n)$. En dicho punto se maximiza la verosimilitud.
            \item $\hat{\theta}(X_1, \ldots, X_n)$ es consistente. De hecho, se puede probar que la convergencia a $\theta_0$ es casi segura.
        \end{enumerate}
    \end{thm}
    \begin{proof}
        Para cualquier muestra $X$ de $f(X|\theta_0)$ tenemos que
        \[0 > -\mathcal{I}(\theta_0)=E_{X|\theta_0}\left[ \frac{\partial^2}{\partial\theta^2} \log f(X;\theta_0)\right] = \frac{\partial}{\partial\theta} E_{X|\theta_0} \left[ \frac{\partial}{\partial\theta} \log f(X;\theta_0) \right].\]
        Consecuentemente, $E_{X|\theta_0} \left[ S(X; \theta) \right]$ es decreciente en un entorno de $\theta_0$. Recordemos que $E_{X|\theta_0} \left[ S(X; \theta_0) \right] = 0$ por el Lema \ref{lem:score:esp}. Por tanto, existe $\varepsilon > 0$ tal que
        \begin{itemize}
            \item $E_{X|\theta_0} \left[ S(X; \theta) \right] > 0$ para todo $\theta \in (\theta_0 - \varepsilon, \theta_0)$;
            \item $E_{X|\theta_0} \left[ S(X; \theta) \right] < 0$ para todo $\theta \in (\theta_0, \theta_0 + \varepsilon)$.
        \end{itemize}
        Esto implica que $\theta_0$ es un máximo relativo de $E_{X|\theta_0}[\log f(X|\theta)]$.
        INCOMPLETO.
    \end{proof}

    \begin{thm}
        Bajo hipótesis de regularidad de Cramer-Rao, si $\hat{\theta}(X_1, \ldots, X_n)$ es un estimador máximo verosímil consistente, entonces es asintóticamente normal. Además, la varianza de la distribución normal asociada es $1/\mathcal{I}_{X_1}(\theta_0)$.
    \end{thm}
    \begin{proof}
        Escribimos $L_n(\theta) = \frac{1}{n}\sum_{i = 1}^n \log f(X_i|\theta)$. Tenemos que $L_n'(\hat\theta_n) = 0$. El teorema del valor medio nos proporciona un $\theta_n$ entre $\theta_0$ y $\hat\theta_n$ tal que $0 = L_n'(\hat\theta) = L_n'(\theta_0) + L_n''(\theta_n)(\hat\theta_n - \theta_0)$. Por tanto,
        \begin{equation} \label{eq:seq-normal}
            \sqrt{n}(\theta_0 - \hat\theta_n) = \frac{\sqrt{n}L_n'(\theta_0)}{L_n''(\theta_n)}.
        \end{equation}
        Por el teorema central del límite tenemos que
        \[\sqrt{n}L_n'(\theta_0) = \sqrt{n}(L_n'(\theta_0) - E_{\theta_0}[S(X_1; \theta_0)]) \to N(0, \mathcal{I}_{X_1}(\theta_0)),\]
        donde hemos utilizado que $Var_{\theta_0}(S(X_1; \theta_0)) = \mathcal{I}_{X_1}(\theta_0)$.
        Estudiamos ahora el denominador de \eqref{eq:seq-normal}. Puesto que $\hat\theta_n$ converge en probabilidad a $\theta_0$ y $\theta_n$ se encuentra entre ambos, tenemos que $\theta_n$ converge en probabilidad a $\theta_0$. Además, la ley uniforme de los grandes números nos garantiza que
        \[L_n''(\theta) \xrightarrow{P_{\theta_0}} E_{\theta_0}\left[\frac{\partial^2}{\partial \theta^2}f(X_1|\theta)\right],\]
        siendo la convergencia uniforme en espacios de parámetros compactos. Por tanto, tomando un compacto que contenga una cola de $\theta_n$ obtenemos la mencionada convergencia uniforme. De esta convergencia uniforme se desprende que
        \[L_n''(\theta_n) \xrightarrow{P_{\theta_0}} E_{\theta_0}\left[\frac{\partial^2}{\partial \theta^2}f(X_1|\theta_0)\right] = - \mathcal{I}_{X_1}(\theta_0).\]
        Hemos obtenido pues
        \[\sqrt{n}(\theta_0 - \hat\theta_n) = \frac{\sqrt{n}L_n'(\theta_0)}{L_n''(\theta_n)} \rightarrow N(0, \frac{1}{\mathcal{I}_{X_1}(\theta_0)}). \qedhere\]
    \end{proof}

\section{La familia exponencial}


Una variable aleatoria se distribuye respecto de una familia exponencial si $ X  \sim   f(x | \theta_1, ... \theta_k) = l(x)  e ^{\sum^k_{i=1} \theta_i T_i(x)  + \Psi (\theta_1, ..., \theta_k)}$ . Esta función de probabilidad le confiere a las distribuciones de esta familia unas características muy convenientes, que se manifiestan a la hora de calcular, por ejemplo, un estadístico suficiente para una muestra $x_1, ..., x_n$.

Supongamos que en vez de $x$ tenemos un vector$ x = (x_1, ..., x_n)$, entonces 

\begin{equation*}
f(x_1,...,x_n | \theta_1, ... \theta_k) = \prod_{i=1}^{n}l(x_i)  e ^{{\sum^n_{i=1}}{\sum^k_{j=1} \theta_i T_i(x_j)  + n\Psi (\theta_1, ..., \theta_k)}} = \prod_{i=1}^{n}l(x_i)  e ^{{\sum_{i=1}^{n}\theta_i}{\sum^k_{j=1}  T_i(x_j)  + n\Psi (\theta_1, ..., \theta_k)}} 
\end{equation*}


De donde obtenemos que $U_i(x_1,...,x_n) = \sum^n_{j=1} T_i(x_j)$ es un estadístico suficiente de dimensión k (siempre tendrá dimensión finita aunque la muestra aumente).

A continuación veremos unos ejemplos en los que esto se cumple:

\begin{example}
	Cualquier distribución de probabilidad siguiendo una distribución $N(x|\mu, \sigma ^2 )$ admite un estadístico suficiente de dimensión dos.
	
	Este estadístico es $T = (\overline{x}, s^2)$ donde:
	\begin{equation*}
	\overline{x} = \frac{1}{n} \sum^n_{i=1} x_i 
	\end{equation*}
	
	\begin{equation*}
	s^2 = \frac{1}{n} \sum^n_{i=1}(x_i-\overline{x})^2 %s^2 = \frac{1}{n} \sum^n_{i=1}(x_i - \overline{x})^2
	\end{equation*}
	
\end{example}

Casi todas las distribuciones que usamos en probabilidad pertenecen a una familia exponencial, aquí una lista de ejemplos:

\begin{table}[h!]
	\begin{center}
		\begin{tabular}{|l|l|l|}
			\hline
			DENSIDAD & NOTACIÓN & SOPORTE\\
			\hline \hline
			$\frac{1}{\Gamma(\alpha)\beta^\alpha}x^{\alpha - 1}e^{\frac{-x}{\beta}}$ & $ G(x|\alpha,\beta)$ &   $(0,\infty)  $\\ \hline
			$\frac{1}{\Gamma(\frac{p}{2})2^{\frac{p}{2}}}x^{\frac{p}{2} - 1}e^{\frac{-x}{2}}$ & $\chi^2$ con p grados de libertad  & $(0,\infty)  $ \\ \hline
			$\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) \Gamma(\beta)} x ^{\alpha - 1}(1-x)^{\beta - 1}$ &  $B(x| \alpha, p)$   &   $(0,1)$   \\ \hline
			$\binom{n}{x} \theta ^x (1-\theta)^{n-x}$ &  $B(x|\theta, n)$ & ${0,1, ... , n}$   \\ \hline
			$\frac{e^{-\lambda} \lambda^x}{x!}$ & $P(x|\lambda)$ & ${0,1, ... , n}$   \\ \hline
		\end{tabular}
		\label{tabla:1}
	\end{center}
\end{table}


\section{Tests de hipótesis}


\section{Estadística bayesiana}

En esta sección estudiaremos el modelo de inferencia estadística desde el punto de vista bayesiano.

\subsection{Introducción}

Empecemos recordando uno de los teoremas clásicos de la probabilidad, el teorema de Bayes, que va a ser la base del modelo que queremos establecer. Supongamos que en el espacio de probabilidad \[(\Omega,\mathcal{A},P)\] tenemos la partición de \[\Omega\] dada por los sucesos \[A_1,\dots,A_n\], todos ellos con probabilidad no nula. Y sea \[B\] un suceso no nulo del que conocemos sus probabilidades condicionadas a cada suceso \[A_i\]. Entonces, podemos obtener la probabilidad de cada $A_i$ condicionada al suceso $B$ de la siguiente forma:

\begin{equation*}
	P(A_i|B)=\frac{P(A_i\cap B)}{P(B)}=\frac{P(B|A_i)P(A_i)}{P(B)}
\end{equation*}

A su vez, la ley de la probabilidad total establece que \[P(B)=\sum_{i=1}^n{P(B|A_i)P(A_i)}\], luego:

\begin{equation*}
	P(A_i|B)=\frac{P(B|A_i)P(A_i)}{\sum_{i=1}^n{P(B|A_i)P(A_i)}}
\end{equation*}

Donde los valores \[P(B|A_i)\] son conocidos. Los valores $P(A_i)$ son lo que llamaremos probabilidades a priori, mientras que los $P(A_i|B)$ serán las probabilidades a posteriori.

La estadística bayesiana sigue esta idea, basándose en la interpretación subjetiva de la probabilidad. Para ello, utiliza la percepción existente, por parte del investigador, como una variable modificadora (distribución a priori) de los datos muestrales, que dan lugar a una distribución (distribución a posteriori), con la que formular inferencias con respecto al parámetro de interés. Pasemos a definir formalmente estas distribuciones:

\begin{definition}
	Sea \[X_{\sim}=(X_1,\dots,X_n)\] un vector de variables aleatorias de la familia de densidades \[\{f(x_{\sim}|\theta)|\theta = (\theta_1,\dots,\theta_k) \in \Theta \subset \mathbb{R}^k \} \]. A una distribución \[\pi(\theta)\] sobre el espacio \[\Theta \] establecida con información previa conocida sobre \[\theta\] se le llama distribución a priori de la variable aleatoria \[\theta\].
	
	Dada una muestra \[x_{\sim} = x_1,\dots,x_n\] de \[X_{\sim}\], se define la probabilidad a posteriori de \[\theta\] condicionada a la muestra como:
	
	\begin{equation*}
		\pi(\theta|x_{\sim})= \frac{f(x_{\sim}|\theta)\pi(\theta)}{\int_{\Theta}{f(x_{\sim}|\theta)\pi(\theta)d\theta}}
	\end{equation*}
\end{definition}

\subsection{Estadística clásica vs Bayesiana}

Veamos ahora las diferencias entre la inferencia clásica y la bayesiana. En la inferencia clásica destacan las siguientes características:

\begin{itemize}
	\item El concepto de probabilidad está limitado a aquellos sucesos en los que se pueden definir frecuencias relativas.
	\item \[\theta\] es un valor fijo, pero desconocido.
	\item Se usa el concepto de intervalo de confianza (AÑADIR SI ESO)
	\item El método de muestreo es muy importante.
	\item Se pueden usar estimadores de máxima verosimilitud o estimadores insesgados.
\end{itemize}

Por su parte, en la inferencia bayesiana destacan:

\begin{itemize}
	\item Podemos establecer probabilidades previas para cualquier suceso.
	\item \[\theta\] es una variable que sigue una distribución de probabilidad.
	\item Se usa el concepto de intervalo de credibilidad para \[\theta\]. (AÑADIR SI ESO)
	\item El método de muestreo no importa; solo importan los datos.
	\item Se utilizan estimadores diferentes según la utilidad; la estimación es un problema de decisión.
\end{itemize}

Una parte muy importante en la inferencia bayesiana es la selección de la distribución a priori. En muchos casos, si no disponemos de una distribución clara para modelar \[\theta\] es posible considerar distribuciones específicas que permitan simplificar los cálculos de la distribución a posteriori. A continuación estudiaremos distintos medios para seleccionar estas distribuciones.

\subsection{Familias conjugadas}

La principal dificultad que surge en los problemas de inferencia bajo la perspectiva bayesiana es tanto la confianza que se pueda esperar de la distribución a priori como el cálculo de la distribución a posteriori. La primera cuestión es importante ya que la inferencia que se realice posteriormente puede depender de la elección hecha de la distribución inicial, razón por la cual en muchos casos se recurre a distribuciones no informativas, que no imponen unas condiciones muy fuertes sobre el parámetro, o bien se puede aprovechar parte de la información muestral para mejorar la distribución inicial, dando origen a las denominadas distribuciones intrínsecas a priori, de gran auge en la actualidad.

En cuanto a la segunda opción, el cálculo de la distribución a posteriori no tiene por qué conducir a una distribución tratable y, en ocasiones, hay que
recurrir a métodos numéricos para poder trabajar con ellas. Centrándonos en esta última parte, interesa considerar familias de distribuciones a priori cuyas distribuciones a posteriori asociadas sean de fácil cálculo. En este sentido surge el concepto de familias a priori conjugadas.

\begin{definition}
	Sea \[\mathcal{F} = \{\pi_i(\theta)|i\in I\} \] una familia de distribuciones a priori. \[\mathcal{F}\] se dice que es conjugada respecto de la familia de densidades \[\{f(x|\theta)|\theta\in\Theta\}\], si para cualquier \[\pi(\theta)\in\mathcal{F}\] se verifica que \[f(x|\theta)\pi(\theta)\in\mathcal{F}\].
\end{definition}

Tener una familia de distribuciones conjugadas a priori nos permite simplificar en gran medida el cálculo de la distribución a posteriori, pues para el cálculo de la distribución marginal de $x$ (la integral) en el denominador del cociente, tenemos una integral de una función de la familia \[\mathcal{F}\], que sabemos que integra 1. En la práctica el producto de las distribuciones podría no estar normalizado, pero en tal caso, si la distribución a priori es conjugada, las constantes son las mismas en numerador y denominador, permitiendo reducir de nuevo el cálculo (explicar mejor).

Es posible calcular las distribuciones conjugadas para las familias de distribuciones clásicas, obteniendo de nuevo otras distribuciones clásicas.

\begin{prop}
	\begin{itemize}
		\item La familia de distribuciones Beta es una familia de distribuciones conjugada para las distribuciones de Bernouilli, binomiales y binomiales negativas.
		
		\item La familia de distribuciones Gamma es una familia de distribuciones conjugada para las distribuciones de Poisson y (exponenciales (definir)).
		
		\item La familia de distribuciones normales es una familia de distribuciones conjugada para la familia de distribuciones normales con varianza conocida.
	\end{itemize}
\end{prop}
\begin{proof}
	Próximamente.	
\end{proof}

\begin{example}
	Vamos a aplicar lo que hemos visto a la distribución de Poisson.
\end{example}




\begin{definition}
    Sea $\{f(x | \theta): \theta \in \Theta \}$ una familia de distribuciones con parámetro $\theta \in \Theta$. La distribución a priori de Jeffreys se define como $\pi^{J}(\theta) \propto \sqrt{\mathcal{I}_X(\theta)}$.
\end{definition}

\begin{ex}
    Vamos a estudiar la distribución a priori de Jeffreys para la distribución binomial. En el ejemplo \ref{ex:fisher:binom} se calculó la función de información de Fisher para la distribución binomial. A partir de los resultados obtenidos tenemos que $\pi^J(\theta) \propto \theta^{-1/2} (1 - \theta)\theta^{-1/2}$. Por tanto, $\pi^J(\theta)$ sigue una distribución $beta(1/2,1/2)$. La distribución a posteriori para $x = (x_1, \ldots, x_k)$ viene dada por
    \[\pi(\theta; x) \propto \pi(\theta) \prod_{i = 1}^k f(x_i; \theta) \propto \theta^{\sum x_i -1/2} (1 - \theta)^{\sum (n-x_i) -1/2},\]
    esto es, $\pi(\theta;x)$ sigue una distribución $beta(k\overline{x} -1/2, k(n - \overline{x}) - 1/2)$. Recordando el Corolario \ref{cor:beta:esp} podemos calcular la esperanza y la varianza de la distribución a posteriori:
    \[E[\pi(\theta; x)] = \frac{k\overline{x} -1/2}{kn - 1} = \frac{\overline{x} -1/(2k)}{n - 1/k};\]
    \[Var(\pi(\theta; x)) = \frac{(k\overline{x} -1/2)(k(n - \overline{x}) - 1/2)}{(kn - 1)^2(kn)} = \frac{(\overline{x} -1/{2k})((n - \overline{x}) - 1/(2k))}{kn(n - 1/k)^2}.\]
    Para $k$ lo suficientemente grande $E[\pi(\theta; x)] \approx \overline{x} / n$, que es el estimador máximo verosímil. Por tanto, cuando $k \to \infty$ obtenemos que $Var(\pi(\theta; x)) \to 0$ y $E[\pi(\theta; x)] \to \theta_0$.
\end{ex}

\begin{thebibliography}{99}
\bibitem{gamma} Proof Wiki, Euler's Reflection Formula, \url{https://proofwiki.org/wiki/Euler%27s_Reflection_Formula}.
\bibitem{cauchy} Wikipedia, Residue theorem, \url{https://en.wikipedia.org/wiki/Residue_theorem#Example}.
\bibitem{leibniz} Wikipedia, Leibniz integral rule, \url{https://en.wikipedia.org/wiki/Leibniz_integral_rule}.
\bibitem{char} Davide Giraudo, No first moment and differentiable characteristic function, \url{http://math.stackexchange.com/questions/793788/continuous-probability-distribution-with-no-first-moment-but-the-characteristic}
\end{thebibliography}
\end{document}
