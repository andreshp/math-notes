%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Plantilla básica de Latex en Español.
%
% Autor: Andrés Herrera Poyatos (https://github.com/andreshp)
%
% Es una plantilla básica para redactar documentos. Utiliza el paquete fancyhdr para darle un
% estilo moderno pero serio.
%
% La plantilla se encuentra adaptada al español.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%-----------------------------------------------------------------------------------------------------
%	INCLUSIÓN DE PAQUETES BÁSICOS
%-----------------------------------------------------------------------------------------------------

\documentclass{article}

%-----------------------------------------------------------------------------------------------------
%	SELECCIÓN DEL LENGUAJE
%-----------------------------------------------------------------------------------------------------

% Paquetes para adaptar Látex al Español:
\usepackage[spanish,es-noquoting, es-tabla, es-lcroman]{babel} % Cambia
\usepackage[utf8]{inputenc}                                    % Permite los acentos.
\selectlanguage{spanish}                                       % Selecciono como lenguaje el Español.

%-----------------------------------------------------------------------------------------------------
%	SELECCIÓN DE LA FUENTE
%-----------------------------------------------------------------------------------------------------

% Fuente utilizada.
\usepackage{courier}                    % Fuente Courier.
\usepackage{microtype}                  % Mejora la letra final de cara al lector.

%-----------------------------------------------------------------------------------------------------
%	ESTILO DE PÁGINA
%-----------------------------------------------------------------------------------------------------

% Paquetes para el diseño de página:
\usepackage{fancyhdr}               % Utilizado para hacer títulos propios.
\usepackage{lastpage}               % Referencia a la última página. Utilizado para el pie de página.
\usepackage{extramarks}             % Marcas extras. Utilizado en pie de página y cabecera.
\usepackage[parfill]{parskip}       % Crea una nueva línea entre párrafos.
\usepackage{geometry}               % Asigna la "geometría" de las páginas.

% Se elige el estilo fancy y márgenes de 3 centímetros.
\pagestyle{fancy}
\geometry{left=3cm,right=3cm,top=3cm,bottom=3cm,headheight=1cm,headsep=0.5cm} % Márgenes y cabecera.
% Se limpia la cabecera y el pie de página para poder rehacerlos luego.
%\fancyhfb{}

% Espacios en el documento:
\linespread{1.1}                        % Espacio entre líneas.
\setlength\parindent{0pt}               % Selecciona la indentación para cada inicio de párrafo.

% Cabecera del documento. Se ajusta la línea de la cabecera.
\renewcommand\headrule{
	\begin{minipage}{1\textwidth}
	    \hrule width \hsize
	\end{minipage}
}

% Texto de la cabecera:
\lhead{\docauthor}                          % Parte izquierda.
\chead{}                                    % Centro.
\rhead{\subject \ - \doctitle}              % Parte derecha.

% Pie de página del documento. Se ajusta la línea del pie de página.
\renewcommand\footrule{
\begin{minipage}{1\textwidth}
    \hrule width \hsize
\end{minipage}\par
}

\lfoot{}                                                 % Parte izquierda.
\cfoot{}                                                 % Centro.
\rfoot{Página\ \thepage\ de\ \protect\pageref{LastPage}} % Parte derecha.

%-----------------------------------------------------------------------------------------------------
%	PORTADA
%-----------------------------------------------------------------------------------------------------

% Elija uno de los siguientes formatos.
% No olvide incluir los archivos .sty asociados en el directorio del documento.
\usepackage{title1}
%\usepackage{title2}
%\usepackage{title3}

%----------------------------------------------------------------------------------------
%   MATEMÁTICAS
%----------------------------------------------------------------------------------------

\usepackage{mathematics}
\usepackage{pgfplots}
\pgfplotsset{compat=newest}
\usepackage{float}

%----------------------------------------------------------------------------------------
%   ENLACES
%----------------------------------------------------------------------------------------
\usepackage{hyperref}
\hypersetup{
    colorlinks   = true,   % Quita las cajas y añade un color al texto.
    % Tipos de enlaces cuyo color se puede configurar:
    linkcolor    = [rgb]{0,0.2,0.5},        % Por defecto red
    anchorcolor  = gray,        % Por defecto black
    citecolor    = magenta,     % Por defecto green
    filecolor    = red,         % Por defecto cyan
    menucolor    = green,       % Por defecto red
    runcolor     = red,         % Por defecto cyan
    urlcolor     = cyan        % Por defecto magenta
}

%-----------------------------------------------------------------------------------------------------
%	TÍTULO, AUTOR Y OTROS DATOS DEL DOCUMENTO
%-----------------------------------------------------------------------------------------------------

% Título del documento.
\newcommand{\doctitle}{Apuntes}
% Subtítulo.
\newcommand{\docsubtitle}{}
% Fecha.
\newcommand{\docdate}{\date}
% Asignatura.
\newcommand{\subject}{Inferencia Estadística}
% Autor.
\newcommand{\docauthor}{Andrés Herrera Poyatos}
\newcommand{\docaddress}{Universidad de Granada}
\newcommand{\docemail}{andreshp9@gmail.com}


%-----------------------------------------------------------------------------------------------------
%	RESUMEN
%-----------------------------------------------------------------------------------------------------

% Resumen del documento. Va en la portada.
% Puedes también dejarlo vacío, en cuyo caso no aparece en la portada.
\newcommand{\docabstract}{}
%\newcommand{\docabstract}{En este texto puedes incluir un resumen del documento. Este informa al lector sobre el contenido del texto, indicando el objetivo del mismo y qué se puede aprender de él.}

\begin{document}

\hypersetup{pageanchor=false}
\maketitle
\hypersetup{pageanchor=true}

%-----------------------------------------------------------------------------------------------------
%	ÍNDICE
%-----------------------------------------------------------------------------------------------------

% Profundidad del Índice:
%\setcounter{tocdepth}{1}

\newpage
\tableofcontents
\newpage

%-----------------------------------------------------------------------------------------------------
%	SECCIÓN 1
%-----------------------------------------------------------------------------------------------------

\section{Familias de distribuciones}

\subsection{Distribuciones discretas}

\subsection{Distribuciones continuas}

\subsubsection{Distribución uniforme}

La distribución uniforme asigna una credibilidad uniforme a todos los puntos de un intervalo $[a,b]$. Esto es, su función de densidad viene dada por
\[f(x|a,b) = \begin{cases}\frac{1}{b-a} \text{ si } x \in [a,b], \\ 0 \text{ en otro caso.}\end{cases}\]
Claramente tenemos que $\int_{-\infty}^{\infty} f(x |a,b) dx = 1$. Además, podemos calcular fácilmente sus momentos y, por tanto, también su varianza, como sigue
\[E[X^j] = \int_a^b \frac{x^j}{b-a} dx = \frac{b^{j+1} - a^{j+1}}{(b-a) (j+1)},\]
\[Var(X) = E[X^2] - E[X]^2 = \frac{a^2 + ab + b^2}{3} - \frac{(a+b^2)}{4} = \frac{(b-a)^2}{12}.\]

\subsubsection{Distribución normal}

La distribución normal, también llamada distribución gaussiana, es la distribución más importante de la estadística. Esto se debe a sus numerosas aplicaciones en análisis de poblaciones y al teorema central del límite.

\begin{definition}
    Sean $\mu \in \mathbb{R}$ y $\sigma^2 > 0$. Definimos la distribución $N(x | \mu, \sigma^2)$ como la distribución que tiene función de densidad
    \[f(x | \mu, \sigma^2) = \frac{1}{\sqrt{2\pi}\sigma}e^{-(x-\mu)^2 / (2\sigma^2)}.\]
\end{definition}


\subsubsection{Distribución gamma}

La famila de distribuciones gamma se encuentra definida sobre el intervalo $[0, \infty)$. En su definición entra en juego la famosa función gamma, de ahí su nombre.

\begin{definition}
    Se define la función gamma como la aplicación $\Gamma : (0, \infty) \to (0, \infty)$ dada por
    \[\Gamma(\alpha) = \int_0^\infty t^{\alpha-1}e^{-t}dt.\]
\end{definition}
\begin{prop}
    La función gamma está bien definida.
\end{prop}
\begin{proof}
    Sea $\alpha > 0$. Tenemos que probar que $\int_0^\infty t^{\alpha-1}e^{-t}dt < \infty$. Tomando $b > 0$, escribimos
    \[\int_0^\infty t^{\alpha-1}e^{-t}dt = \int_0^b t^{\alpha-1}e^{-t}dt + \int_b^\infty t^{\alpha-1}e^{-t}dt.\]
    Sabemos que la función $t^{\alpha - 1}$ tiene a $t^{\alpha} / \alpha$ como primitiva y, por tanto, es integrable en $[0,b]$. Puesto que $t^{\alpha-1}e^{-t} \le t^{\alpha-1}$, obtenemos que $t^{\alpha-1}e^{-t}$ es integrable en $[0,b]$. Por otro lado tenemos que
    \[\lim_{t \to \infty} \frac{t^{\alpha-1}e^{-t}}{e^{-t / 2}} = 0.\]
    Consecuentemente, para cierto $b > 0$ se verifica $t^{\alpha-1}e^{-t} \le e^{-t / 2}$ para todo $t \ge b$. Puesto que $e^{-t / 2}$ es integrable en $[b, \infty)$, deducimos que $t^{\alpha-1}e^{-t}$ también lo es, lo que termina la demostración.
\end{proof}

\begin{prop}[Propiedades de la función gamma]
    Sea $\alpha > 0$. Se verifica:
    \begin{enumerate}
        \item $\Gamma(1) = 1$;
	\item $\Gamma(\alpha+1) = \alpha\Gamma(\alpha)$;
    \item $\Gamma(n+1) = n!$ para cualquier $n \in \mathbb{N}$;
    \item (Fórmula de reflexión de Euler) si $0 < \alpha < 1$, entonces $\Gamma(\alpha) \Gamma(1- \alpha) = \frac{\pi}{\sin(\alpha \pi)}$;
    \item $\Gamma(1/2) = \sqrt{\pi}$;
    \item $\Gamma(\alpha) = \beta^\alpha\int_0^\infty t^{\alpha-1}e^{-\beta t} dt$ para todo $\beta > 0$.
    \end{enumerate}
\end{prop}
\begin{proof}
    \
    \begin{enumerate}
        \item Es fácil ver que $\int_{0}^\infty e^{-t} dt = 1$.
        \item Integrando por partes obtemos
        \[\Gamma(\alpha+1) = \int_0^{\infty}{t^{\alpha}e^{-t}dt} = \bigg[-e^{-t}t^\alpha\bigg]_0^{\infty} +
            \int_0^{\infty}{xt^{\alpha-1}e^{-t}dt} = \alpha\int_0^{\infty}{t^{\alpha-1}e^{-t}dt} = \alpha\Gamma(\alpha).\]
        \item Es consecuencia directa de los apartados a) y b).
        \item Se obtiene utilizando definiciones alternativas de la función gamma tras extenderla a $\mathbb{C} \setminus \mathbb{Z}^-_0$. Para más información véase \cite{gamma}. No desarrollamos esta demostración pues solo la necesitamos para el siguiente apartado.
        \item Se obtiene al evaluar la fórmula de reflexión en $\alpha = 1/2$.
        \item Se obtiene realizando el cambio de variable $t = \beta s$. \qedhere
    \end{enumerate}
\end{proof}

\begin{definition}
    Sean $\alpha, \beta > 0$. Definimos la distribución $Gamma(x | \alpha, \beta)$ como la distribución que tiene función de densidad
    \[f(x | \alpha, \beta) = \frac{\beta^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x}.\]
\end{definition}

El parámetro $\alpha$ se conoce como parámetro de forma ya que influencia la forma de la distribución, como muestra el siguiente resultado.

\begin{prop}
    La función de densidad de la distribución $Gamma(\alpha, \beta)$ verifica las siguientes propiedades:
    \begin{itemize}
        \item Si $0< \alpha <1$, entonces $f(x | \alpha, \beta)$ es decreciente y $f(x) \to \infty$ para $x \to 0$.
        \item Si $\alpha = 1$, entonces $f(x | \alpha, \beta)$ es decreciente con $f(0) = 1$.
        \item Si $\alpha > 1$, entonces $f(x | \alpha, \beta)$ crece en $[0, (\alpha-1) / \beta]$ y decrece en $[(\alpha-1) / \beta,\infty]$.
        \item Si $0 < \alpha \le 1$, entonces $f(x | \alpha, \beta)$ es convexa.
        \item Si $1 < \alpha \le 2$, entonces $f(x | \alpha, \beta)$ es cóncava en $[0,(\alpha-1 + \sqrt{\alpha - 1}) / \beta]$ y convexa en $[(\alpha-1 + \sqrt{\alpha - 1}) / \beta, \infty]$.
        \item Si $2 < \alpha$, entonces $f(x | \alpha, \beta)$ es cóncava en $[(\alpha-1 - \sqrt{\alpha - 1}) / \beta,(\alpha-1 + \sqrt{\alpha - 1}) / \beta]$ y convexa en $[0, (\alpha-1 - \sqrt{\alpha - 1}) / \beta]$ y $[(\alpha-1 + \sqrt{\alpha - 1}) / \beta, \infty]$.
    \end{itemize}
\end{prop}
\begin{proof}
Los resultados se obtienen mediante las herramientas habituales del cálculo. Basta estudiar la derivada primera y la derivada segunda
\begin{align*}
f^\prime(x) &= \frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha-2} e^{-\beta x}[(\alpha - 1) - \beta x]; \\
f^{\prime \prime}(x) &= \frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha-3} e^{-\beta x} \left[(\alpha - 1)(\alpha - 2) - 2 \beta (\alpha - 1) x + \beta^2 x^2\right]. \qedhere
\end{align*}
\end{proof}

La Figura \ref{fig:gamma:alpha} muestra la función de densidad de la distribución gamma para distintos valores de $\alpha$.  El parámetro $\beta$ se denomina parámetro de escala debido a su influencia en la escala de la función de densidad. La Figura \ref{fig:gamma:beta} muestra la función de densidad de la distribución gamma para distintos valores de $\beta$.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}[
        declare function={gamma(\z)=
        2.506628274631*sqrt(1/\z)+ 0.20888568*(1/\z)^(1.5)+ 0.00870357*(1/\z)^(2.5)- (174.2106599*(1/\z)^(3.5))/25920- (715.6423511*(1/\z)^(4.5))/1244160)*exp((-ln(1/\z)-1)*\z;},
        declare function={gammapdf(\x,\k,\theta) = 1/(\theta^\k)*1/(gamma(\k))*\x^(\k-1)*exp(-\x/\theta);}
        ]
        \begin{axis}[
            ylabel={$f(x | \alpha, \beta)$},
            domain=0.000001:10, samples=100,
            axis lines=left,
            every axis y label/.style={at=(current axis.above origin),anchor=east},
            every axis x label/.style={at=(current axis.right of origin),anchor=north},
            height=6cm, width=12cm,
            enlargelimits=false, clip=false, axis on top,
            grid = major,
            legend pos=outer north east
        ]
            \addplot [very thick,cyan!20!black] {gammapdf(x,0.98,2)};
            \addlegendentry{$\alpha = 0.9, \beta = 2$}
            \addplot [very thick,cyan!35!black] {gammapdf(x,1,2)};
            \addlegendentry{$\alpha = 1, \beta = 2$}
            \addplot [very thick,cyan!60!black] {gammapdf(x,2,2)};
            \addlegendentry{$\alpha = 2, \beta = 2$}
            \addplot [very thick,cyan] {gammapdf(x,3,2)};
            \addlegendentry{$\alpha = 3, \beta = 2$}
        \end{axis}
    \end{tikzpicture}
    \caption{Densidad de la distribución gamma con distintos valores de $\alpha$.}
    \label{fig:gamma:alpha}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{tikzpicture}[
        declare function={gamma(\z)=
        2.506628274631*sqrt(1/\z)+ 0.20888568*(1/\z)^(1.5)+ 0.00870357*(1/\z)^(2.5)- (174.2106599*(1/\z)^(3.5))/25920- (715.6423511*(1/\z)^(4.5))/1244160)*exp((-ln(1/\z)-1)*\z;},
        declare function={gammapdf(\x,\k,\theta) = 1/(\theta^\k)*1/(gamma(\k))*\x^(\k-1)*exp(-\x/\theta);}
        ]
        \begin{axis}[
            ylabel={$f(x | \alpha, \beta)$},
            domain=0:10, samples=100,
            axis lines=left,
            every axis y label/.style={at=(current axis.above origin),anchor=east},
            every axis x label/.style={at=(current axis.right of origin),anchor=north},
            height=6cm, width=12cm,
            enlargelimits=false, clip=false, axis on top,
            grid = major,
            legend pos=outer north east
        ]
            \addplot [very thick,magenta!10!black] {gammapdf(x,2,0.5)};
            \addlegendentry{$\alpha = 2, \beta = 0.5$}
            \addplot [very thick,magenta!40!black] {gammapdf(x,2,1)};
            \addlegendentry{$\alpha = 2, \beta = 1$}
            \addplot [very thick,magenta!75!black] {gammapdf(x,2,2)};
            \addlegendentry{$\alpha = 2, \beta = 2$}
            \addplot [very thick,magenta] {gammapdf(x,2,3)};
            \addlegendentry{$\alpha = 2, \beta = 3$}
        \end{axis}
    \end{tikzpicture}
    \caption{Densidad de la distribución gamma con distintos valores de $\beta$.}
    \label{fig:gamma:beta}
\end{figure}

\begin{prop} \label{prop:gamma:cf}
    La función característica de la distribución $Gamma(x|\alpha, \beta)$ viene dada por $\varphi_X(t) = \left(\frac{\beta}{\beta -it}\right)^\alpha$.
\end{prop}
\begin{proof}
    Basta utilizar el cambio de variable $g(y) = y / (\beta - it)$ como sigue
    \[E[e^{itX}] = \frac{\beta^\alpha}{\Gamma(\alpha)} \int_{0}^{\infty} x^{\alpha-1}e^{-(\beta - it) x} dx = \frac{\beta^\alpha}{\Gamma(\alpha) (\beta -it)^\alpha} \int_{0}^{\infty} y^{\alpha-1}e^{-y} dy = \left(\frac{\beta}{\beta -it}\right)^\alpha.\]
    Nótese que a pesar de ser una integral de contorno compleja el cambio de variable es válido. En efecto, el cambio de variable es afín y la función a integrar es entera. Por tanto, utilizando el camino cerrado $g([0, \infty]) + [\infty, 0]$ se puede probar que el cambio es válido.
\end{proof}

\begin{cor}
    El momento $k$-ésimo de la distribución $Gamma(x|\alpha,\beta)$ es $\alpha (\alpha+1) \ldots (\alpha + k -1) / \beta^k$.
\end{cor}
\begin{proof}
    Tenemos que $i^k E[X^k]= \varphi_X^{(k)}(t) = i^k \alpha (\alpha+1) \ldots (\alpha + k -1) / \beta^k$.
\end{proof}

\begin{prop}
    La función generatriz de momentos de la distribución $Gamma(x|\alpha, \beta)$ viene dada por $\varphi_X(t) = \left(\frac{\beta}{\beta - t}\right)^\alpha$.
\end{prop}
\begin{proof}
    La demostración es análoga a la dada en la Proposición \ref{prop:gamma:cf}.
\end{proof}

\begin{cor}
    La distribución $Gamma(x|\alpha,\beta)$ tiene media $\alpha / \beta$ y varianza $\alpha / \beta^2$.
\end{cor}

\begin{prop}
    Sea $n \ge 1$. Consideremos $X_1, \ldots, X_n$ variables aleatorias independientes tales que $X_j$ sigue una distribución $Gamma(x|\alpha_i, \beta)$. Entonces, $\sum_{i=1}^n X_j$ sigue una distribución $Gamma(x|\sum_{i=1}^n \alpha_i, \beta)$.
\end{prop}
\begin{proof}
    En primer lugar, calculamos la función característica de $\sum_{i=1}^n X_j$ como sigue
    \[E[e^{i\sum X_j}] = E[\prod e^{iX_j}] = \prod E[e^{iX_j}] = \left(\frac{\beta}{\beta - it}\right)^{\sum \alpha_j},\]
    donde se ha utilizado que la esperanza del producto de dos variables aleatorias independientes es el producto de las esperanzas. Por último, nótese que la función característica de la variable $\sum X_j$ es la función característica de $Gamma(x|\sum_{i=1}^n \alpha_i, \beta)$. El hecho de que la función característica de una distribución la determina de forma unívoca finaliza la prueba.
\end{proof}

\subsubsection{Distribución beta}

\subsubsection{Distribución de Cauchy}

\subsubsection{Distribución de Laplace}

\subsubsection{Distribución T de Student}

\subsubsection{Distribución de Dirichlet}

\section{Estimación de parámetros}

Supongamos que estamos estudiando un fenómeno aleatorio que sabemos que sigue una distribución $f(X | \theta_0)$, donde $\theta_0 \in \Omega$ es un parámetro que no es conocido. Nuestro objetivo es estimar el parámetro $\theta_0$ a partir de una muestra $x_1, \ldots, x_n$. Para ello buscamos una función $T_n$ de manera que podamos decir $\theta_0 \approx T_n(x_1, \ldots, x_n)$.

\begin{definition}
    Un estimador puntuales una función medible $T_n(X_1, \ldots, X_n)$ que toma valores $\Omega$, donde $\Omega$ es el dominio del parámetro a estimar. Una estimación es la evaluación obtenida por un estimador sobre una muestra $x_1, \ldots, x_n$, esto es, $T_n(x_1, \ldots, x_n)$.
\end{definition}

En múltiples situaciones encontramos estimadores de calidad de forma natural. Por ejemplo, imaginemos que el parámetro $\theta_0$ se corresponde con la media de la distribución $f(X | \theta_0)$. En tal caso, parece claro que el mejor estimador para $\theta_0$ será la media muestral $\overline{x} = \frac{1}{n}\sum_{i = 1}^n x_i$. Sin embargo, en general no sabemos qué estimador hay que utilizar. Buscamos técnicas que nos proporcionen estimadores que sean razonables. En ocasiones querremos estimar $g(\theta_0)$, donde $g$ es determinada transformación de $\Omega$ en otro espacio más manejable.

Para comprobar cómo de bueno es un estimador podemos definir una función de pérdida $L(\theta,T)$ que indique la pérdida asociada a estimar un parámetro mediante un estimador $T$ si su verdadero valor es $\theta$. A partir de la función de pérdida deinfimos la función de riesgo, que asocia a cada posible valor del parámetro la pérdida media asociada al estimador. La función de riesgo viene dada por
\[ R^L_T(\theta) = E_\theta [L(\theta,T)].\]
El estimador óptimo es el que minimiza uniformemente la función de riesgo, esto es, $T$ es estimador óptimo si para cada estimador $T'$ se tiene que
\[ R^L_T(\theta) \leq R^L_{T'}(\theta) \ \forall \ \theta \in \Omega.\]

\subsection{Método de los momentos}

El método de los momentos es, probablemente, el método más antiguo para estimar parámetros. Fue propuesto por Pearson al finales del siglo XIX. En muchos casos los resultados de este método son mejorables. Sin embargo, siempre es un último recurso en el caso de que no podamos aplicar otros métodos.

Sea $X_1, \ldots, X_n$ una muestra de un fenómeno con función de distribución $f(X |\theta)$ con $\theta \in \Omega$. Suponemos que $\theta = (\theta_1, \ldots, \theta_k)$ con $\theta_i \in \mathbb{R}$. Definimos los momentos de la muestra como $m_j = \frac{1}{n} \sum_{i = 1}^n X_i^j$. En media se debería cumplir que $m_j = E_\theta X^j$ para todo $j$ tal que $E_\theta X^j$ existe. Nótese que $E_\theta X^j = \mu_j(\theta_1, \ldots, \theta_k)$ es una función que depende de $\theta_1, \theta_2, \ldots, \theta_k$. El método de los momentos propone como estimador a una solución del sistema de ecuaciones
\begin{equation} \label{eq:sistema-momentos}
    \begin{matrix}
        m_1 = \mu_1(\theta_1, \ldots, \theta_k), \\
        m_2 = \mu_1(\theta_1, \ldots, \theta_k), \\
        \vdots \\
        m_k = \mu_1(\theta_1, \ldots, \theta_k). \\
    \end{matrix}
\end{equation}

\begin{example}[Distribución normal]
    Supongamos que $X_1, \ldots, X_n$ son muestras de una distribución normal $N(\theta, \sigma^2)$. En el contexto anterior, los parámetros a estimar son $\theta_1 = \theta, \theta_2 = \sigma^2$. En este caso el sistema \eqref{eq:sistema-momentos} viene dado por las ecuaciones $\overline{X} = \theta$ y $m_2 = \theta^2 + \sigma^2$. La solución claramente es $\theta = \overline{X}$ y
    \[\sigma^2 = \frac{1}{n} \sum_{i = 1}^n X_i^2 - \overline{X}^2 = \frac{1}{n} \sum_{i = 1}^n (X_i - \overline{X})^2.\]
    En este caso, los estimadores obtenidos coinciden con nuestra intuición. Este método es más útil cuando no disponemos de un estimador intuitivo.
\end{example}

\begin{example}[Distribución binomial]
\end{example}

\subsection{Estimadores insesgados}

\begin{definition}
    Se denomina sesgo de un estimador $T$ de $g(\theta)$ a la diferencia entre la esperanza del estimador y el verdadero valor del parámetro a estimar. Diremos que un estimador es insesgado si su sesgo es nulo.
\end{definition}

\begin{prop}
    Sea $X_1, \ldots, X_n$ una muestra de alguna población con función de densidad $f(X | \theta_0)$. Definimos la varianza muestral como
    \[S^2 = \frac{1}{n-1}\sum_{i = 1}^n(X_i - \overline{X})^2.\]
    Entonces, $S^2$ es un estimador insesgado de la varianza de la distribución.
\end{prop}
\begin{proof}
    Nótese que $\sum_{i = 1}^n(X_i - \overline{X})^2 = \sum_{i = 1}^nX_i^2 - n\overline{X}^2$. Consecuentemente tenemos
    \[E\left[\sum_{i = 1}^n(X_i - \overline{X})^2\right] = \sum_{i = 1}^nE\left[X_i^2\right] -     nE[\overline{X}^2] = n(E\left[X_i^2\right] - E[\overline{X}^2]).\]
    Utilizando que $Var(\overline{X}) = Var(X_i) / n$ y $E[\overline{X}] = E[X_i]$ obtenemos
    \[E[X_i^2] - E[\overline{X}^2] = Var(X_i) + E[X_i]^2 - Var(\overline{X}) - E[\overline{X}]^2 = \frac{n-1}{n} Var(X_i).\]
    Por tanto, $E[S^2] = Var(X_i)$ como se quería.
\end{proof}

\subsection{Estadísticos suficientes}

Intuitivamente, un estadístico es suficiente para el parámetro $\theta$ si utiliza toda la información contenida en la muestra aleatoria con respecto a $\theta$.

Un criterio para ver si un estadístico es suficiente viene dado por el teorema de factorización de Neyman.

\begin{thm}
    Sea $X_1, X_2, \ldots, X_n$ una muestra de una distribución con una función de densidad de probabilidad $f(x;\theta)$. Se dice que $T(X_1, X_2, \ldots, X_n)$ es un estadístico suficiente de $\theta$ si y solo si la función de verosimilitud puede factorizarse de la siguiente forma
    \[L(x_1, x_2, \ldots, x_n) = h(t;\theta) g(x_1, x_2, \ldots, x_n).\]
\end{thm}

\subsection{Método de la máxima verosimilitud de Fisher}

    El método de la máxima verosimilitud es la técnica más utilizada para obtener estimadores.

    \begin{definition}
        Sea $x_1, \ldots, x_n$ una muestra de un fenómeno con función de distribución $f(X | \theta_0)$, donde $\theta_0 \in \Omega$. Se define la función de verosimilitud para cada $\theta \in \Omega$ como $L(\theta | x) = \prod_{i = 1}^n f(x_i| \theta)$.
    \end{definition}

    Para cada posible valor $\theta$ del parámetro a estimar, la verosimilitud proporciona la credibilidad que se le da a $\theta$ para los datos $x_1, \ldots, x_n$. Buscamos una aproximación $\hat{\theta}$ de $\theta_0$ en base a la muestra obtenida. Parece lógico que si asumimos que los datos son correctos, entonces una buena aproximación será aquella en la que los datos sean coherentes, esto es, la probabilidad de que se den datos similares a la muestra observada debe ser lo más alta posible.

    \begin{definition}
        Para cada elemento $x = (x_1, \ldots, x_n)$ del espacio muestral, definimos $\hat{\theta}(x) \in \Omega$ como un máximo de $L(\theta | x)$. El estimador máximo verosímil (EMV) de una muestra $X$ se define como $\hat{\theta}(X)$.
    \end{definition}

    El estimador máximo verosímil presenta principalmente dos problemas.
    \begin{itemize}
        \item Cálculo del estimador. Para calcular $\hat{\theta}(X)$ es necesario maximizar una función. Muchas veces esto es complejo incluso para funciones de densidad comunes.
        \item Sensibilidad numérica. El valor $\hat{\theta}(x)$ puede cambiar considerablemente para pequeñas variaciones de $x$. Nos preguntamos qué condiciones debe verificar la función de distribución para evitar este comportamiento.
    \end{itemize}

    \begin{remark} \label{rem:emv:log}
        Los máximos globales de la función $L(\theta | x)$ se corresponden con los máximos globales de la función $\log L(\theta | x) = \sum_{i = 1}^n \log f(x_i | \theta)$. En múltiples ocasiones es más sencillo maximizar esta última expresión.
    \end{remark}

    \begin{example}[Distribución normal]
        Consideremos una muestra $X_1, \ldots, X_n$ de un fenómeno con distribución $N(\theta,1)$. En primer lugar, calculamos la función de verosimilitud
        \[L(\theta | x) = \prod_{i = 1}^n \frac{1}{\sqrt{2\pi}} e^{-(x_i - \theta)^2 / 2} = \frac{1}{(2\pi)^{n/2}}e^{-\sum_{i = 1}^n (x_i - \theta)^2 / 2}.\]
        En virtud del Comentario \ref{rem:emv:log} maximizamos la función $-\sum_{i = 1}^n (x_i - \theta)^2 / 2 - n/2 \log(2\pi)$. Maximizar esta función equivale a minimizar $h(\theta) = \sum_{i = 1}^n (x_i - \theta)^2$. Derivando, obtenemos que $h'(\theta) = 0$ si, y solo si, $\theta = \overline{x}$. Además, es rutinario comprobar que $\overline{x}$ es el mínimo absoluto de $h$. Por tanto, $\overline{x}$ es el máximo absoluto de $L(\theta | x)$. Tenemos pues $\hat{\theta}(x) = \overline{x}$.
    \end{example}

    A continuación pretendemos extender el método de la máxima verosimilitud para estimar $g(\theta)$, donde $g : \Omega \to \Omega'$ sobreyectiva. Si la aplicación $g$ fuese inyectiva, entonces podemos definir de norma natural la verosimilitud de $\eta \in \Omega'$ como $L^*(\eta | x) = L(g^{-1}(\eta) | x)$. Claramente, el valor que maximiza $L^*(\eta | x)$, que denotaremos $\hat{g}(x)$, es $g(\hat{\theta}(x))$. Sin embargo, los casos que presentan relevancia práctica son aquellos en los que $g$ no es inyectiva ya que de esta forma conseguimos reducir la dimensionalidad del espacio de parámetros. Necesitamos extender la definición de verosimilitud para abordar esta problemática.

    \begin{definition}
        En el contexto anterior, definimos la verosimilitud inducida por $g$ como
        \[L^*(\eta|x) = \sup\{L(\theta | x): \theta \in g^{-1}(\eta)\}.\]
        El valor $\hat{g}(x)$ que maximiza $L^*(\eta|x)$ se denomina estimador maximo verosímil de $g(\theta)$.
    \end{definition}

    La definición anterior es artificial en el sentido de que se realiza con el fin de poder mantener la propiedad de invarianza del estimador máximo verosímil, que se recoge en el siguiente teorema.

    \begin{thm}[Invarianza de Zehna]
        Para cualquier aplicación sobreyectiva $g: \Omega \to \Omega'$ se tiene que $\hat{g}(X) = g(\hat{\theta}(X))$.
    \end{thm}
    \begin{proof}
        En primer lugar, por la definición de la verosimilitud inducida se tiene que
        \[\sup_{\eta \in \Omega'} L^*(\eta|x) = \sup_{\eta \in \Omega'} \sup\{L(\theta | x): \theta \in g^{-1}(\eta)\} = \sup_{\theta \in \Omega} L(\theta | x)\]
        Por tanto, la verosimilitud tiene un máximo global si, y solo si, lo tiene la verosimilitud inducida, en cuyo caso la credibilidad de ambos coincide. Si existe un EMV de $\theta$, entonces $L^*(g(\hat{\theta}),x) = L(\hat{\theta} | x)$ por definición. Consecuentemente, $g(\hat{\theta})$ es estimador máximo verosímil de $g(\theta)$.
    \end{proof}

\begin{thebibliography}{99}
\bibitem{gamma} Proof Wiki, Euler's Reflection Formula, \url{https://proofwiki.org/wiki/Euler%27s_Reflection_Formula}.
\end{thebibliography}


\end{document}
